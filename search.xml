<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[深度学习算法-卷积网络]]></title>
      <url>/2017/10/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/</url>
      <content type="html"><![CDATA[<h1 id="卷积运算">1. 卷积运算</h1><p>假设我们在用激光传感器追踪宇宙飞船的位置，$t$时刻位置在$x(t)$。</p>
<p>为了更好地估计，我们将时间越近的测量给予更高的权重$w(a)$，其中$a$表示测量结果距当前的时间间隔，那么：</p>
<p>$$s(t)=\int x(a)w(t-a)da = (x*w)(t)$$</p>
<p>tips:<br>$a$：距离当前时间的间隔；<br>$x(a)$：$a$时刻，飞船位置，$x$也叫<strong>输入</strong>；<br>$w(t-a)$：$t-a$时刻，也就是a秒前，飞船的权重，也是一种概率密度，叫做<strong>核函数</strong>；</p>
<p>离散形式的卷积是：<br>$$s(t)=(x*w)(t)=\sum_{\alpha=-\infty}^{\infty}x(a)w(t-a)$$</p>
<p>二维形式的卷积（我们定义核为K）：</p>
<p>$$S(i,j)=(I*K)(i,j)=\sum_m \sum_n I(m,n)K(i-m,j-n)$$</p>
<p>卷积是可交换的，也可写作：</p>
<p>$$S(i,j)=(K*I)(i,j)=\sum_m \sum_n I(i-m,j-n)K(m,n)$$</p>
<p>出现上面可交换的原因是：我们将核的相对输入进行了翻转，也相当于一种变量替换；</p>
<p>然而，在许多神经网络中采用的是<strong>互相关函数(cross-correlation)</strong>：</p>
<p>$$S(i,j)=(I*K)(i,j)=\sum_m \sum_n I(i+m,j+n)K(m,n)$$</p>
<p>这个是不可交换的。</p>
<h1 id="为什么要用卷积？">2. 为什么要用卷积？</h1><p>我们先说一下卷积网络的概念：卷积神经网络（Convolutional Neural Networks）的卷积操作是通过可训练的滤波器对上一层的输出进行卷积求和，然后添加上偏移量经过激活函数，得到了特征映射图作为下一层的输入。卷积操作相对于传统神经网络主要有稀疏链接、权值共享和等变表达的特性。</p>
<p>上面介绍完了卷积的概念，下面我们探讨一下，卷积存在的动机是什么。</p>
<p>卷积通过三个重要思想来帮助改进机器学习系统：稀疏交互、参数共享、等变表示。</p>
<p><strong>稀疏交互</strong></p>
<p>对于一张图像来说，输入图像可能包含上千万像素点。但我们可以通过只占用几十或几百的核来检测一些小的但有意义的特征，例如图像边缘。</p>
<p>下图是一种稀疏连接的例子，从下往上看，我们强调了一个输入单元$x_3$以及$s$中受该单元影响的输出单元。这个是当$s$由核宽度为3的卷积产生的，只有3个输出受到了$x$的影响：</p>
<p><img src="https://i.loli.net/2017/10/31/59f865cb07946.png" alt=""> </p>
<p>从另一个角度，从上往下看，这次我们抢到了一个输出单元$s_3$以及$x$中影响该单元的输入单元。这些单元被称为$s_3$的<strong>接受域</strong>。</p>
<p><img src="https://i.loli.net/2017/10/31/59f86ae962147.png" alt=""> </p>
<p>从深层的网络来看，我们可以看到尽管连接稀疏，但处在更深层的单元可以间接地连接到全部或大部分输入图像中。</p>
<p><img src="https://i.loli.net/2017/10/31/59f86aff4a4b1.png" alt="">  </p>
<p><strong>参数共享</strong></p>
<p>因为核的每一个元素都作用在输入的每一个位置上，因此卷积运算会导致用于一个输入的权重也会被绑定在其它权重上。这样的参数共享保证了我们只需要学习一个参数集合，而不是对每一个位置都需要学习一个单独的参数集合。如下图所示，黑色箭头表示两个不同模型中使用了特殊的参数连接。灰色箭头表示它用了黑色箭头的参数。其实就是一个$x$只有一个参数，但这个参数被用于了多个下一层。</p>
<p><img src="https://i.loli.net/2017/10/31/59f86f09c700e.png" alt="">  </p>
<p>对于卷积，参数共享的特殊形式使得神经网络层具有对<strong>平移等变的性质</strong>：先平移后卷积=先卷积后平移。</p>
<p><strong>边缘检测的例子</strong></p>
<p>如图所示，我们使用每个像素减去左边相邻像素形成的。这其实就是一种最简单的卷积。</p>
<p><img src="https://i.loli.net/2017/10/31/59f879f482dd9.png" alt=""></p>
<h1 id="池化">3. 池化</h1><p>卷积网络中一个典型层包括三级：卷积级、探测级和池化级。</p>
<p><img src="https://i.loli.net/2017/10/31/59f881a6783fa.png" alt=""> </p>
<p><strong>卷积级</strong>：并行计算多个卷积，产生一组线性激活响应；</p>
<p><strong>探测级</strong>(detector stage)：每个线性激活响应会通过一个非线性激活函数；</p>
<p><strong>池化级</strong>：我们使用池化(pooling)函数来进一步调整这一层的输出。</p>
<h2 id="池化函数">3.1. 池化函数</h2><p><strong>池化函数</strong>：使用某一位置的相邻输出的总体统计特征来代替网络再该位置的输出。</p>
<p>最大池化函数：给出相邻矩形区域内的最大值。</p>
<h2 id="池化函数有什么用？">3.2. 池化函数有什么用？</h2><p>池化函数帮助输入近似不变：即当我们对输入进行少量平移时，经过池化函数后的大多数输出并不会发生改变。</p>
<p>例如下图所示的例子。上图是一个网络，下图是一个网络，每个网络的下层是非线性输出，上层是最大池化输出。下图的非线性输出是通过向右平移一个像素得到的。我们可以发现，池化层的输出只有一半发生了改变，这是因为最大池化单元只对周围的最大值较敏感，而不是精确的位置。</p>
<p><img src="https://i.loli.net/2017/11/01/59f939076125c.png" alt=""> </p>
<p>当我们只关心某个特征是否出现（比如是否有眼睛），而不关心它的具体位置时，局部平移不变性是一个非常有用的性质。</p>
<p>对空间区域进行池化产生了平移不变性。下图是一种学习不变性的实例：反映的是池化的旋转不变性，对于输入手写5，有三个滤波器分别检测选择不同角度的手写5。当滤波器和对应的手写5匹配时，滤波器会得到一个较大的激活值，然后池化会选择得到最大的激活值，无论手写5是怎样的旋转的。</p>
<p><img src="https://ooo.0o0.ooo/2017/11/01/59f95b688c95b.png" alt=""> </p>
<h1 id="参考文献">4. 参考文献</h1><ol>
<li><a href="">深度学习</a></li>
<li><a href="http://www.datagrand.com/blog/neural.html" target="_blank" rel="external">达观数据深度学习</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 深度学习算法 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[数学-最大似然估计]]></title>
      <url>/2017/10/26/%E6%95%B0%E5%AD%A6-%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/</url>
      <content type="html"><![CDATA[<p>其实在之前的博客<a href="https://jiayi797.github.io/2017/07/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%9A%84%E7%90%86%E8%A7%A3/" target="_blank" rel="external">朴素贝叶斯的理解</a>一文中曾经提到过最大似然估计。</p>
<p>极大似然估计的核心思想是：我们已知$x$已发生，我们再根据实际情况写出$x$发生的概率$p(x;θ)$。目标函数是使得这个概率$p(x;θ)$最大，然后求得$θ$：</p>
<p>$$\theta_{ML}=arg max_\theta p(X;\theta)=arg max_\theta ∏_{i=1}^mp(x^{i};\theta)$$</p>
<font size="2.5">上公式中：<br>$p(X;\theta)$是样本集$X$出现的概率；<br>$p(x^{i};\theta)$是某个样本出现的概率；<br>左式等于右式原因是每个样本出现的概率独立；<br></font>

<p>多个数的连乘容易溢出，我们可以将它转化为log运算：<br>$$\theta_{ML}=arg max_\theta \sum{i=1}^mlog p(x^{i};\theta)$$<br>将上式除以$m$，得到一种期望：<br>$$\theta_{ML}=arg max_\theta E_{x\text{~}p’_{data}}log p(x^{i};\theta) \tag{公式1}$$<br>这个式子的含义是：在经验分布$x\text{~}p^`$上，求得一个$\theta$，使得模型分布的期望最大化。</p>
<p>此时我们暂时先不看上面这个公式。我们从另一个角度——误差来衡量。训练集上的经验分布$p’_{data}​$和模型之间的分布差异可以用KL散度衡量：</p>
<p>$$D_{KL}(p’_{data}||p_{model}) = E_{x\text{~}p’_{data}}[logp’_{data}(x)-logp_{model}(x)]$$</p>
<p>我们的目标是使上式最小化。减号左边是在训练集上的，是一个常数；我们只关心右边：</p>
<p>$$\theta_{KL}=argmin_{\theta} -E_{x\text{~}p’_{data}}[logp_{model}(x)]\tag{公式2}$$</p>
<p>很明显我们可以看到，公式2与公式1其实是一样的。我们从这个角度证明了这种度量下的误差与极大似然是相同的。</p>
]]></content>
      
        <categories>
            
            <category> 数学 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[深度学习算法-误差函数探究]]></title>
      <url>/2017/10/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E8%AF%AF%E5%B7%AE%E5%87%BD%E6%95%B0%E6%8E%A2%E7%A9%B6/</url>
      <content type="html"><![CDATA[<p>之前我们在<a href="https://jiayi797.github.io/2017/09/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E4%BB%8B/" target="_blank" rel="external">神经网络简介</a>中曾经提到过误差函数。这一节我们总结一下误差函数。</p>
<p>误差函数一般有两种来源：</p>
<ol>
<li>如果参数模型定义了一个分布$p(y|x;\theta)$，我们采用最大似然原理得到代价函数：训练数据和模型预测间的交叉熵。这个在之后会详细解释。</li>
<li>如果不预测y的完整概率分布，仅仅预测在给定x条件下y的某种统计量，那就用某些专门的损失函数来计算。</li>
</ol>
<h1 id="方法1，使用最大似然学习条件分布">1. 方法1，使用最大似然学习条件分布</h1><p>可以在博客<a href="https://jiayi797.github.io/2017/10/26/%E6%95%B0%E5%AD%A6-%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/" target="_blank" rel="external">最大似然估计</a>中看到，参数模型定义了一个分布$p(y|x;\theta)$，为了求得参数，我们使用最大似然原理，得到最终的目标函数是最小化代价函数J——<strong>训练数据</strong>和<strong>模型预测</strong>间的<strong>交叉熵:</strong></p>
<p>$$J(\theta)=-E_{x,y\sim p’_{data}}log p_{model}(y|x)$$</p>
<p>上式的意义是：在$x,y$服从训练数据$ p’_{data}$分布下，使得模型的$-Elog p_{model}(y|x)$最小。</p>
<p>用似然解决问题带来的好处：</p>
<ol>
<li>当明确了一个模型$p(y|x)$时，就自动地确定了代价函数$logp(y|x)$。</li>
<li>对数函数能帮我们避免梯度过小（例如有的输出单元有一个指数函数，取对数后梯度就不那么小了）</li>
</ol>
<h1 id="方法2，简单学习条件统计量">2. 方法2，简单学习条件统计量</h1><p>我们用历史的数据，计算出特征x下y发生的概率：$f(x)=p(y|x)$，将它作为x特征下y的预测。学习这个条件统计量的过程就是我们这节介绍的方法。</p>
<h2 id="均方误差">2.1. 均方误差</h2><p>通过解优化问题：</p>
<p>$$f^<em>=arg min_f E_{x,y\sim p_{data}}||y-f(x)||^2 \tag{均方误差最小化时的f^</em>}$$</p>
<p>得到$f^*$,我们用它来进行预测得到：</p>
<p>$$f^*(x)=E_{y\sim p_{data}(y|x)}[y]\tag{将所有服从p_{data}(y|x)的y的y均值作为x特征下y的预测}$$</p>
<p>可以看出，这样得到的函数是可以用来对每个x的值预测出y的<strong>均值</strong>。</p>
<h2 id="平均绝对误差">2.2. 平均绝对误差</h2><p>还有另一种误差叫平均绝对误差，通过解优化问题：</p>
<p>$$f^*=arg min_f E_{x,y \sim p_{data}}||y-f(x)||_1$$</p>
<p>得到的函数，可以对每个x预测y取值的<strong>中位数</strong>。</p>
<h1 id="比较">3. 比较</h1><p>一般，均方误差和平均绝对误差在梯度下降法表现不好，因为饱和的输出单元梯度非常小。所以一般来说交叉熵代价函数更受欢迎。</p>
]]></content>
      
        <categories>
            
            <category> 深度学习算法 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[机器学习算法-L2R进一步了解]]></title>
      <url>/2017/09/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-L2R%E8%BF%9B%E4%B8%80%E6%AD%A5%E4%BA%86%E8%A7%A3/</url>
      <content type="html"><![CDATA[<p>之前的博客中简单介绍了Learning to Rank的基本原理，也讲到了Learning to Rank的几类常用的方法：pointwise，pairwise，listwise。这篇博客就pairwise中的RankSVM、GBRank和LambdaRank做简要介绍。</p>
<p>RankSVM是2000年提出的；GBRank是2007年提出的；LambdaMART是2008年提出的。因此我们按照提出顺序来讲解这三种算法。</p>
<h1 id="引言">1. 引言</h1><p>机器学习一般都是解决分类问题。而在Rank中我们遇到的是排序问题。那么如何将排序问题转化为分类问题成了当下的关键。</p>
<h2 id="如何将排序问题转化为分类问题？">1.1. 如何将排序问题转化为分类问题？</h2><p>对于一个query-doc pair（检索-文档结果对），我们可以将其用一个feature vector表示：x。而排序函数为f(x)，我们根据f(x)的大小来决定哪个doc排在前面，哪个doc排在后面。即如果f(xi) &gt; f(xj)，则xi应该排在xj的前面，反之亦然。可以用下面的公式表示：</p>
<p><img src="https://i.loli.net/2017/09/25/59c8b1ffea865.png" alt=""> </p>
<p>理论上，f(x)可以是任意函数，为了简单起见，我们假设其为线性函数：<br><img src="https://i.loli.net/2017/09/25/59c8b2152e915.png" alt=""><br>如果这个排序函数f(x)是一个线性函数，那么我们便可以将一个排序问题转化为一个二元分类问题。理由如下：<br>首先，对于任意两个feature vector xi和 xj，在f(x)是线性函数的前提下，下面的关系都是存在的：<br><img src="https://i.loli.net/2017/09/25/59c8b41b9bba0.png" alt=""><br>然后，便可以对xi和 xj的差值向量考虑二元分类问题。特别地，我们可以对其赋值一个label：<br><img src="https://i.loli.net/2017/09/25/59c8b4335d7e6.png" alt=""> </p>
<p>有一个很好的例子说明了如何将排序问题转化为分类问题，在L2R的笔记中已提到过，此处不再多加阐述。</p>
<p>将排序问题转化为分类问题之后, 我们就可以使用常用的机器学习方法解决该问题。</p>
<h1 id="RankSVM">2. RankSVM</h1><p>RankSVM的<strong>基本思想</strong>是，将排序问题转化为pairwise的分类问题，然后使用SVM分类模型进行学习并求解。Ranking SVM使用SVM来进行分类:<br><img src="https://i.loli.net/2017/09/25/59c8b8e74b0df.png" alt=""> </p>
<p>其中w为参数向量, x为文档的特征,y为文档对之间的相对相关性, ξ为松弛变量。</p>
<p>对这个公式，<a href="https://www.zhihu.com/question/23764120" target="_blank" rel="external">知乎</a>上有一个很好的解释：<br>之前svm为实现软间隔最大化，约束条件里有<img src="https://i.loli.net/2017/09/25/59c8b458a2a54.png" alt=""> 。而rank-svm是典型的pairwise方法，考虑两个有偏序关系的文档对，训练样本是xi^(1)-xi^(2)，所以要把约束条件改成<img src="https://i.loli.net/2017/09/25/59c8b472b130b.png" alt=""> ，由于相减不再需要偏置b。而优化问题中的目标函数和其他约束项不变。</p>
<h2 id="使用Clikthrough数据作为训练数据">2.1. 使用Clikthrough数据作为训练数据</h2><p>T. Joachims提出了一种非常巧妙的方法, 来使用Clickthrough数据作为Ranking SVM的训练数据。</p>
<p>假设给定一个查询”Support Vector Machine”, 搜索引擎的返回结果为<br><img src="https://ooo.0o0.ooo/2017/09/25/59c8b9563cab6.png" alt=""><br>其中1, 3, 7三个结果被用户点击过, 其他的则没有。因为返回的结果本身是有序的, 用户更倾向于点击排在前面的结果, 所以用户的点击行为本身是有偏(Bias)的。为了从有偏的点击数据中获得文档的相关信息, 我们认为: 如果一个用户点击了a而没有点击b, 但是b在排序结果中的位置高于a, 则a&gt;b。<br>所以上面的用户点击行为意味着: 3&gt;2, 7&gt;2, 7&gt;4, 7&gt;5, 7&gt;6。</p>
<h2 id="Ranking-SVM的开源实现">2.2. Ranking SVM的开源实现</h2><p><a href="http://www.cs.cornell.edu/people/tj/svm_light/svm_rank.html" target="_blank" rel="external">Joachims的主页</a>上有Ranking SVM的开源实现。</p>
<p>数据的格式与LIBSVM的输入格式比较相似, 第一列代表文档的相关性, 值越大代表越相关, 第二列代表查询, 后面的代表特征:<br>qid:1 1:1 2:1 3:0 4:0.2 5:0 # 1A<br>qid:1 1:0 2:0 3:1 4:0.1 5:1 # 1B<br>qid:1 1:0 2:1 3:0 4:0.4 5:0 # 1C<br>qid:1 1:0 2:0 3:1 4:0.3 5:0 # 1D<br>qid:2 1:0 2:0 3:1 4:0.2 5:0 # 2A<br>qid:2 1:1 2:0 3:1 4:0.4 5:0 # 2B<br>qid:2 1:0 2:0 3:1 4:0.1 5:0 # 2C<br>qid:2 1:0 2:0 3:1 4:0.2 5:0 # 2D<br>qid:3 1:0 2:0 3:1 4:0.1 5:1 # 3A<br>qid:3 1:1 2:1 3:0 4:0.3 5:0 # 3B<br>qid:3 1:1 2:0 3:0 4:0.4 5:1 # 3C<br>qid:3 1:0 2:1 3:1 4:0.5 5:0 # 3D</p>
<h1 id="GBRank">3. GBRank</h1><p>参考文献<a href="http://www.tuicool.com/articles/yAfiQ3r" target="_blank" rel="external">GBRank:一种基于回归的学习排序算法</a><br>对GBRank做出了较好的解释。原论文是[A Regression Framework for Learning Ranking Functions Using Relative Relevance Judgments]。下面对这个博客和论文进行摘录和整理。</p>
<h2 id="算法原理">3.1. 算法原理</h2><p>一般来说在搜索引擎里面，相关性越高的越应该排在前面。现在 query-doc 的特征使用向量x或者y表示，假设现在有一个文档对<xi,yi>，当xi排在yi前面时，我们使用xi&gt;yi来表示。我们含顺序的 pair 对用如下集合表示(也就是真的xi真的排在yi前面):<br><img src="https://i.loli.net/2017/09/25/59c8b9d26d47d.png" alt=""><br>现假设学习的排序函数为h，我们希望当h(xi)&gt;h(yi)时，满足xi&gt;yi的数量越多越好。那么如何来评价这个h到底好不好呢，那么我们可以定义h的风险函数为:<br><img src="https://i.loli.net/2017/09/25/59c8ba28f012e.png" alt=""><br>对于这个风险函数，我们可以做如下解释。我们的目标是：对于集合S中的某个文档对<xi,yi>来说，h要符合我们之前的设定，也就是：</xi,yi></xi,yi></p>
<p>当h(xi)&gt;h(yi)时，h是正确的，不造成损失；<br>当h(xi)&lt;h(yi)时，h是不符合预期的，会造成损失，并且损失的大小成残差的平方级别；</p>
<p>将R(h)与每个 pair 对<xi,yi>的cost画成图可表示为：<br><img src="https://i.loli.net/2017/09/25/59c8ba5bd7a2e.png" alt=""> </xi,yi></p>
<p>上述风险函数直接优化比较困难，这里一个巧妙的解决方案：也就是首先固定h(xi)或者h(yi)当中其中的一个，然后再通过回归的方式来解决问题。<br>为了避免优化函数h是一个常量，我们对风险函数加入一个平滑项τ(0&lt;τ≤10)：<br><img src="https://i.loli.net/2017/09/25/59c8ba71a4abd.png" alt=""><br>其实加上了这个平滑项之后，一来可以防止h变为常数，二来还对损失函数给了更严格的条件：如果希望xi&gt;yi，就得有h(xi)&gt;h(yi)+τ，也就是更为严格了。</p>
<p>接下来我们用Functional Gradient Descent法来求解h.</p>
<p>参考文献<a href="http://www.cnblogs.com/bentuwuying/p/6684585.html" target="_blank" rel="external">Learning to Rank算法介绍：GBRank</a>对这个求解方法做了扼要的介绍：</p>
<p>在GBDT中，Functional Gradient Descent的使用为：将需要求解的F(x)表示成一个additive model，即将一个函数分解为若干个小函数的加和形式，而这每个小函数的产生过程是串行生成的，即每个小函数都是在拟合 loss function在已有的F(x)上的梯度方向（由于训练数据是有限个数的，所以F(x)是离散值的向量，而此梯度方向也表示成一个离散值的向量），然后将拟合的结果函数进一步更新到F(x)中，形成一个新的F(x)。</p>
<ol>
<li>将h(xi)和h(xi)作为未知数。梯度下降使得R最小，来求得这些未知数。</li>
<li>对R计算h的负梯度：<br><img src="https://i.loli.net/2017/09/25/59c8baf10df1f.png" alt=""> </li>
<li>当pair对<xi,yi>符合条件时，上述梯度为0；反之，他们对应的梯度为：<br><img src="https://i.loli.net/2017/09/25/59c8bb529920a.png" alt=""> </xi,yi></li>
<li>接下来，还需要知道如何将梯度作用到h的更新上。通过设定xi的目标值为h(yi)+τ。yi的目标值为h(xi)−τ（这一步我的理解就是首先固定x/y中的某一个，然后去计算另一个）。因此在每轮迭代中，当h不满足<xi,yi>会产生一组数据：<img src="https://i.loli.net/2017/09/25/59c8bb6276a5c.png" alt=""> </xi,yi></li>
</ol>
<p>我们需要拟合本轮产生的所有负例。</p>
<p>下面形式化本算法：<br><img src="https://ooo.0o0.ooo/2017/09/25/59c8d9a57ef9f.png" alt=""><br>可以看到step3里面每轮都拟合误判的结果，在迭代中这个集合会越来越小。还有一种做法是将曾经误判的集合维持在训练集中，那么训练集就会始终增长。在这个步骤中使用GBDT模型进行回归预测，当然其他的回归方法也可以使用。</p>
<h1 id="LambdaMART">4. LambdaMART</h1><p>在learn to rank的成长过程中，2000提出了SVMRank，2006年提出GBrank，2008年提出lambdaMART。看了几个比较大的框架，我发现现在市面上最常见的learn to rank算法就是LambdaMART了。接下来先介绍一下LambdaMART的原理，然后再介绍xgboost中是怎么写的LambdaMart。</p>
<h2 id="LambdaMart的原理">4.1. LambdaMart的原理</h2><p>这一小节主要参考资料<a href="https://liam0205.me/2016/07/10/a-not-so-simple-introduction-to-lambdamart/" target="_blank" rel="external">LambdaMART 不太简短之介绍</a></p>
<p>Pointwise和Pairwise类型的LTR算法，将排序问题转化为回归、分类或者有序分类问题。Listwise 类型的 LTR 算法则另辟蹊径，将用户查询（Query）所得的结果作为整体，作为训练用的实例（Instance）。</p>
<p>LambdaMART 是一种 Listwise 类型的 LTR 算法，它基于 LambdaRank 算法和 MART(Multiple Additive Regression Tree)算法，<strong>将搜索引擎结果排序问题转化为回归决策树问题</strong>。MART实际就是梯度提升决策树（GBDT, Gradient Boosting Decision Tree）算法。GBDT 的核心思想是在不断的迭代中，新一轮迭代产生的回归决策树模型拟合损失函数的梯度，最终将所有的回归决策树叠加得到最终的模型。LambdaMART使用一个特殊的 Lambda 值来代替上述梯度，也就是将LambdaRank算法与MART算法加和起来。考虑到LambdaRank是基于RankNet算法的，所以在搞清楚LambdaMART算法之前，我们首先需要了解 MART、RankNet 和 LambdaRank 是怎么回事。</p>
<p>MART其实也是GBDT。此处对GBDT不再做过多的介绍。值得一提的是，MART并不对损失函数的形式做具体规定。实际上，损失函数几乎只需要满足可导这一条件就可以了。这一点非常重要，意味着我们可以把任何合理的可导函数安插在 MART 模型中。LambdaMART 就是用一个 λ 值代替了损失函数的梯度，将 λ和 MART 结合起来罢了。</p>
<h2 id="LambdaMART是怎么来的">4.2. LambdaMART是怎么来的</h2><p>Lambda 的设计，最早是由 LambdaRank 从 RankNet 继承而来。因此，我们先要从 RankNet 讲起。<br>后记：其实这些文章都是到处整理得来，远不及直接看论文的好。如果有兴趣的话，可以读一读微软整理的这篇论文<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf" target="_blank" rel="external">https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf</a></p>
<p><strong>RankNet的创新</strong></p>
<p>Ranking常见的评价指标都无法求梯度，因此没法直接对评价指标做梯度下降。</p>
<p>RankNet 的创新之处在于，它将不适宜用梯度下降求解的Ranking问题，转化为对概率的交叉熵损失函数的优化问题，从而适用梯度下降方法。</p>
<p>RankNet的终极目标是得到一个带参的算分函数s = f(x;w)</p>
<p>参考文献机器学习—RankNet.md](<a href="https://github.com/MangoLiu/mangoliu.github.io/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0---RankNet.md)给了一个非常好的例子：那么如何通过pair来训练，并最终作用到针对point的算分函数上，请看下面的简单例子。假设有以下同一个query下的4个文档，并且有3个特征维度，并对它们进行了人工打分，我们就利用它们来训练model。" target="_blank" rel="external">https://github.com/MangoLiu/mangoliu.github.io/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0---RankNet.md)给了一个非常好的例子：那么如何通过pair来训练，并最终作用到针对point的算分函数上，请看下面的简单例子。假设有以下同一个query下的4个文档，并且有3个特征维度，并对它们进行了人工打分，我们就利用它们来训练model。</a></p>
<pre><code>point       特征f1  特征f2  特征f3  label     
文档doc1      3       2        1      3(很好) 
文档doc2      1       2        1      2（好） 
文档doc3      1       1        2      1（一般） 
文档doc4      1       0        3      0（不好） 
</code></pre><p>于是，根据这个算分函数，我们可以根据特征来计算文档xi和xj的得分si和sj：<br>                        Si = f(xi;w),sj = f(xj,w)</p>
<p>我们并不知道每个特征维度的具体权值w[i]。但我们感觉到要训练出这样的结果，就是使label得分比较高的样本得分尽量大，让label低的样本得分尽量小。<br>即本例中，我们应该让f(doc1)得分尽量大，f(doc4)得分尽量小。其实也就是f(doc1)-f(doc4)的结果尽量大，因为这个分差实际就包含了前者尽量大后者尽量小的含义。并且之前那个常量b通过作差后，不见了。<br>这样两两文档即可组成一个文档对，我们把前者好于后者的成为正向文档对；反之称之为负向文档对。正向对表示前者好于后者，负向对表示后者劣于前者。其实表述的是同样的意义。因此，我们只需要正向的对就好了。因为负向对不能再额外提供有意义的信息了。那么我们提取出上面的正向对：</p>
<pre><code>Pair  作差       特征f1 特征f2  特征f3
P12 (doc1-doc2)    2      0       0
P13 (doc1-doc3)    2      1      -1
P14 (doc1-doc4)    2      2      -2
P23 (doc2-doc3)    0      1      -1
P24 (doc2-doc4)    0      2      -2
P34 (doc3-doc4)    0      1      -1
</code></pre><p>需要注意的是，这里的特征也进行了相减！</p>
<p>我们再引入一个文档对概率，表示文档i好于文档j的概率。我们将它称为两者的偏序概率：(这个东西我理解为是将偏序关系转化为概率的函数，类似于lr里面的sigmod函数)<br><img src="https://i.loli.net/2017/09/25/59c8db05e3ddb.png" alt=""> </p>
<p>那么，现在这个问题就转化成了使所有正向对的概率和最大。我们现在已经知道了目标函数，那么接下来就需要一个损失函数来将这个目标函数最优化。<br>再将以上的交叉熵定义为损失函数：<br><img src="https://i.loli.net/2017/09/25/59c8db19cd5b2.png" alt=""><br>然后对这个损失函数进行梯度下降：<br><img src="https://i.loli.net/2017/09/25/59c8db276ebc2.png" alt=""><br>在以上的方法中，我们将偏序关系转化为目标函数，然后再定义目标函数的损失函数，再通过梯度下降法求参数使得损失函数最小，得到目标函数。那么我们能不能直接定义梯度呢？</p>
<p><strong>LambdaRank</strong></p>
<p>参考文献<a href="http://blog.csdn.net/huagong_adu/article/details/40710305" target="_blank" rel="external">Learning To Rank之LambdaMART的前世今生</a>对下面这个图有非常详细的解释。此处对一些重点内容进行摘录。<br><img src="https://ooo.0o0.ooo/2017/09/25/59c8db4cb37ec.png" alt=""><br>如图所示，每个线条表示文档，蓝色表示相关文档，灰色表示不相关文档。<br>RankNet以pairwise error的方式计算cost，左图的cost为13，右图通过把第一个相关文档下调3个位置，第二个文档上条5个位置，将cost降为11，但是像NDCG或者ERR等评价指标只关注top k个结果的排序，在优化过程中下调前面相关文档的位置不是我们想要得到的结果。图 1右图左边黑色的箭头表示RankNet下一轮的调序方向和强度，但我们真正需要的是右边红色箭头代表的方向和强度，即更关注靠前位置的相关文档的排序位置的提升。</p>
<p>LambdaRank正是基于这个思想演化而来，其中Lambda指的就是红色箭头，代表下一次迭代优化的方向和强度，也就是梯度。<br>受LambdaNet的启发，LambdaRank对RankNet的梯度做因式分解：<br><img src="https://i.loli.net/2017/09/25/59c8db76c9652.png" alt=""><br>注意有下面对称性<br><img src="https://i.loli.net/2017/09/25/59c8db85eb3f3.png" alt=""><br><img src="https://i.loli.net/2017/09/25/59c8db9255992.png" alt=""><br>也就是说：<strong>每条文档移动的方向和趋势取决于其他所有与之 label 不同的文档</strong>。<br>现在回过头来看，看看我们做了些什么？</p>
<ul>
<li>分析了梯度的物理意义；</li>
<li>绕开损失函数，直接定义梯度。<br>当然，我们可以反推一下 LambdaRank 的损失函数：<br><img src="https://i.loli.net/2017/09/25/59c8dbaf0603f.png" alt=""> </li>
</ul>
<p><strong>LambdaMART</strong><br>现在的情况变成了这样：</p>
<ul>
<li>MART 是一个框架，缺一个「梯度」；</li>
<li>LambdaRank 定义了一个「梯度」。<br>于是，就有了 LambdaMART：<br><img src="https://i.loli.net/2017/09/25/59c8dbc928934.png" alt=""> </li>
</ul>
<h1 id="Xgboost中的Learning-to-rank">5. Xgboost中的Learning to rank</h1><p>为了后续方便后续小伙伴们的使用，我将官方文档<a href="https://github.com/dmlc/xgboost/tree/master/demo/rank" target="_blank" rel="external">xgboost的learning to rank文档</a>进行扼要的翻译，并在此贴出。<br>Xgboost的rank模型是基于lambdaRank的。<br>XGBoost支持以ranking为目标的学习。在ranking的情况下，数据集一般都需要被格式化为group input：<br>在ranking中，数据是根据不同的真实场景被分为groups的。例如，在学习web pages的rank场景下，rank page数据是根据不同的queries分到各groups的。</p>
<p><strong>数据形式</strong><br><strong>基本数据形式train.txt</strong><br>Xgboost接受像libSVM格式数据，例如：</p>
<pre><code>1 101:1.2 102:0.03
0 1:2.1 10001:300 10002:400
0 0:1.3 1:0.3
1 0:0.01 1:0.3
0 0:0.2 1:0.3
</code></pre><p>每行表示：</p>
<pre><code>label   特征1索引:值 特征2索引:值
</code></pre><p><strong>groups索引文件train.txt.group</strong><br>除了group input format,XGboost需要一个索引group信息的文件，索引文件train.txt.group格式如下：</p>
<pre><code>2
3
</code></pre><p>这意味着，数据集包含5个实例，前两个是一个group，后三个是一个group。</p>
<p><strong>实例权重文件train.txt.weight</strong></p>
<p>XGboost还支持每个实例的权重调整，数据格式如下：</p>
<pre><code>1
0.5
0.5
1
0.5
</code></pre><p><strong>初始margin文件train.txt.base_margin</strong></p>
<p>XGBoost还可以支持每个实例的初始化margin prediction.例如我们对train.txt可以有一个initial margin file:</p>
<pre><code>-0.4
1.0
3.4
</code></pre><p>XGBoost will take these values as initial margin prediction and boost from that. An important note about base_margin is that it should be margin prediction before transformation, so if you are doing logistic loss, you will need to put in value before logistic transformation. If you are using XGBoost predictor, use pred_margin=1 to output margin values.</p>
<p><strong>使用Demo:</strong></p>
<p><a href="https://github.com/stegben/kaggle_outbrain/blob/990f5e1cc18ff0f6156a56b9d919ac0d52222268/train_xgb.py" target="_blank" rel="external">https://github.com/stegben/kaggle_outbrain/blob/990f5e1cc18ff0f6156a56b9d919ac0d52222268/train_xgb.py</a></p>
<p><strong>xgboost的pairwiseRank实现</strong></p>
<p><strong>**如何构造pair对？</strong><br>xgboost/src/objective/rank_obj.cc,75行开始构造pair对。如上理论所说，每条文档移动的方向和趋势取决于其他所有与之 label 不同的文档。因此我们只需要构造不同label的“正向文档对”。其方法主要为:遍历所有的样本，从与本样本label不同的其他label桶中，任意取一个样本，构造成正样本；<br><strong>**如何定义梯度？</strong><br>xgboost/src/objective/rank_obj.cc中，写到了它是使用lambdaWeight.<br>然后将梯度和文档对输入GBDT训练即可。<br><strong>**输出是什么？</strong><br>根据labdaMart原理，输出是模型对每个文档的打分。</p>
<p>#　参考文献</p>
<p><a href="http://www.cnblogs.com/kemaswill/p/3241963.html" target="_blank" rel="external">Learning to Rank之Ranking SVM 简介</a><br><a href="http://www.tuicool.com/articles/yAfiQ3r" target="_blank" rel="external">GBRank:一种基于回归的学习排序算法</a><br><a href="http://mlnote.com/2016/09/18/gbRank-logsitRank-from-up-to-bottom/" target="_blank" rel="external">gbRank &amp; logsitcRank自顶向下</a></p>
]]></content>
      
        <categories>
            
            <category> 机器学习算法 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[深度学习算法-神经网络简介]]></title>
      <url>/2017/09/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E4%BB%8B/</url>
      <content type="html"><![CDATA[<p>所谓神经网络就是将许多个单一“神经元”联结在一起，这样，一个“神经元”的输出就可以是另一个“神经元”的输入。神经网络就是按照一定规则将多个神经元连接起来的网络。</p>
<p><img src="https://i.loli.net/2017/09/05/59aea656bf8da.png" alt=""><br>我们使用圆圈来表示神经网络的输入，标上“+1”的圆圈被称为<strong>偏置节点</strong>，也就是截距项。神经网络最左边的一层叫做<strong>输入层</strong>，最右的一层叫做<strong>输出层</strong>（本例中，输出层只有一个节点）。中间所有节点组成的一层叫做<strong>隐藏层</strong>，因为我们不能在训练样本集中观测到它们的值。同时可以看到，以上神经网络的例子中有3个<strong>输入单元</strong>（偏置单元不计在内），3个<strong>隐藏单元</strong>及一个<strong>输出单元</strong>。</p>
<p>记：<br>$a^{[0]} = X$，表示输入特征，也表示“acitive value”<br>$a^{[1]}$，表示隐藏层的“active value”<br>$a^{[2]} = y^{\text{~}}$，表示输出层</p>
<p>刚才提到的是一种最简单的神经网络，叫<strong>深度前馈(feedforword)网络</strong>，又称前馈神经网络、多层感知机，是典型的深度学习模型。</p>
<p>前馈网络的目标是近似某个函数$f^*(x)$,将输入$x$映射到输出$y$。</p>
<p>而映射$ f(x;\theta)$，并且学习参数$\theta$的值，使它能够得到最佳函数$f^*(x) $的近似。</p>
<p>前馈是因为没有反馈连接。如果有反馈的话，叫循环(recurrent)神经网络。</p>
<p>全连接：第N层的每个神经单元和第N-1层的所有神经元相连。</p>
<h1 id="如何计算神经网络的输出？">1. 如何计算神经网络的输出？</h1><p>首先，我们回顾最简单的LR单元如何计算输出：</p>
<ol>
<li>首先计算$z = w^Tx+b$;</li>
<li>代入激活函数计算$a = a(z)$</li>
<li>得到预测值$a = y^{\text ~}$</li>
</ol>
<p>在神经网络中，我们以此计算每个神经元即可。</p>
<p>为了方便表示，我们先约定符号：<br>$$a_{i\text{&lt;- node index in layer}}^{[j]\text{&lt;- layer index}}$$</p>
<p>上标方括号表示层数；下标表示在本层的第几个node。</p>
<p>因此，在神经网络中，我们计算以下即可：<br><img src="https://i.loli.net/2017/09/06/59afebe9849fe.png" alt=""> </p>
<p>即依次计算z和a即可。</p>
<p>我们将上面的计算过程向量化，得到：<br>$$<br>z^{[1]} =<br>\begin{bmatrix}<br>w_1^{[1]T}\\<br>w_2^{[1]T}\\<br>w_3^{[1]T} \\<br>\end{bmatrix}<br>\begin{bmatrix}<br>x_1\\<br>x_2\\<br>x_3\\<br>\end{bmatrix}<br>+\begin{bmatrix}<br>b_1^{[1]}\\<br>b_2^{[1]}\\<br>b_3^{[1]} \\<br>\end{bmatrix}<br>$$<br>$$=\begin{bmatrix}<br>w_1^{[1]T}x+b_1^{[1]}\\<br>w_2^{[1]T}x+b_2^{[1]}\\<br>w_3^{[1]T}x+b_3^{[1]} \\<br>\end{bmatrix}<br>=\begin{bmatrix}<br>z_1^{[1]}\\<br>z_2^{[1]}\\<br>z_3^{[1]} \\<br>\end{bmatrix}<br>$$</p>
<p>而这一层得到的输出$a$作为下一层的输入$x$</p>
<p>因此在神经网络中，我们按照以下步骤计算：<br><img src="https://i.loli.net/2017/09/06/59aff15c7043c.png" alt=""> </p>
<p>我们将上面的计算步骤叫作<strong>前向传播</strong>。即：给定第$l$层激活值$a^{[l]}$，第$l+1$层的激活值$a^{[l+1]}$可以按照以下步骤得到：<br>$z^{[l+1]} = w^{[l]}a^{[l]}+b^{[l]}$<br>$a^{[l+1]} =  a(z^{[l+1]})$</p>
<h1 id="如何加速多样本计算？">2. 如何加速多样本计算？</h1><p>在上一节中，我们讲到我们的输出是依次计算的。即从$x^{(1)}$到$x^{(m)}$</p>
<p>假设输入样本$X$有m个，那么我们的计算过程为：<br>$x^{(1)} \text{  ———-&gt;  } a^{[l]\text{(1)}} = y^{\text{~(1)}}$<br>…<br>$x^{(i)} \text{  ———-&gt;  } a^{[l]\text{(i)}} = y^{\text{~(i)}}$<br>…<br>$x^{(m)} \text{  ———-&gt;  } a^{[l]\text{(m)}} = y^{\text{~(m)}}$</p>
<p>同样的，我们也可以将这个过程向量化，只需要将m个样本放入一个大矩阵$X$中即可。此处对于我来说较容易理解，故不再多加阐述。</p>
<h1 id="关于激活函数">3. 关于激活函数</h1><p>回顾之前的内容，我们的网络为：</p>
<ol>
<li>计算$z = wx+b$</li>
<li>将$z$代入激活函数$\sigma(z)$得到预测值</li>
</ol>
<p>其中的$\sigma = \frac{1}{1+e^{-z}}$就是sigmod激活函数。当然也有其它的激活函数：</p>
<ol>
<li>$tanh$(在神经网络隐藏层，$tanh$比$\sigma$表现更佳)<br>$tanh(z) = \frac{e^z-e^{-z}}{e^z+e^{-z}}$<br><img src="https://i.loli.net/2017/10/15/59e3657d65b64.png" alt=""> </li>
<li>$ReLU$-修正线性单元，更普遍<br>$a=max(0,z)$<br>学习速度很快</li>
<li>带泄露的ReLU<br>$a=max(0.0001z,z)$<br>z小于零时，函数稍微倾斜一些</li>
</ol>
<h2 id="为什么需要激活函数？">3.1. 为什么需要激活函数？</h2><p>会导致输出结果就是输入特征的线性组合，导致网络并没有什么卵用。</p>
<h1 id="如何计算参数-神经网络的梯度下降法">4. 如何计算参数-神经网络的梯度下降法</h1><h2 id="正向传播">4.1. 正向传播</h2><p>我的理解是：正向传播就是从输入计算输出的过程，也就是我们常说的进行预测。也就是我们现在已经有了一个模型，只需要把输入喂进去，然后得到的输出就是预测值。</p>
<ol>
<li>$z^{[1]}=w^{[1]}x+b^{[1]}$</li>
<li>$A^{[1]}=g^{[1]}(z^{[1]})$该层的激活函数</li>
<li>$z^{[2]}=w^{[2]}A^{[1]}+B^{[2]}$</li>
<li>$A^{[2]}=g^{[2]}(^{[2]})=\sigma(z^{[2]})$</li>
</ol>
<h2 id="反向传播">4.2. 反向传播</h2><p>上述正向传播时我们假设我们已经有了一个模型。但事实上我们应该是已经有了一堆样本想和样本的y，我们想去学习这个模型。那如何进行模型学习呢？就要用到反向传播法，从已知的输出y出发，结合梯度下降，得到一个模型，使得这个模型最符合x的分布。</p>
<p>反向传播算法其实指的是用于计算梯度的方法。而梯度下降是使用这个计算好了的梯度来进行学习的方法。</p>
<p>具体过程的<strong>思想精华：在样本集下，想要得到各层的z=wx+b的参数w和b，使得损失函数L(a,y)最小。用梯度下降法的话，就要沿着$L(a,y)$导数的方向来调节w和b。</strong></p>
<p>关于误差函数$L(a,y)$我会在之后的博客<a href="https://jiayi797.github.io/2017/10/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E8%AF%AF%E5%B7%AE%E5%87%BD%E6%95%B0%E6%8E%A2%E7%A9%B6/" target="_blank" rel="external">误差函数探究</a>里进行叙述。</p>
<p>要计算$L(a,y)$的导数$\frac{dL(a,y)}{da}=-\frac{y}{a} + \frac{1-y}{1-a}$,那么就要计算$dz=\frac{dL}{dz}$，从而要计算$dw=\frac{dL}{dw}$和$db=\frac{dL}{db}$</p>
<ol>
<li>$dz^{[2]}=A^{[2]}-Y,Y=[y^{[1]}],y^{[2]},…,y^{[m]}$</li>
<li>$dw^{[2]}=\frac{1}{m}dz^{[2]}A^{[1]T}$</li>
<li>$db^{[2]}=\frac{1}{m}sum(dz^{[2]},axis=1,keepdims=True)$</li>
<li>$dz^{[1]}=w^{[2]T}dz^{[2]} \times g^{[1]’}(z^{[1]})$</li>
<li>$dw^{[1]}=\frac{1}{m}dz^{[1]}X^T$</li>
<li>$db^{[1]}=\frac{1}{m}np.sum(dz^{[1]},axis=1,keepdims=True)$</li>
</ol>
<h1 id="参考文献">5. 参考文献</h1><ol>
<li>[吴恩达，deepLearning.ai]</li>
<li><a href="http://ufldl.stanford.edu/wiki/index.php/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C" target="_blank" rel="external">神经网络</a></li>
<li><a href="http://www.jianshu.com/p/d161a22a0292" target="_blank" rel="external">不会停的蜗牛，什么是神经网络</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 深度学习算法 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Java学习笔记4-泛型数组列表(ArrayList)]]></title>
      <url>/2017/09/04/Java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04-%E6%B3%9B%E5%9E%8B%E6%95%B0%E7%BB%84%E5%88%97%E8%A1%A8/</url>
      <content type="html"><![CDATA[<p>ArrayList : 是一个采用类型参数(type parameter)的泛型类(generic class)（泛型类指数组内的元素可以是任意类型）。</p>
<p>新建：</p>
<pre><code>ArrayList&lt;Employee&gt; staff = new ArrayList&lt;Employee&gt;();
</code></pre><p>增：</p>
<pre><code>add();
</code></pre><p>若调用add且内部数组已经满了，数组列表就自动地创建一个更大的数组，并将所有的对象从较小的数组中拷贝到较大的数组中。</p>
<p>指定数组大小：</p>
<pre><code>test.ensureCapacity(100);
</code></pre><p>或</p>
<pre><code>ArrayList&lt;Employee&gt; staff = new ArrayList&lt;&gt;(100);
</code></pre><p>一旦确定数组大小不再发生变化，即可调用<code>trimeToSize</code>方法，使得存储区域的大小调整为当前元素数量所需的存储空间数目。垃圾回收器将回收多余的存储空间。</p>
<p>其它操作：</p>
<pre><code>get(index);
set(index,element);
add(index,element);
remove(index);
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[深度学习算法-引言-LR的梯度下降法]]></title>
      <url>/2017/09/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E5%BC%95%E8%A8%80-LR%E7%9A%84%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/</url>
      <content type="html"><![CDATA[<p>本节是吴恩达老师在deepLearning.ai第二周课程的笔记。</p>
<p>本节以逻辑回归的梯度下降法为例，讲了我们究竟如何使用梯度下降法。</p>
<h1 id="LR的梯度下降">1. LR的梯度下降</h1><p>在LR中，我们想要得到z=wx+b，并且这个z在样本上，损失函数L(a,y)最小。那么，我们可以不断地改变w和b，找到一个合适的w和b，达到我们上述的目的。</p>
<p><img src="https://i.loli.net/2017/09/04/59acd4eac78da.png" alt=""> </p>
<p>如何改变w和b，能更快地得到最优的w和b呢？那么我们就要使用梯度下降法。<br><img src="https://i.loli.net/2017/09/04/59acd39e1a9ea.png" alt=""> </p>
<p>上图中，从左到右的计算过程就是前向传播法。</p>
<p>一般来说，我们都用后向传播法来计算这个过程：</p>
<p>在单个样本中，<br>想要计算$L(a,y)$的导数:</p>
<ol>
<li>先向前一步，计算损失函数$L(a,y)$关于$a$的导数$da = \frac{dL(a,y)}{da} = -\frac{y}{a} + \frac{1-y}{1-a}$。</li>
<li>再向前一步，计算$dz = \frac{dL}{dz} = a - y$</li>
<li>再向前一步，计算$dw = \frac{dL}{dw} = …, db = ..$</li>
<li>用 $ w = w - \lambda dw,b = b - \lambda db$</li>
</ol>
<p>在m个训练集中，<br>$J(w,b) = \frac{1}{m} \sum{_i^m L(a^{(i)},y^{(i)})}$<br>那么：<br>$\frac{d(J(w,b))}{w1} = \frac{1}{m}\sum_i^m\frac{d(L(w^{(i)},y^{(i)}))}{w_i}$</p>
<p>也就是说，m个训练样本的损失函数的导数 = 每个训练样本损失函数导数的均值</p>
<p>伪代码：</p>
<pre><code>J = 0; dw1 = 0; dw2 = 0 ; db = 0;
for i = 1 to m :
    z = w1x1[i] + w2x2[i] + b ;
    y = sigmod(z) ;
    a = get(i) ;
    J += ylog(a) + (1-y)log(1-a);
    dz = a - y; # 先算dz
    dw1+= x1dz; # 后算dw,db
    dw2 += x2dz;
    db+= dz;
J/= m;
dw1 /= m;
dw2 /= m;
db /= m; 
</code></pre><p>此时就已经得到了全部样本的dw1,dw2,db,J</p>
<p>然后应用梯度下降：</p>
<pre><code>w1 = w1 - sdw1
w2 = w2 - sdw2
b = b - sb
</code></pre><p>其中，s是步长。</p>
<h1 id="向量化">2. 向量化</h1><p>一般来说，for循环是很不好的。可以使用向量化来摆脱for循环，加速运算。接下来我们来讲一讲向量化。</p>
<p>一般来说，如果我们想计算$z = w^T x + b$,其中，w和x都是一个n维的列向量。在非向量化实现中，我们会用：</p>
<pre><code>z = 0;
for i in range(n):
    z += w[i]*x[i];
z += b ;
</code></pre><p>在向量化（例如numpy中），我们用：</p>
<pre><code>z = np.dot(w,x) + b
</code></pre><p>向量运算非常快（主要原因是并行运算）。因此我们尽量将loop运算转换为向量运算。</p>
<h1 id="向量化的LR">3. 向量化的LR</h1><p>x是m维向量</p>
<pre><code>import numpy as np
J = 0; dw1 = 0; dw2 = 0 ; db = 0;
z = np.dot(w.T,x) + b; # m维列向量
y = sigmod(z) ;# m维列向量
a = label;# m维列向量
J = np.dot(y.T,log(a)) + np.dot((1-y).T,log(1-a));
J/= m;
dz = a - y; # 先算dz
dw1 = np.dot(x1.T,dz) /m ; # 后算dw,db
dw2 = np.dot(x2.T,dz) /m ;
db= np.sum(dz) /m ;
</code></pre><p>然后应用梯度下降：</p>
<pre><code>w1 = w1 - sdw1
w2 = w2 - sdw2
b = b - sb
</code></pre><h1 id="总结">4. 总结</h1><p>这一节主要讲了我们如何将梯度下降法应用到LR中，以及强调了Nuppy。应该只是为了后续的学习做一些准备。</p>
]]></content>
      
        <categories>
            
            <category> 深度学习算法 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[机器学习算法-初识Learning to Rank]]></title>
      <url>/2017/08/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E5%88%9D%E8%AF%86Learning-to-Rank/</url>
      <content type="html"><![CDATA[<p>本文主要对排序模型做一个简要的整理。首先介绍了一些传统的排序模型，然后介绍比较新的learning to rank.</p>
<p>要想了解L2R，首先我们要了解一下传统的排序模型。</p>
<h1 id="传统的排序模型">1. 传统的排序模型</h1><p>传统的排序模型主要分为两类：相关度排序模型和重要性排序模型。</p>
<h2 id="相关度排序模型-Relevance-Ranking-Model">1.1. 相关度排序模型(Relevance Ranking Model)</h2><p>相关度排序模型根据查询和文档之间的相似度来对文档进行排序。常用的模型包括：布尔模型(Boolean Model)，向量空间模型(Vector Space Model)，隐语义分析(Latent Semantic Analysis)，BM25，LMIR模型等等。</p>
<p>相关度排序模型主要用在查询（例如搜索引擎）上，它主要是要计算【关键字】与【文档】之间的相关性，给出【关于关键字】的排序。</p>
<h2 id="重要性排序模型-Importance-Ranking-Model">1.2. 重要性排序模型(Importance Ranking Model)</h2><p>重要性排序模型就不考虑上述提到的【查询】，而仅仅根据网页(亦即文档)之间的图结构来判断文档的权威程度，典型的权威网站包括Google，Yahoo!等。常用的模型包括PageRank，HITS，HillTop，TrustRank等等。</p>
<h2 id="传统排序模型的缺陷">1.3. 传统排序模型的缺陷</h2><p>以上的这些传统的排序模型，单个模型往往只能考虑某一个方面(相关度或者重要性)，所以只是用单个模型达不到要求。搜索引擎通常会组合多种排序模型来进行排序，但是，如何组合多个排序模型来形成一个新的排序模型，以及如何调节这些参数，都是一个很大的问题。</p>
<p>因此，伟大的科学家们提出了Learning to Rank，来解决上述问题。</p>
<h1 id="Learning-to-Rank">2. Learning to Rank</h1><p>Learning to Rank是一种机器学习模型。它使用机器学习的方法，我们可以把各个现有排序模型的【输出作为特征】，然后训练一个新的模型，并自动学得这个新的模型的参数，从而很方便的可以组合多个现有的排序模型来生成新的排序模型。</p>
<h1 id="L2R特征的选取">3. L2R特征的选取</h1><p>与文本分类不同，L2R考虑的是【给定查询的文档集合的排序】。所以，L2R用到的特征不仅仅包含文档d本身的一些特征(比如是否是Spam)等，也包括文档d和给定查询q之间的相关度，以及文档在整个网络上的重要性(比如PageRank值等)，亦即我们可以使用相关性排序模型和重要性排序模型的输出来作为L2R的特征。</p>
<p>总结来说，L2R的特征有以下两点：</p>
<ol>
<li>传统排序模型的输出，既包括相关性排序模型的输出f(q,d)，也包括重要性排序模型的输出。</li>
<li>文档本身的一些特征，比如是否是Spam等。</li>
</ol>
<h1 id="L2R训练数据的构造">4. L2R训练数据的构造</h1><p>L2R的训练数据可以有三种形式：</p>
<ol>
<li>对于每个查询，各个文档的绝对相关值(非常相关，比较相关，不相关，等等)；</li>
<li>对于每个查询，两两文档之间的相对相关值(文档1比文档2相关，文档4比文档3相关，等等)；</li>
<li>对于每个查询，所有文档的按相关度排序的列表(文档1&gt;文档2&gt;文档3)。</li>
</ol>
<p>这三种形式的训练数据之间可以相互转换，详见[1]。</p>
<p>训练数据的获取有两种主要方法：人工标注[3]和从日志文件中挖掘[4]:</p>
<p>人工标注：首先从搜索引擎的搜索记录中随机抽取一些查询，将这些查询提交给多个不同的搜索引擎，然后选取各个搜索引擎返回结果的前K个，最后由专业人员来对这些文档按照和查询的相关度进行标注。</p>
<p>从日志中挖掘：搜索引擎都有大量的日志记录用户的行为，我们可以从中提取出L2R的训练数据。Joachims提出了一种很有意思的方法[4]：给定一个查询，搜索引擎返回的结果列表为L，用户点击的文档的集合为C，如果一个文档di被点击过，另外一个文档dj没有被点击过，并且dj在结果列表中排在di之前，则di&gt;dj就是一条训练记录。亦即训练数据为：{di&gt;dj|di属于C，dj属于L-C，p(dj) &lt; p(di)}，其中p(d)表示文档d在查询结果列表中的位置，越小表示越靠前。</p>
<h1 id="L2R模型训练">5. L2R模型训练</h1><p>L2R是一个有监督学习过程。</p>
<p>对与每个给定的查询-文档对(query document pair)，抽取相应的特征(既包括查询和文档之间的各种相关度，也包括文档本身的特征以及重要性等)，另外通过或者人工标注或者从日志中挖掘的方法来得到给定查询下文档集合的真实序列。然后我们使用L2R的各种算法来学到一个排序模型，使其输出的文档序列和真实序列尽可能相似。</p>
<h1 id="L2R算法分类和简介">6. L2R算法分类和简介</h1><p>L2R算法主要包括三种类别：PointWise，PairWise，ListWise。</p>
<h2 id="PointWise-L2R">6.1. PointWise L2R</h2><p><strong>pointwise简介</strong><br>PointWise方法只考虑【给定查询下】，单个文档的绝对相关度，而不考虑其他文档和给定查询的相关度。亦即给定查询q的一个真实文档序列，我们只需要考虑【单个文档di和该查询的相关程度ci】，亦即输入数据应该是如下的形式：<br><img src="https://i.loli.net/2017/08/30/59a69397eeec7.png" alt=""> </p>
<p>一种思想是将query与doc之间的相关程度作为标签，比如标签有三档，问题就变为多类分类问题,模型有McRank,svm，最大熵等。另一种思想是将query与doc之间的相关程度作为分数利用回归模型拟合，经典回归模型有线性回归，dnn，mart等。</p>
<p><strong>pointwise形式</strong><br>输入：doc 的特征向量<br>输出：每个doc的相关性分数<br>损失函数: 回归loss，分类loss，有序回归loss</p>
<p><strong>pointwise常用算法</strong><br>Pointwise方法主要包括以下算法：Pranking (NIPS 2002), OAP-BPM (EMCL 2003), Ranking with Large Margin Principles (NIPS 2002), Constraint Ordinal Regression (ICML 2005)。</p>
<p><strong>pointwise特点</strong><br>Pointwise方法仅仅使用传统的分类，回归或者Ordinal Regression方法来对给定查询下单个文档的相关度进行建模。这种方法没有考虑到排序的一些特征，比如文档之间的排序结果针对的是给定查询下的文档集合，而Pointwise方法仅仅考虑单个文档的绝对相关度；另外，在排序中，排在最前的几个文档对排序效果的影响非常重要，Pointwise没有考虑这方面的影响。</p>
<h2 id="PairWise">6.2. PairWise</h2><p><strong>pairwise简介</strong><br>Pairwise方法考虑给定查询下，【两个文档之间】的相对相关度。亦即给定查询q的一个真实文档序列，我们只需要考虑任意两个相关度不同的文档之间的相对相关度：di&gt;dj，或者di &lt; dj 。</p>
<p><strong>pairwise原理</strong><br>Pairwise的方法是将文档组成文档对，不单考虑单个文档，而是考虑文档组对是否合理，比如对于query 1返回的三个文档 doc1，doc2，doc3, 有三种组对方式，<doc1,doc2>,<doc2,doc3>,<doc1,doc3>。当三个文档原来的label为3,4,2时，这样组对之后的三个例子就有了新的分数（表达这种顺序是否合理），可以利用这种数据进行分类学习，模型如SVM Rank, 还有RankNet(C. Burges, et al. ICML 2005)， FRank(M.Tsai, T.Liu, et al. SIGIR 2007)，RankBoost(Y. Freund, et al. JMLR 2003)。</doc1,doc3></doc2,doc3></doc1,doc2></p>
<p>参考文献<a href="http://www.javashuo.com/content/p-5980716.html" target="_blank" rel="external">机器学习排序之Learning to Rank简单介绍</a>对pairwise方法做出了比较容易理解的介绍：<br>文档对方法（parwise）则将重点转向量对文档顺序关系是否合理进行判断。<br>之所以被称为文档对方法，是因为这种机器学习方法的训练过程和训练目标，是判断任意两个文档组成的文档对<d0c1，d0c2>是否满足顺序关系，即判断是否D0C1应该排在DOC2的前面。图3展示了一个训练实例：査询Q1对应的搜索结果列表如何转换为文档对的形式，因为从人工标注的相关性得分可以看出，D0C2得分最高，D0C3次之，D0C1得分最低，于是我们可以按照得分大小顺序关系得到3个如图3所示的文档对，将每个文档对的文档转换为特征向量后，就形成了一个具体的训练实例。【备注：根据我的理解，下图有了一些错误。doc1分数应该为3，doc2分数应该为5】。<br><img src="https://ooo.0o0.ooo/2017/08/30/59a69437ecc6a.png" alt=""><br>                         图3  文档对的方法训练实例</d0c1，d0c2></p>
<p>根据转换后的训练实例，就可以利用机器学习方法进行分类函数的学习，具体的学习方法有很多，比如SVM. Boosts、神经网络等都可以作为具体的学习方法，但是不论具体方法是什么，其学习目标都是一致的，即输入- 个査询和文档对<docl，doc2>, 机器学习排序能够判断这种顺序关系是否成立，如果成立，那么在搜索结果中D0C1应该排在D0C2 前面，否则Doe2应该摔在Docl前面，通过这种方式，就完成搜索结果的排序任务。</docl，doc2></p>
<p>那么，<strong>如何将排序问题转化为机器学习能够学习的分类问题呢？</strong></p>
<p>参考文献<a href="http://www.cnblogs.com/kemaswill/p/3241963.html" target="_blank" rel="external">Learning to Rank之Ranking SVM 简介</a>给出了一个很好的例子解释这个问题：给定查询q, 文档d1&gt;d2&gt;d3(亦即文档d1比文档d2相关, 文档d2比文档d3相关, x1, x2, x3分别是d1, d2, d3的特征)。为了使用机器学习的方法进行排序，我们将排序转化为一个分类问题。我们定义新的训练样本, 令x1-x2, x1-x3, x2-x3为正样本,令x2-x1, x3-x1, x3-x2为负样本, 然后训练一个二分类器(支持向量机)来对这些新的训练样本进行分类，如下图所示:<br><img src="https://i.loli.net/2017/08/30/59a694b19797c.png" alt=""><br>左图中每个椭圆代表一个查询, 椭圆内的点代表那些要计算和该查询的相关度的文档, 三角代表很相关, 圆圈代表一般相关, 叉号代表不相关。我们把左图中的单个的文档转换成右图中的文档对(di, dj), 实心方块代表正样本, 亦即di&gt;dj, 空心方块代表负样本, 亦即di &lt; dj。将【排序问题转化为分类问题】之后, 我们就可以使用常用的机器学习方法解决该问题。</p>
<p><strong>pairwise存在的问题</strong></p>
<p>尽管文档对方法相对单文档方法做出了改进，但是这种方法也存在两个明显的问题：</p>
<p>一个问题是：文档对方法只考虑了两个文档对的相对先后顺序，却没有考虑文档出现在搜索列表中的位置，排在搜索站果前列的文档更为重要，如果前列文档出现判断错误，代价明显高于排在后面的文档。针对这个问题的改进思路是引入代价敏感因素，即每个文档对根据其在列表中的顺序具有不同的权重，越是排在前列的权重越大，即在搜索列表前列如 果排错顺序的话其付出的代价更高?</p>
<p>另外一个问题是：不同的査询，其相关文档数量差异很大，所以转换为文档对之后， 有的查询对能有几百个对应的文档对，而有的查询只有十几个对应的文档对，这对机器学习系统的效果评价造成困难 ?我们设想有两个查询，査询Q1对应500个文文档对，查询Q2 对应10个文档对，假设学习系统对于査询Ql的文档对能够判断正确480个，对于査询 Q2的义格对能够判新正确2个，如果从总的文档对数量来看，这个学习系统的准确率是 (480+2)/（500+10）=0.95.即95%的准确率，但是从査询的角度，两个査询对应的准确率 分别为：96%和20%,两者平均为58%,与纯粹从文档对判断的准确率相差甚远，这对如何继续调优机器学习系统会带来困扰。</p>
<h2 id="ListWise（文档列表方法）">6.3. ListWise（文档列表方法）</h2><p><strong>listwise简介</strong><br>单文档方法将训练集里每一个文档当做一个训练实例，文档对方法将同一个査询的搜索结果里任意两个文档对作为一个训练实例。与Pointwise和Pairwise方法不同，文档列表方法与上述两种表示方式不同，是将每一个查询对应的【所有搜索结果列表整体】作为一个训练实例，这也是为何称之为文档列表方法的原因。</p>
<p><strong>listwise原理</strong><br>文档列表方法根据K个训练实例（一个査询及其对应的所有搜索结果评分作为一个实 例）训练得到最优评分函数F， 对于一个新的用户査询，函数F 对每一个文档打分，之后按照得分顺序由高到低排序，就是对应的搜索结果。 </p>
<p>所以关键问题是：<strong>拿到训练数据，如何才能训练得到最优的打分函数？</strong></p>
<p>这里介绍一种训练方法，它是基于搜索结果排列组合的概率分布情况来训练的，图4是这种方式训练过程的图解示意。<br><img src="https://i.loli.net/2017/08/30/59a6951348a74.png" alt=""><br>            图4 不同评分函数的KL距离</p>
<p>首先解释下什么是搜索结果排列组合的概率分布，我们知道，对于搜索引擎来说，用户输入査询Q， 搜索引擎返回搜索结果，我们假设搜索结果集合包含A、B和C 3个文档，搜索引擎要对搜索结果排序，而这3个文档的顺序共有6种排列组合方式:</p>
<p>ABC, ACB, BAG, BCA, CAB和CBA,</p>
<p>而每种排列组合都是一种可能的搜索结果排序方法。</p>
<p>对于某个评分函数F来说，对3个搜索结果文档的相关性打分，得到3个不同的相关度得分F(A)、F(B)和F(C)，根据这3个得分就可以计算6种排列组合情况各自的概率值。</p>
<p>不同的评分函数，其6种搜索结果排列组合的概率分布是不一样的。</p>
<p>了解了什么是搜索结果排列组合的概率分布，我们介绍如何根据训练实例找到最优的评分函数。图4展示了一个具体的训练实例，即査询Q1及其对应的3个文档的得分情况，这个得分是由人工打上去的，所以可以看做是标准答案。</p>
<p>可以设想存在一个最优的评分函数g，对查询Q1来说，其打分结果是：A文档得6分，B文档得4分，C文档得3分， </p>
<p>因为得分是人工打的，所以具体这个函数g是怎样的我们不清楚，我们的任务就是找到一 个函数，使得函数对Ql的搜索结果打分顺序和人工打分顺序尽可能相同。既然人工打分 (虚拟的函数g) 已知，那么我们可以计算函数g对应的搜索结果排列组合概率分布，其具体分布情况如图4中间的概率分布所示。</p>
<p>假设存在两个其他函数h和f，它们的计算方法已知，对应的对3个搜索结果的打分在图上可以看到，由打分结果也可以推出每个函数对应的搜索结果排列组合概率分布，那么h与f哪个与虚拟的最优评分函数g更接近呢？</p>
<p>一般可以用两个分布概率之间的距离远近来度量相似性，KL距离就是一种衡量概率分布差异大小的计算工具，通过分别计算h与g的差异大小及f与g的差异大小，可以看出f比h更接近的最优函数g，那么在这个函数中，我们应该优先选f作为将来搜索可用的评分函数，训练过程就是在可能的函数中寻找最接近虚拟最优函数g的那个函数作为训练结果，将来作为在搜索时的评分函数。</p>
<p>上述例子只是描述了对于单个训练实例如何通过训练找到最优函数，事实上我们有K 个训练实例，虽然如此，其训练过程与上述说明是类似的，可以认为存在一个虚拟的最优 评分函数g(实际上是人工打分），训练过程就是在所有训练实例基础上，探寻所有可能的 候选函数，从中选择那个KL距离最接近于函数g的，以此作为实际使用的评分函数。 经验结果表明，基于文档列表方法的机器学习排序效果要好于前述两种方法。</p>
<p><strong>常用算法</strong><br>Listwise算法主要包括以下几种算法：LambdaRank (NIPS 2006), AdaRank (SIGIR 2007), SVM-MAP (SIGIR 2007), SoftRank (LR4IR 2007), GPRank (LR4IR 2007), CCA (SIGIR 2007), RankCosine (IP&amp;M 2007), ListNet (ICML 2007), ListMLE (ICML 2008) 。</p>
<p>相比于Pointwise和Pairwise方法，Listwise方法直接优化给定查询下，整个文档集合的序列，所以比较好的解决了克服了以上算法的缺陷。Listwise方法中的LambdaMART(是对RankNet和LambdaRank的改进)在Yahoo Learning to Rank Challenge表现出最好的性能。</p>
<h1 id="参考文献">7. 参考文献</h1><p>[1]. Learning to Rank for Information Retrieval. Tie-yan Liu.<br>[2]. Learning to Rank for Information Retrieval and Natural Language Processing. Hang Li.<br>[3]. A Short Introduction to Learning to Rank. Hang Li.<br>[4]. Optimizing Search Engines using Clickthrough Data. Thorsten Joachims. SIGKDD,2002.<br>[5]. Learning to Rank小结</p>
<ol>
<li><a href="http://www.cnblogs.com/kemaswill/archive/2013/06/01/3109497.html" target="_blank" rel="external">Learning to Rank 简介</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/26221188" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/26221188</a></li>
<li><a href="http://www.javashuo.com/content/p-5980716.html" target="_blank" rel="external">机器学习排序之Learning to Rank简单介绍</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 机器学习算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> L2R </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[数据库常用语句]]></title>
      <url>/2017/07/25/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%B8%B8%E7%94%A8%E8%AF%AD%E5%8F%A5/</url>
      <content type="html"><![CDATA[<h1 id="启动-关闭">1. 启动/关闭</h1><ul>
<li>启动：<code>sudo systemctl start mysqld</code>或<code>mysql -u root -p</code></li>
<li>查看状态：<code>sudo systemctl status mysqld</code></li>
</ul>
<h1 id="linux下执行sql脚本">2. linux下执行sql脚本</h1><p>进入到mysql后，执行<code>source /路径/tester.sql;</code>即可</p>
<h1 id="databases操作">3. databases操作</h1><ul>
<li>列出所有数据库：<code>SHOW DATABASES;</code></li>
<li>创建数据库：<code>CREATE DATABASE database_name;</code></li>
<li>进入某数据库：<code>USE database_name;</code></li>
</ul>
<h1 id="tables操作">4. tables操作</h1><ul>
<li>列出所有表：<code>SHOW TABLES;</code></li>
<li><p>创建表：</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">CREATE TABLE 表名称</div><div class="line">(</div><div class="line">列名称1 数据类型,</div><div class="line">列名称2 数据类型,</div><div class="line">列名称3 数据类型,</div><div class="line">....</div><div class="line">)</div></pre></td></tr></table></figure>
</li>
<li><p>输出表头：<code>SHOW COLUMNS FROM Table_name;</code></p>
</li>
</ul>
<h1 id="MYSQL数据类型">5. MYSQL数据类型</h1><p><a href="http://www.runoob.com/mysql/mysql-data-types.html" target="_blank" rel="external">MySQL 数据类型</a></p>
<h1 id="参考文献">6. 参考文献</h1><ol>
<li><a href="http://www.centoscn.com/mysql/2016/0315/6844.html" target="_blank" rel="external">CentOS 7 安装 MySQL</a></li>
<li><a href="http://www.2cto.com/database/201210/164243.html" target="_blank" rel="external">linux下执行mysql的sql文件</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[推荐系统初探]]></title>
      <url>/2017/07/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%88%9D%E6%8E%A2/</url>
      <content type="html"><![CDATA[<p>推荐系统根据用户过去的购买和搜索历史，以及其他用户的行为，自主地为各个用户识别推荐内容。</p>
<p>常见的推荐系统有以下几类：</p>
<ul>
<li>协同过滤推荐</li>
<li>基于内容的推荐</li>
<li>混合推荐</li>
</ul>
<p>参考文献<a href="https://www.zhihu.com/question/19971859" target="_blank" rel="external">协同过滤和基于内容推荐有什么区别？</a>给出了一个很好的例子，来区分协同过滤和内容推荐：<br>举个简单的小例子，我们已知道：<br>用户u1喜欢的电影是A，B，C<br>用户u2喜欢的电影是A, C, E, F<br>用户u3喜欢的电影是B，D</p>
<p>我们需要解决的问题是：决定对u1是不是应该推荐F这部电影</p>
<p>基于内容的做法：要分析F的特征和u1所喜欢的A、B、C的特征，需要知道的信息是A（战争片），B（战争片），C（剧情片），如果F（战争片），那么F很大程度上可以推荐给u1，这是基于内容的做法，你需要对item进行特征建立和建模。</p>
<p>协同过滤的办法：那么你完全可以忽略item的建模，因为这种办法的决策是依赖user和item之间的关系，也就是这里的用户和电影之间的关系。我们不再需要知道ABCF哪些是战争片，哪些是剧情片，我们只需要知道用户u1和u2按照item向量表示，他们的相似度比较高，那么我们可以把u2所喜欢的F这部影片推荐给u1</p>
<p>下面我们对这几种推荐算法进行简介。</p>
<h1 id="协同过滤推荐算法">1. 协同过滤推荐算法</h1><h2 id="简介">1.1. 简介</h2><p><strong>简介</strong>：通过在用户的一系列行为中寻找特定模式来产生用户特殊推荐。<br><strong>输入</strong>：仅仅依赖于惯用数据（例如评价、购买、下载等用户偏好行为）。<br><strong>方式</strong>：可通过单个用户行为单独构造模型；也可以通过其他用户行为，使用群组知识并基于相似用户来形成推荐内容。<br><strong>类型</strong>：</p>
<ul>
<li>基于领域的协同过滤（user-based或item-based）</li>
<li>基于模型的协同过滤（矩阵因子分解、受限玻尔兹曼机、贝叶斯网络等等）</li>
</ul>
<h2 id="实例">1.2. 实例</h2><p>为了更好地理解，我们以博客推荐为例。<br>已知用户已订阅并阅读博客的信息，可以根据用户偏好来对他们进行分组。例如可以将阅读多篇相同博客的用户分到一个组。基于组信息，可识别出该组阅读了哪些最流行的博客，然后对于群组中的某个用户，可以向他推荐他还未阅读也未订阅的最流行的博客。</p>
<ol>
<li>在下图的表中，行是一组博客，列是用户，表是该用户阅读该文章的数量。</li>
<li>通过根据用户的阅读习惯来为用户划分集群。比如使用一个 nearest-neighbor 算法：找到与当前用户user口味相近的k各用户；对用户u没有见过的博客p，利用k个近邻对p进行预测评分。</li>
<li>用以上算法我们得到两个分别包含两个用户的cluster，每个cluster中的成员都有相似的阅读习惯：Marc 和 Elise（他们都阅读了多篇关于 Linux® 和云计算的文章）形成 Cluster 1。Cluster 2 中包含 Megan 和 Jill，他们都阅读了多篇关于 Java™ 和敏捷性的文章。</li>
</ol>
<p><img src="https://i.loli.net/2017/07/16/596ae56897d11.png" alt=""> </p>
<h2 id="nearest-nerghbor算法">1.3. nearest-nerghbor算法</h2><p>刚才说到了用nearest-nerghbor算法来计算user-based的user相似度，然后再进行推荐，那么就带来了两个问题：</p>
<ul>
<li>如何度量user之间的相似性？</li>
<li><p>如何推荐博客？</p>
</li>
<li><p>首先解决第一个问题，<strong>如何度量相似性？</strong></p>
</li>
</ul>
<p>先说<strong>结论：采用改进的余弦相似度来进行度量。</strong></p>
<p>首先我们看一下Pearson相关系数和余弦相似度。<br>pearson相关系数用来描诉两组向量一同变化的趋势，取值从+1（强正相关）到-1（强负相关）。用户a和用户b的相似度：<br><img src="https://i.loli.net/2017/07/16/596af2f5cba54.png" alt=""><br>其中：</p>
<ul>
<li>$r_{a,p}$表示用户a对博客p的阅读量；</li>
<li>$\overline{r_a}$表示用户a的平均阅读量；</li>
<li>pearson相关系数越接近于1，那么用户a、b月相似。</li>
</ul>
<p>然而，这并不完美，pearson相关系数存在以下缺陷：</p>
<ul>
<li>未考虑博客的数量对相似度的影响；<br>例如：用户a与b有两个重叠项，用户a与c有10个重叠项；但有可能出现$sim(a,c)&lt; sim(a,b)$的情况，因为计算pearson系数时，重叠项的个数没有影响。但这并不能说明用户b更与a相似。</li>
<li>如果只有一个重叠项，或所有重叠项的评分都相等，就无法计算pearson相关系数（分子或分母为0）。</li>
</ul>
<p>接下来我们看看另一种相似度度量方式——<strong>余弦相似度</strong>。<br><img src="https://i.loli.net/2017/07/16/596b1d46cc650.png" alt=""><br>这代表两个user向量的夹角。但这与向量的大小无关，因此伟大的科学家们提出了<strong>改进的余弦相似度</strong>：<br><img src="https://i.loli.net/2017/07/16/596b1d9a7a066.png" alt=""><br>它的取值范围在$[-1,1]$。</p>
<ul>
<li>接下来我们来解决第二个问题，<strong>如何推荐博客？</strong></li>
</ul>
<p>先选取k个用户的近邻，利用这k个近邻的阅读排行来做推荐。</p>
<p>其实，这个方法是基于user-based的。它并不是完美的。有两个问题：数据稀疏（用户看过的博客非常少）和算法复杂度高。而这两个问题可以通过item-based方法来解决。具体内容见参考文献<a href="http://www.chongchonggou.com/g_60592064.html" target="_blank" rel="external">基于物品的协同过滤推荐算法——读“Item-Based Collaborative Filtering Recommendation Algorithms”</a></p>
<h2 id="协同过滤的方法">1.4. 协同过滤的方法</h2><p>上面提到的方法是<strong>基于领域（记忆）的方法</strong>，而还有一类叫<strong>基于模型的方法——即隐语义模型</strong>。矩阵分解就是实现隐语义模型的成果实现。参考文献<a href="http://baogege.info/2014/10/19/matrix-factorization-in-recommender-systems/" target="_blank" rel="external">个性化推荐中的矩阵分解技术</a>给出了矩阵分解的方法。<br>矩阵分解的核心思想认为用户的兴趣只受少数几个因素的影响，因此将稀疏且高维的User-Item评分矩阵分解为两个低维矩阵，即通过User、Item评分信息来学习到的用户特征矩阵P和物品特征矩阵Q，通过重构的低维矩阵预测用户对产品的评分。</p>
<h1 id="基于内容的推荐">2. 基于内容的推荐</h1><p>基于内容的推荐是指根据用户的行为来推荐内容。</p>
<p><strong>基于内容推荐的过程：</strong></p>
<ul>
<li>item Representation:为每个item抽取特征（也就是item的内容）来表示item;</li>
<li>Profile Learning:利用用户过去喜欢（及不喜欢）的item的特征数据，来学习出此用户的喜好特征(profile)；</li>
<li>Recommendation Generation:通过比较上一步得到的用户profile与候选item的特征，为此用户推荐一组相关性最大的item。</li>
</ul>
<p>上面三个步骤有一张很细致的流程图（第一步对应着Content Analyzer，第二步对应着Profile Learner，第三步对应着Filtering Component）：<br><img src="https://i.loli.net/2017/07/16/596b2b6a02c0e.png" alt=""><br>举个例子，对于博客推荐来说，一个item就是一篇博客；</p>
<ul>
<li>第一步，首先从文章内容中抽取文章的特征。常用算法就是利用这篇文章的关键词来代表这篇文章，而每个词对应的权重往往使用tf-idf来计算。利用这种方法，将一篇文章用一个向量来表示即可；</li>
<li>第二步，根据用户过去喜好来刻画用户profile。最简单的方法可以把用户所有喜欢的文章对应的向量的平均值作为此用户的profile。比如某个用户经常关注与推荐系统有关的文章，那么他的profile中“CB”、“CF”和“推荐”对应的权重值就会较高。</li>
<li>第三步，利用所有item与用户profile的相关度进行推荐。一个常用的相关度计算方法是向量的cos夹角。最终把候选item里与此用户最相关（cosine值最大）的N个item作为推荐返回给此用户。</li>
</ul>
<p>接下来我们来详细了解一下以上三个步骤。</p>
<h2 id="item-representation">2.1. item representation</h2><p>想用属性来描述item时，我们会遇到两种属性：</p>
<ul>
<li>结构化(structured)属性：取值固定，例如身高、学历、籍贯等；</li>
<li>非结构化(unstructured)属性：如文章；</li>
</ul>
<p>接下来我们针对如何将非结构化的属性转化为结构化属性。我们采用最常用的<strong>向量空间模型</strong>（Vector Space Model,简称VSM）：<br>已知：</p>
<ul>
<li>所有文章集合$D={d_1,d_2,…,d_N}$</li>
<li>所有文章中出现的词的集合$T={t_1,t_2,…,t_n}$</li>
</ul>
<p>目标：用向量表示文章：</p>
<ul>
<li>第j篇文章被表示为$d_j={w_{1j},w_{2j},…,w_{nj}}$,其中$w_{nj}$表示第$n$个词在文章$j$中的权重。</li>
</ul>
<p>最简单的表示权重$w_{nj}$的方式是直接统计出现次数。但一般来说我们还是使用tf-idf：<br>$$TFIDF(t_k,d_j)=TF(t_k,d_j)log \frac{N}{n_k}$$<br>其中：</p>
<ul>
<li>$TF(t_k,d_j)$是词频，表示第$k$个词在文章$j$中出现的次数；</li>
<li>$log \frac{N}{n_k}$是逆文档词频，其中$n_k$是所有文章中包括第$k$个词的文章数量；$N$是文章数量。</li>
</ul>
<p>最终第$k$个词在文章$j$中的权重由下面公式获得：<br>$$w_{k,j}=\frac{TFIDF(t_k,d_j)}{\sqrt{\sum_{s=1}^{|T|}TFIDF(t_k,d_j)^2}}$$<br>做归一化的好处是不同文章之间的表示向量被归一到一个量级上，便于下面步骤的操作。 </p>
<h2 id="Profile-Learning">2.2. Profile Learning</h2><p>假设用户u已经对一些item给出了他的喜好判断，喜欢其中的一部分item，不喜欢其中的另一部分。<br>那么，这一步要做的就是通过用户u过去的这些喜好判断，为他产生一个模型。有了这个模型，我们就可以根据此模型来判断用户u是否会喜欢一个新的item。所以，我们要解决的是一个典型的有监督分类问题，理论上机器学习里的分类算法都可以照搬进这里。</p>
<p>下面我们简单介绍下CB里常用的一些学习算法：</p>
<ol>
<li>KNN</li>
<li>Rocchio</li>
<li>决策树（DT）</li>
<li>线性分类（LC）</li>
<li>朴素贝叶斯（NB）</li>
</ol>
<h2 id="Recommendation-Generation">2.3. Recommendation Generation</h2><p>如果上一步Profile Learning中使用的是分类模型（如DT、LC和NB），那么我们只要把模型预测的用户最可能感兴趣的n个item作为推荐返回给用户即可。而如果Profile Learning中使用的直接学习用户属性的方法（如Rocchio算法），那么我们只要把与用户属性最相关的n个item作为推荐返回给用户即可。其中的用户属性与item属性的相关性可以使用如cosine等相似度度量获得。</p>
<h2 id="基于内容的推荐的优缺点">2.4. 基于内容的推荐的优缺点</h2><p><strong>优点</strong></p>
<ol>
<li>用户之间的独立性（User Independence）：既然每个用户的profile都是依据他本身对item的喜好获得的，自然就与他人的行为无关。而协同过滤就需要利用很多其他人的数据。因此这种用户独立性带来的一个显著好处是别人不管对item如何作弊（比如利用多个账号把某个产品的排名刷上去）都不会影响到自己。</li>
<li>好的可解释性（Transparency）：如果需要向用户解释为什么推荐了这些产品给他，你只要告诉他这些产品有某某属性，这些属性跟你的品味很匹配等等。</li>
<li>新的item可以立刻得到推荐（New Item Problem）：只要一个新item加进item库，它就马上可以被推荐，被推荐的机会和老的item是一致的。而协同过滤对于新item就很无奈，只有当此新item被某些用户喜欢过（或打过分），它才可能被推荐给其他用户。所以，如果一个纯CF的推荐系统，新加进来的item就永远不会被推荐:( 。这也就是常说的item冷启动问题。</li>
</ol>
<p><strong>缺点</strong></p>
<ol>
<li>item的特征抽取一般很难（Limited Content Analysis）：如果系统中的item是文档（如个性化阅读中），那么我们现在可以比较容易地使用信息检索里的方法来“比较精确地”抽取出item的特征。但很多情况下我们很难从item中抽取出准确刻画item的特征，比如电影推荐中item是电影，社会化网络推荐中item是人，这些item属性都不好抽。其实，几乎在所有实际情况中我们抽取的item特征都仅能代表item的一些方面，不可能代表item的所有方面。这样带来的一个问题就是可能从两个item抽取出来的特征完全相同，这种情况下基于内容的推荐就完全无法区分这两个item了。比如如果只能从电影里抽取出演员、导演，那么两部有相同演员和导演的电影对于基于内容的推荐来说就完全不可区分了。</li>
<li>无法挖掘出用户的潜在兴趣（Over-specialization）：既然CB的推荐只依赖于用户过去对某些item的喜好，它产生的推荐也都会和用户过去喜欢的item相似。如果一个人以前只看与推荐有关的文章，那基于内容的推荐只会给他推荐更多与推荐相关的文章，它不会知道用户可能还喜欢数码。</li>
<li>无法为新用户产生推荐（New User Problem）：新用户没有喜好历史，自然无法获得他的profile，所以也就无法为他产生推荐了。当然，这个问题协同过滤也有。</li>
</ol>
<h1 id="参考文献">3. 参考文献</h1><ol>
<li><a href="https://www.ibm.com/developerworks/cn/opensource/os-recommender1/index.html" target="_blank" rel="external">推荐系统,IBM</a></li>
<li><a href="http://www.infoq.com/cn/articles/recommendation-algorithm-overview-part01" target="_blank" rel="external">推荐算法综述（一）</a></li>
<li><a href="http://blog.csdn.net/keyboardlabourer/article/details/26692177" target="_blank" rel="external">协同过滤之基于用户的最近邻推荐</a></li>
<li><a href="http://www.chongchonggou.com/g_60592064.html" target="_blank" rel="external">基于物品的协同过滤推荐算法——读“Item-Based Collaborative Filtering Recommendation Algorithms”</a></li>
<li><a href="https://www.zhihu.com/question/19971859" target="_blank" rel="external">协同过滤和基于内容推荐有什么区别？</a></li>
<li><a href="https://read.douban.com/reader/column/3346397/chapter/18909999/" target="_blank" rel="external">基于内容的推荐</a></li>
<li><a href="http://baogege.info/2014/10/19/matrix-factorization-in-recommender-systems/" target="_blank" rel="external">个性化推荐中的矩阵分解技术</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 机器学习实践 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[朴素贝叶斯的理解]]></title>
      <url>/2017/07/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%9A%84%E7%90%86%E8%A7%A3/</url>
      <content type="html"><![CDATA[<h1 id="朴素贝叶斯分类的思想基础">1. 朴素贝叶斯分类的思想基础</h1><p>参考文献<a href="http://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html" target="_blank" rel="external">算法杂货铺——分类算法之朴素贝叶斯分类</a>指出，朴素贝叶斯分类是一种十分简单的分类算法，叫它朴素贝叶斯分类是因为这种方法的思想真的很朴素，朴素贝叶斯的<strong>思想基础</strong>是这样的：对于给出的待分类项，求解在此项出现的条件下各个类别出现的概率，哪个最大，就认为此待分类项属于哪个类别。通俗来说，就好比这么个道理，你在街上看到一个黑人，我问你你猜这哥们哪里来的，你十有八九猜非洲。为什么呢？因为黑人中非洲人的比率最高，当然人家也可能是美洲人或亚洲人，但在没有其它可用信息下，我们会选择条件概率最大的类别，这就是朴素贝叶斯的思想基础。</p>
<p>将上面的描述形式化描述，就是下面的朴素贝叶斯分类的定义。</p>
<h1 id="朴素贝叶斯分类的定义和求解">2. 朴素贝叶斯分类的定义和求解</h1><ol>
<li>设$x={a_1,a_2,…,a_m}$为一个待分类项，其中每个$a$是$x$的一个特征属性。</li>
<li>有类别集合$C={y_1,y_2,…,y_n}$</li>
<li>计算$P(y_1|x),P(y_2|x),…,P(y_n|x)$。(也就是这个特征成为每个类别的概率)</li>
<li>如果$P(y_k|x)=max[P(y_1|x),P(y_2|x),…,P(y_n|x)],则x\in y_k$。(选出一个最可能的类别，将这个类别设为x的类别)</li>
</ol>
<h2 id="如何计算-P-y-i-x">2.1. 如何计算$P(y_i|x)$?</h2><p>问题来了，那么我们应该如何计算第3步当中的$P(y_i|x)$呢？</p>
<p>$P(y_i|x)$代表在这个$x$的情况下的类别成为$y_i$的概率，一般来说通过建模$p(y|x)$来预测$y$的模型叫“<strong>判别式模型</strong>”。<br>但问题在于如果特征数量n较大或者每个特征能取大量值时，基于概率模型列出概率表变得不现实。所以我们修改这个模型使之变得可行。因此我们可以先对联合概率分布$p(x,y)$建模，然后再由此得出$P(y_i|x)$，这样的是“<strong>生成式模型</strong>”。贝叶斯定理为：<br>$$P(y|x)=\frac{p(x,y)}{p(x)}=\frac{p(y)p(x|y)}{p(x)}\tag{公式0}$$</p>
<h2 id="因此将问题转化成了：如何基于训练数据D来估计先验-p-y-和似然-p-x-y-？">2.2. 因此将问题转化成了：如何基于训练数据D来估计先验$p(y)$和似然$p(x|y)$？</h2><ul>
<li>$p(y)$是先验概率，表示样本空间中各类样本所占比例；可以通过统计近似得出；</li>
<li>$p(x|y)$是各类样本条件下，所有$x$特征分布的概率。假设特征空间$x$有$d$维，且每一维都有2个取值，那么$x$的取值就有$2^d$种。一般来说这远大于训练样本数m。也就是很多取值是覆盖不到的。所以用频率来估计它不可行，因为“未被观测到”和“与出现概率为0”通常是不同的。</li>
</ul>
<h2 id="现在问题又来了，如何去估计-p-x-y-？">2.3. 现在问题又来了，如何去估计$p(x|y)$？</h2><p>估计类条件概率的通用解决方案：先假定其具有某种确定的概率分布形式，再基于训练样本对概率分布的参数进行估计。</p>
<h2 id="问题又转化成了-如何进行参数估计？">2.4. 问题又转化成了:如何进行参数估计？</h2><p>为明确起见，我们将$p(x|y)$记作$p(x|θ_y)$。</p>
<p>根据频率学派的思路，我们可以通过极大似然法来估计参数θ。</p>
<p>极大似然估计的核心思想是：我们已知$x$已发生，我们再根据实际情况写出$x$发生的概率$p(x_θ)$。目标函数是使得这个概率$p(x_θ)$最大，然后求得$θ$。</p>
<p>在本问题中，我们有训练样本集$X$，令$X_y$表示训练样本集$X$中第$y$类样本组成的集合，假设这些样本独立同分布。似然函数是某事件发生的概率，也就是$P(X_y|θ_y)$:<br>$$P(X_y|θ_y)=∏_{x\in X_y}P(x|θ_y) \tag{公式1}$$<br><em>小注，上式表达的意思是：</em>$在参数θ_y时，第y类样本集X_y发生的概率 = X_y中每个样本x发生的概率的乘积$</p>
<p>我们已经知道$X_y|θ_y$这个事件发生了（因为我们观测到了），那就让这个概率$P(X_y|θ_y)$最大化，去求得一个$θ_y$，这就是我们的最终目标——得到$θ_y$。</p>
<h2 id="如何解出参数？">2.5. 如何解出参数？</h2><p>如上所述，我们现在的目标是求得一个$θ_y$是的公式1最大。而公式1的连乘操作容易造成下溢，因此我们通常使用对数似然：<br>$$LL(θ_y)=log P(X_y|θ_y)$$<br>$$=\sum_{x\in X_y}log P(x|θ_y)\tag{公式2.1}$$<br>此时我们求得一个$θ_y$，使得公式2.1最大:</p>
<p>$$θ_y=arg_{θ_y} max LL(θ_y)\tag{公式2.2}$$</p>
<p>因此，我们只需要知道$p(x|θ)$,就可以求得各$y$类标签取值下的$θ$，就得到了$x$下各label的概率:$P(x|θ_y)$，也就是$P(x|y)$。代入<em>公式0</em>，我们得到了$P(y|x)$。此时我们就<strong>解决了朴素贝叶斯分类的定义的第3步</strong>，这样就能进行下一步了。</p>
<h2 id="并没有那么简单">2.6. 并没有那么简单</h2><p>然而，<strong>这个问题并没有这么简单。</strong>在公式2中我们要求得$θ$。假设$x^{(j)}$有$S_j$个取值，那么每个类别下的$θ_y$就有$∏_{j=1}^nS_j$维。且$y$的取值有$k$个，那就是$k∏_{j=1}^nS_j$，这样就很难算，几乎算不出来。</p>
<h2 id="参数太多，维度爆炸了，怎么办？">2.7. 参数太多，维度爆炸了，怎么办？</h2><p>因此，朴素贝叶斯分类器用了<strong>属性条件独立性假设</strong>:对于已知类别，假设所有属性相互独立。</p>
<p>此时，<em>公式0</em>可以改写成：<br>$$P(y|x)=\frac{p(y)p(x|y)}{p(x)}=\frac{p(y)}{p(x)}∏_{i=1}^dP(x_i|y)\tag{公式4}$$</p>
<p>而$p(x)$是样本分布，可以认为是常数，所以忽略。<br>按照我们刚刚推导的步骤，想求得$P(y|x)$，我们就回到了朴素贝叶斯分类的定义的第3步，算出公式2.2:</p>
<p>$$θ_y=arg_{θ_y} max LL(θ_y)=arg max_{y\in Y}P(y)∏_{i=1}^dP(x_i|y)\tag{公式5}$$</p>
<p>之后还有半朴素贝叶斯分类器。我们来日再说。</p>
<h1 id="参考文献">3. 参考文献</h1><ol>
<li><a href="http://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html" target="_blank" rel="external">算法杂货铺——分类算法之朴素贝叶斯分类</a></li>
<li><a href="https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E5%88%86%E7%B1%BB%E5%92%8C%E5%9B%9E%E5%BD%92/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/nb.md" target="_blank" rel="external">朴素贝叶斯</a></li>
<li><a href="">机器学习，周志华</a></li>
<li><a href="">概率论与数理统计，华师大出版社</a></li>
</ol>
<p>那我们回头看看我们的训练集。训练集是由一个已知分类的集合构成，也就是集合$X$和对应的$y$。也就是说，我们可以通过统计来获得各类别下各特征属性的条件概率估计：<br>$P(a_1|y_1),P(a_2|y_1),…,P(a_m|y_1);$<br>$P(a_1|y_2),P(a_2|y_2),…,P(a_m|y_2);$<br>$…,$<br>$P(a_1|y_n),P(a_2|y_n),…,P(a_m|y_n)$</p>
]]></content>
      
        <categories>
            
            <category> 机器学习算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 贝叶斯理论 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[机器学习算法-总结]]></title>
      <url>/2017/07/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E6%80%BB%E7%BB%93/</url>
      <content type="html"><![CDATA[<p>我一想到明天要面试，我就贼紧张。赶紧好好复习一下吧。</p>
<h1 id="特征降维">1. 特征降维</h1><p>主成分分析PCA<br>线性判别分析LDA<br>矩阵奇异值分解SVD<br>深度学习SparseAutoEncoder<br>LASSO<br>小波分析法<br>拉普拉斯特征映射</p>
<h1 id="统计模式分类问题中，当先验概率未知时，可以使用">2. 统计模式分类问题中，当先验概率未知时，可以使用</h1><p>最小误判概率准则<br>最小损失准则</p>
<h1 id="各种决策树">3. 各种决策树</h1><table>
<thead>
<tr>
<th>决策树</th>
<th>ID3/C4.5</th>
<th>CART</th>
</tr>
</thead>
<tbody>
<tr>
<td>相同</td>
<td>都是基于信息论的决策树算法</td>
<td></td>
</tr>
<tr>
<td>不同1</td>
<td>ID3是信息增益，C4.5是信息增益比</td>
<td>CART中用于选择变量的不纯性度量是Gini指数</td>
</tr>
<tr>
<td>不同2</td>
<td>C4.5/ID3不一定是二叉树</td>
<td>CART一定是二叉树</td>
</tr>
</tbody>
</table>
]]></content>
      
        <categories>
            
            <category> 机器学习算法 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[SVD分解]]></title>
      <url>/2017/07/10/%E6%95%B0%E5%AD%A6-SVD%E5%88%86%E8%A7%A3/</url>
      <content type="html"><![CDATA[<p><strong>简介</strong></p>
<ul>
<li>SVD(Singular Value Decomposition，奇异值分解)是对实数矩阵(甚至复数矩阵)的一种因式分解。</li>
<li>任意的一个矩阵都可以做SVD分解。相比SVD分解，和SVD相近的特征值分解只能应用于方阵。</li>
<li>SVD分解可用来解决非方阵不能计算逆矩阵的问题。</li>
</ul>
<h1 id="SVD定义">1. SVD定义</h1><p>设一个$m\times n$的矩阵$M$,它的SVD分解是：<br>$$M=UΣV^*$$<br>其中：</p>
<ul>
<li>$U$是一个$m\times m$的酉矩阵。(我的理解：酉矩阵是在复数空间上，类似正交矩阵的矩阵。它有很多不错的性质。可以在我上一篇博客里看到)</li>
<li>$Σ$是$m\times n$的矩形对角矩阵，并且在对角线上的元素都是非负实数$σ_i$，称为$M$的奇异值</li>
<li>$V^*$是一个$n\times n$的酉矩阵，也是$V$的共轭转置矩阵。</li>
</ul>
<h1 id="SVD的原理">2. SVD的原理</h1><p>首先，我们对正交矩阵进行一些回顾。</p>
<p><strong>正交矩阵回顾</strong></p>
<p>从上一节我们知道，正交矩阵对应的变换是不会改变向量长度的。即，对于向量$(a,b)$，正交矩阵$U$，变换后的向量$U(a,b)$的长度与$(a,b)$是相等的。这个正交变换只是对$(a,b)$做了旋转或者镜射等操作。</p>
<h2 id="特征值分解——EVD">2.1. 特征值分解——EVD</h2><p>在讨论SVD之前，我们先讨论矩阵的特征值分解（EVD）。</p>
<p>回顾特征值分解，特征值分解是把一个n阶实对称矩阵分解为下面的形式：<br>$$A=QΣQ^{-1}$$<br>其中：</p>
<ul>
<li>$Q$是这个矩阵$A$的特征向量组成的矩阵，是一个正交矩阵</li>
<li>$Σ$是一个对角阵，每个对角线上的元素就是一个特征值</li>
</ul>
<p>此时假设有一个$x$向量，用$A$将这个向量$x$变换到$A$的列空间中，即：<br>$$Ax=QΣQ^{-1}x=QΣQ^Tx=QΣ(Q^Tx)$$</p>
<ol>
<li>首先进行$Q^Tx$操作。$Q$和$T^T$都是正交阵，那么$Q^T$对$x$的变换是正交变换，它将$x$用新的坐标系，这个坐标系就是$A$的所有正交的特征向量构成的坐标系。<br>我们如果将$x$用$A$的所有特征向量来表示的话，即表示为$x=a_1x_1+a_2x_2+…+a_mx_m$，则通过第一个变换，$(Q^Tx)=[a_1,a_2,…,a_m]’$,即<img src="https://ooo.0o0.ooo/2017/07/10/596382b7bdde7.png" alt=""> </li>
<li>紧接着，在新的坐标系表示下，由中间那个对角矩阵对新的向量坐标换，其结果就是将向量往各个轴方向拉伸或压缩：<img src="https://ooo.0o0.ooo/2017/07/10/596382f4d62b4.png" alt=""><br>从上图可以看到，如果A不是满秩的话，那么就是说对角阵的对角线上元素存在0，这时候就会导致维度退化，这样就会使映射后的向量落入m维空间的子空间中。</li>
<li>最后一个变换就是U对拉伸或压缩后的向量做变换，由于U和U’是互为逆矩阵，所以U变换是U’变换的逆变换。</li>
</ol>
<p>因此，从对称阵的分解对应的映射分解来分析一个矩阵的变换特点是非常直观的。假设对称阵特征值全为1那么显然它就是单位阵，如果对称阵的特征值有个别是0其他全是1，那么它就是一个正交投影矩阵，它将m维向量投影到它的列空间中。</p>
<h2 id="奇异值分解–SVD">2.2. 奇异值分解–SVD</h2><p>上面的矩阵$A$要求必须是n阶实对称的。那么对于任意的$M\times N$矩阵，能否找到一个相似的变换呢？这就是SVD分解的精髓所在。</p>
<p>在上面的特征值分解中，我们能找到一个变换$A$，将一组正交基映射到另一组正交基。</p>
<ul>
<li>我们假设存在$M \times N$的矩阵$A$。现在我们的目标是，在n维空间中找到一组正交基$${v_1,v_2,…,v_n}$$，使得经过A变换后还是正交的。</li>
<li>那么$A$矩阵就将这组基映射为：$${Av_1,Av_2,…,Av_n}$$</li>
<li>如果要使得它们两两正交，即：$$Av_i\cdot Av_j = (Av_i)^TAv_j=v_i^TA^TAv_j=0$$</li>
<li>根据假设，存在$$v_i^Tv_j=v_i\cdot v_j = 0$$</li>
<li>所以如果正交基v选择为A’A的特征向量的话，由于A’A是对称阵，v之间两两正交，那么$$v_i^TA^TAv_j=v_i^T\lambda _jv_j=0$$，这样就找到了正交基映射后还是正交基了。</li>
<li>将映射后的正交基单位化，$$u_i = \frac{Av_i}{|Av_i|}=\frac{1}{\sqrt{\lambda_i}}Av_i$$<br>其中$u_i$是映射后的正交基，$v_i$是映射前的正交基。</li>
<li>由此可得，$$Av_i=u_i\alpha_i(奇异值)=\sqrt{\lambda_i},0\leq i \leq k,k=Rank(A)$$</li>
</ul>
<p>这样我们就证明了，这个变换是存在的。</p>
<p>接下来，我们将向量组${u_1,u_2,…,u_k}$扩充为$R^m$中的标准正交基$u_1,u_2,…,u_r,…,u_m$，则：<br>$$AV=A(v_1,v_2,…,v_n)=(Av_1,Av_2,…,Av_k,0,0,…,0)$$<br>而由之前的推导我们知道，$Av_i=u_i\alpha_i(奇异值)$，因此上式变为<br>$$AV=(u_1\alpha_1,u_2\alpha_2,…,u_k\alpha_k,0,0,…,0)=UΣ$$</p>
<p>即：<br>$$A=UΣV^T$$</p>
<p>这就<strong>表明</strong>任意的矩阵$A$是可以分解成三个矩阵。$V$表示了原始域的标准正交基，$U$表示经过$A$变换后的co-domain的标准正交基，$Σ$表示了$V$中的向量与$U$中相对应向量之间的关系。</p>
<p>其中：</p>
<ul>
<li>$A是m\times n维度$</li>
<li>$U叫左奇异向量，是m\times m维的正交矩阵$</li>
<li>$Σ叫右奇异向量，是n\times n维的对角矩阵，但实际上只有左上角的k阶非零$,即:<img src="https://ooo.0o0.ooo/2017/07/10/5963960b257f5.png" alt=""> </li>
</ul>
<p>从大小上来看：<img src="https://ooo.0o0.ooo/2017/07/10/59639293b5bc5.png" alt=""> </p>
<p>即：<img src="https://ooo.0o0.ooo/2017/07/10/59639634df34d.png" alt=""> </p>
<h2 id="特征值分解与奇异值分解">2.3. 特征值分解与奇异值分解</h2><p>参考文献<a href="https://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html" target="_blank" rel="external">机器学习中的数学(5)-强大的矩阵奇异值分解(SVD)及其应用</a>提到，奇异值和特征值可以对应起来。</p>
<h2 id="部分奇异值分解">2.4. 部分奇异值分解</h2><p>在很多情况下，前10%甚至1%的奇异值的和就占了全部的奇异值之和的99%以上了。也就是说，我们也可以用前r大的奇异值来近似描述矩阵，这里定义一下部分奇异值分解：<br>$$A_{m\times n}\approx U_{m\times r}Σ_{r_\times r}V^T_{r\times n}$$<br> r是一个远小于m、n的数，这样矩阵的乘法看起来像是下面的样子：<br><img src="https://ooo.0o0.ooo/2017/07/10/596398011f9e0.png" alt=""><br>右边的三个矩阵相乘的结果将会是一个接近于A的矩阵，在这儿，r越接近于n，则相乘的结果越接近于A。而这三个矩阵的面积之和（在存储观点来说，矩阵面积越小，存储量就越小）要远远小于原始的矩阵A，我们如果想要压缩空间来表示原矩阵A，我们存下这里的三个矩阵：U、Σ、V就好了。</p>
<p><strong>小例子</strong></p>
<p>接下来我们给出一个用python的SVD分解小例子。</p>
<pre><code>&apos;&apos;&apos;Python
#coding=utf-8
# 首先做一些数据声明
from sklearn.decomposition import TruncatedSVD
from matplotlib import pyplot as plt
from numpy import random
import numpy as np
from mpl_toolkits.mplot3d import Axes3D
import pandas as pd
fig = plt.figure()
ax = Axes3D(fig)
ax=plt.subplot(111,projection=&apos;3d&apos;)
ax.set_zlabel(&apos;Z&apos;) #坐标轴
ax.set_ylabel(&apos;Y&apos;)
ax.set_xlabel(&apos;X&apos;)
X = np.arange(0, 4, 0.125) + 0.2 * random.randn(32)
Y = np.arange(0, 4, 0.125) + 0.2 * random.randn(32)
Z = np.arange(0, 4, 0.125) + 0.2 * random.randn(32)
# 数据是3维×32维
data = [[x, y, z] for x, y, z in zip(X, Y, Z)]


# 分解，n_components是主元素个数，也就是维度
svd = TruncatedSVD(n_components=2, algorithm=&quot;arpack&quot;, n_iter=1000)
transformed_data = svd.fit_transform(data)
# 还原
data_inverse = svd.inverse_transform(transformed_data)

#画图
X_ = [x[0] for x in data_inverse]
Y_ = [y[1] for y in data_inverse]
Z_ = [z[2] for z in data_inverse]
ax.scatter(X, Y, Z, c=&apos;r&apos;)#原始数据是红色
ax.scatter(X_, Y_, Z_, c=&apos;b&apos;)#分解后的数据是蓝色
plt.savefig(&quot;svd.png&quot;)
plt.show()
print svd.explained_variance_ratio_
&apos;&apos;&apos;
</code></pre><p>当降到二维，再还原时，我们看到：<br><img src="https://ooo.0o0.ooo/2017/07/11/59643b2a666c7.png" alt=""><br>降到一维，再还原，我们看到：<br><img src="https://ooo.0o0.ooo/2017/07/11/59643cbeed773.png" alt=""> </p>
<h1 id="SVD与潜在语义索引">3. SVD与潜在语义索引</h1><p>$$A=UΣV^T$$</p>
<p>吴军老师在矩阵计算与文本处理中的分类问题中谈到：三个矩阵有非常清楚的物理含义。</p>
<ul>
<li>$U$中的每一行表示意思相关的一类词，其中的每个非零元素表示这类词中每个词的重要性（或者说相关性），数值越大越相关。</li>
<li>$V^T$中的每一列表示同一主题一类文章，其中每个元素表示这类文章中每篇文章的相关性。中间的矩阵则表示类词和文章雷之间的相关性。</li>
<li>因此，我们只要对关联矩阵$A$进行一次奇异值分解，我们就可以同时完成了近义词分类和文章的分类。（同时得到每类文章和每类词的相关性）。</li>
</ul>
<p>参考文献<a href="https://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html" target="_blank" rel="external">机器学习中的数学(5)-强大的矩阵奇异值分解(SVD)及其应用</a>给出了一个理解这句话的例子，此处不再阐述。</p>
<p>我在做比赛的过程中，曾尝试过用SVD分解做APP特征，来描述APP之间的相似性特征。但效果不佳。推测原因是维度过低（几百万维压到了20维）。项目<a href="https://github.com/jiayi797/svd_app_recommend" target="_blank" rel="external">在这里</a></p>
<p>但这里我还是打算好好看看。万一以后用到呢？</p>
<p>参考文献<a href="http://charleshm.github.io/2016/03/SVD-Recommendation-System/" target="_blank" rel="external">SVD在推荐系统中的应用</a>以经典的电影评分问题为例，讲述了整个过程。参考文献<a href="http://www.jscon.co/multiarray/rs_used_svd.html" target="_blank" rel="external">SVD在推荐系统中的应用</a>用matlab进行了详细的过程复现。</p>
<p>我的理解：<br><strong>SVD分解</strong><br>SVD分解是：$$A_{m\times n}=U_{m\times m}Σ_{m\times n}V^T_{n\times n}$$<br>其中：</p>
<ul>
<li>$Σ_{m\times n}$是一个对角阵。</li>
<li>U_{m\times m}表示行间元素（一般是用户）的相似度</li>
<li>V^T_{n\times n}表示列间元素（一般是商品）的相似度<br>根据好友张思遥的理解，是通过数学的方法，来将行和列的拆开，放在两个矩阵里。<br><strong>降维</strong><br>根据PCA理论（强烈建议看斯坦福大学安德鲁老师的机器学习课程，这里有前辈的笔记<a href="http://blog.csdn.net/stdcoutzyx/article/details/37568225" target="_blank" rel="external">斯坦福ML公开课笔记14——主成分分析</a>，我们可以取前$r$维来对矩阵进行近似表示：<br>$$A_{m\times n}\approx U_{m\times r}Σ_{m\times n}V^T_{r\times n}$$</li>
</ul>
<h1 id="项目代码">4. 项目代码</h1><p><a href="https://github.com/jiayi797/svd_app_recommend" target="_blank" rel="external">SVD项目代码</a></p>
<h1 id="参考文献">5. 参考文献</h1><ol>
<li><a href="http://www.qiujiawei.com/linear-algebra-9/" target="_blank" rel="external">线性代数之奇异值(SVD)分解</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_3f738ee00102val0.html" target="_blank" rel="external">奇异值分解(SVD)原理详解及推导</a></li>
<li><a href="http://charleshm.github.io/2016/03/Singularly-Valuable-Decomposition/" target="_blank" rel="external">漫谈奇异值分解</a></li>
<li><a href="http://www.sohu.com/a/127149396_464826" target="_blank" rel="external">机器学习系列-SVD篇</a></li>
<li><a href="https://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html" target="_blank" rel="external">机器学习中的数学(5)-强大的矩阵奇异值分解(SVD)及其应用</a></li>
<li><a href="http://charleshm.github.io/2016/03/SVD-Recommendation-System/" target="_blank" rel="external">SVD在推荐系统中的应用</a></li>
<li><a href="http://www.jscon.co/multiarray/rs_used_svd.html" target="_blank" rel="external">SVD在推荐系统中的应用</a></li>
<li><a href="http://blog.csdn.net/stdcoutzyx/article/details/37568225" target="_blank" rel="external">斯坦福ML公开课笔记14——主成分分析</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 数学 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 矩阵分解 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[矩阵相关知识复习]]></title>
      <url>/2017/07/10/%E6%95%B0%E5%AD%A6-%E7%9F%A9%E9%98%B5%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E5%A4%8D%E4%B9%A0/</url>
      <content type="html"><![CDATA[<h1 id="特征值与奇异值">1. 特征值与奇异值</h1><p><strong>特征值与特征向量</strong></p>
<p>如果一个向量$v$是方阵$A$的特征向量，那么：<br>$$Av=\lambda v$$</p>
<ul>
<li>$\lambda$:特征值</li>
<li>$v$:特征向量<br>把$A$乘到$v$上，得到一个$\lambda v$，也就是意味着我们得到了一个方向未变但在长度上有伸缩改变的向量（方向未变不准确，有可能变反向）。这是让$A$乘以他的特征向量表现出来的性质。</li>
</ul>
<p>因此：</p>
<ul>
<li>特征向量所在直线上的向量都是特征向量；</li>
<li>特征向量所在的直线，叫特征空间；</li>
</ul>
<p><strong>特征值分解</strong></p>
<p>特征值分解是把一个n阶实对称矩阵分解为下面的形式：<br>$$A=QΣQ^{-1}$$<br>其中：</p>
<ul>
<li>$Q$是这个矩阵$A$的特征向量组成的矩阵，是一个正交矩阵</li>
<li>$Σ$是一个对角阵，每个对角线上的元素就是一个特征值</li>
</ul>
<h1 id="正交变换与正交军阵">2. 正交变换与正交军阵</h1><h2 id="正交变换">2.1. 正交变换</h2><p><strong>什么是正交变换？</strong><br>正交变换：在线性空间中，保持向量长度不变的线性变换。<br><strong>正交变换的定义是什么？</strong><br>设$V$为欧式空间，$T$是$V$的一个线性变换。如果$T$保持$V$中任一向量$x$的长度不变，即有：<br>$$(x,x)=(Tx,Tx)$$<br>那么称$T$是$V$的一个正交变换。（即内积不变）</p>
<p>注：<br>$(x,x)$是向量内积<br><strong>怎样的变换算是正交变换？</strong><br>线性变换$T$为正交变换的充要条件是，对于欧式空间$V$中任二向量$x,y$都有：<br>$$(x,y)=(Tx,Ty)$$</p>
<h2 id="正交矩阵">2.2. 正交矩阵</h2><p><strong>正交矩阵的定义是什么？</strong><br>如果实方阵$Q$满足：<br>$$T^TQ=I,或 Q^{-1}=Q^T$$<br>则称$Q$为正交矩阵</p>
<p>其中，$I$是单位矩阵。<br><strong>正交矩阵有哪些特点？</strong></p>
<ul>
<li>正交矩阵的行列式必定为$+-1$</li>
<li>行列式值为+1的正交矩阵，称为特殊正交矩阵，它是一个旋转矩阵。</li>
<li>行列式值为-1的正交矩阵，称为瑕旋转矩阵。瑕旋转是旋转加上镜射。镜射也是一种瑕旋转。</li>
<li>正交矩阵的逆矩阵依然是正交矩阵</li>
<li>两个正交矩阵的乘积依然是正交矩阵</li>
<li>下面是一些小的正交矩阵和可能的解释：<br><img src="https://ooo.0o0.ooo/2017/07/10/59632337a1cdf.png" alt=""> </li>
</ul>
<p><strong>怎样的矩阵能够成为正交矩阵？</strong><br>$Q$是正交矩阵的充要条件是，它的列向量是两两正交的单位向量。</p>
<h2 id="正交变换与正交矩阵的关系">2.3. 正交变换与正交矩阵的关系</h2><p>欧式空间的线性变换是正交变换的充要条件是，它对于标准正交基的矩阵是正交矩阵。</p>
<h1 id="酉空间">3. 酉空间</h1><p>欧式空间是针对实数域$R$上的线性空间；<br>酉空间是特殊的复线性空间。</p>
<p><strong>酉变换</strong><br>酉空间$V$中的线性变换$T$，如果满足<br>$$(x,x)=(Tx,Tx),x\in V$$<br>则称$T$为$V$的酉变换。<br><strong>酉矩阵</strong><br>酉变换在酉空间的标准正交基下的矩阵$A$是酉矩阵，即$A$满足下式：<br>$$A^HA=AA^H=I$$</p>
<ul>
<li>酉矩阵的逆矩阵也是酉矩阵</li>
<li>两个酉矩阵的乘积还是酉矩阵</li>
</ul>
<h2 id="Schur定理">3.1. Schur定理</h2><p><strong>酉空间上的Schur定理（定理1.41）</strong><br>设$A\in C^{n\times n}$的特征值为$\lambda _1,\lambda _2,…,\lambda _n$，则存在酉矩阵$P$,使得：<br>$$P^{-1}AP=P^HAP=\left[<br>\begin{matrix}<br>\lambda _1 &amp; .          &amp; …&amp; . \\<br>           &amp; \lambda _2 &amp; …&amp; . \\<br>           &amp;            &amp; …&amp; . \\<br>           &amp;            &amp;    &amp;\lambda _n<br>\end{matrix}<br>\right]$$</p>
<p><strong>实数空间上的Schur定理</strong><br>设$A\in R^{n\times n}$的特征值为$\lambda _1,\lambda _2,…,\lambda _n$，且$\lambda _n \in R(i=1,2,…,n)$,则存在正交矩阵$Q$,使得：<br>$$Q^{-1}AQ=Q^HAQ=\left[<br>\begin{matrix}<br>\lambda _1 &amp; .          &amp; …&amp; . \\<br>           &amp; \lambda _2 &amp; …&amp; . \\<br>           &amp;            &amp; …&amp; . \\<br>           &amp;            &amp;    &amp;\lambda _n<br>\end{matrix}<br>\right]$$</p>
<p><strong>正规矩阵</strong></p>
<p>设$A \in C^{n \times n}$，且等式<br>$$A^HA=AA^H$$<br>成立，则称$A$为正规矩阵。</p>
<p><strong>正规矩阵与对角矩阵的定理（定理1.42）</strong></p>
<ul>
<li>（酉空间）设$A \in C^{n \times n}$，则$A$酉相似于对角矩阵的充要条件是$A$为正规矩阵；</li>
<li>（实数空间）$A \in R^{n \times n}$，且$A$的特征值都是实数，则$A$正交相似于对角矩阵的充要条件是$A$为正规矩阵。</li>
</ul>
<h1 id="参考文献">4. 参考文献</h1><ol>
<li><a href="https://zh.wikipedia.org/wiki/%E6%AD%A3%E4%BA%A4%E7%9F%A9%E9%98%B5" target="_blank" rel="external">维基百科，正交矩阵</a></li>
<li><a href="">矩阵论，程云鹏</a></li>
<li><a href="http://zisong.me/post/wo-dui-te-zheng-zhi-yu-te-zheng-xiang-liang-de-li-jie" target="_blank" rel="external">我对特征值与特征向量的理解</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 数学 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 矩阵论 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[简单搜索引擎的实现]]></title>
      <url>/2017/07/09/Python-%E7%AE%80%E5%8D%95%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E7%9A%84%E5%AE%9E%E7%8E%B0/</url>
      <content type="html"><![CDATA[<p>这是很久以前的IRIE的期末大作业。现在贴在自己的博客上。</p>
<p>实验要求：</p>
<ol>
<li>用爬虫采集特定网站的信息；</li>
<li>设计实现信息检索与提取系统，对采集的信息进行检索提取；</li>
<li>结合webpy与html实现界面展示。</li>
</ol>
<h1 id="相关知识">1. 相关知识</h1><h2 id="爬虫">1.1. 爬虫</h2><p>网络爬虫是捜索引擎抓取系统中重要的组成部分，其主要目的是将互联网上的网页下载到本地形成一个文件或互联网内容的镜像备份。流程如下：<br>a.  从给定的入口网址把第一个网页下载下来<br>b.  从第一个网页中提取出所有新的网页地址，放入下载列表中<br>c.  按下载列表中的地址，下载所有新的网页<br>d.  从所有新的网页中找出没有下载过的网页地址，更新下载列表<br>e.  重复3、4两步，直到更新后的下载列表为空表时停止<br>其实就是简化成下面的步骤：<br>a.  按下载列表进行下载<br>b.  更新下载列表<br>c.  循环操作a，b，直到列表为空结束<br>在本次作业中我们使用python编码实现爬虫的功能，其中用到的python组件有：<br>urllib2：用于获取URLs（Uniform Resource Locators）的组件，以urlopen函数的形式提供一个非常简单的接口，具有利用不同协议获取URLs的能力，同时提供了一个比较复杂的接口来处理一般情况，如：基础验证，cookies代理和其他。通过handlers和openers的对象提供。urllib2支持获取不同格式的URLs并利用它们相关网络协议（例如FTP，HTTP）进行获取。<br>BeautifulSoup：是python的一个库，最主要的功能是从网页抓取数据。它提供简单的、python式的函数用来处理导航、搜索、修改分析树等功能。可以通过解析文档为用户提供需要抓取的数据。在bs4库中导入。<br>Htmlparser：是一个开源项目，提供了线性和嵌套两种方式来解析网页，主要用于 html 网页的转换（Transformation）以及网页内容的抽取（Extraction）。HtmlParser 有如下一些易于使用的特性：过滤器（Filters），访问者模式（Visitors），处理自定义标签以及易于使用的 JavaBeans。<br>selenium ：是一个模拟浏览器，进行web的自动化测试的工具，它提供一组API可以与真实的浏览器内核交互。用于抓取js动态生成的页面。</p>
<h2 id="信息检索系统模型">1.2. 信息检索系统模型</h2><p>信息检索系统的模型主要有布尔模型、向量模型和概率模型。其中布尔模型<br>是最早的IR模型，也是应用最广泛的模型，目前仍然应用于商业系统中，布尔模型查询简单但不支持部分匹配，很难控制被检索的文档数量；向量模型（VSM：Vector Space Model）是Salton在上世纪60年代提出的，成功应用于SMART（System for the Manipulation and Retrieval of Text）文本检索系统，其基于关键词，并根据关键词的出现频率计算相似度，向量模型中术语权重的算法提高了检索的性能，部分匹配的策略使得检索的结果文档集更接近用户的检索需求，同时可以根据结果文档对于查询串的相关度使用Cosine Ranking等公式对结果文档进行排序。<br>在本次作业中信息检索系统采用向量模型，根据相似度返回结果。</p>
<h2 id="结巴（Jieba）分词">1.3. 结巴（Jieba）分词</h2><p>结巴（jieba）是一个可以对一段中文进行分词的插件，支持精确模式、全模式及搜索引擎模式三种分词模式，可以适应不同需求。其基本实现原理有：（1）基于Trie树结构实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图（DAG）；（2）采用了动态规划查找最大概率路径, 找出基于词频的最大切分组合；（3）对于未登录词，采用了基于汉字成词能力的HMM模型，使用了Viterbi算法。</p>
<h2 id="基于webpy界面设计网页">1.4. 基于webpy界面设计网页</h2><p>webpy 是一个轻量级Python web框架，可以快速的完成简单的web页面。在本次实验中使用webpy建立搜索网页，web.py 的模板语言叫做 Templetor，它能负责将 python 的强大功能传递给模板系统。本实验中使用template与html编写网页。</p>
<h1 id="系统设计">2. 系统设计</h1><p>本次实验中信息检索与提取系统的整体设计流程如下图所示。主要包括抓取信息、分词、建立索引、建立向量模型、计算比较相似度、返回结果这六个过程，此外，我们基于webpy建立了搜索的网页界面，使查询过程更加简洁明了。下面具体介绍相应的模块。<br><img src="https://ooo.0o0.ooo/2017/07/09/596238be1b600.png" alt=""> </p>
<p><strong>抓取信息</strong></p>
<p>使用python编写爬虫程序抓取新浪网（<a href="http://news.sina.com.cn/）" target="_blank" rel="external">http://news.sina.com.cn/）</a><br>上的新闻，使用urllib2获取网页源代码，使用beautifulsoup和htmlparser解析网页获取网页中的新闻（标题、关键字、内容、日期），用selenium获取js动态生成的数据(评论数)。解析过的与未解析的链接分开标记。经过一段时间的抓取，共获得3000多条新闻信息，保存为txt文件，具体格式如下：<br><img src="https://ooo.0o0.ooo/2017/07/09/596238dc23fb4.png" alt=""><br>每条新闻包括标题、关键字、时间、网址、评论数（热度）等信息。</p>
<p><strong>分词</strong><br>导入jieba分词模块，首先按是否为汉字、数字、英文字符及标点<br>符号对新闻内容进行梳理，去除掉信息缺失的数据，然后用jieba分词对title及description内容进行分词，得到如下txt文件；<br><img src="https://ooo.0o0.ooo/2017/07/09/596239055fe8a.png" alt=""><br><strong>建立索引</strong><br>对于所有的词，按照其在全部新闻中出现的情况建立倒排索引，将每个词与相应的新闻序号建立联系。<br><strong>建立向量模型</strong><br>结合建立的倒排索引表，计算每个新闻条目的向量，其中权重采用tf-idf算法生成，构建向量模型。<br><img src="https://ooo.0o0.ooo/2017/07/09/5962392041016.png" alt=""><br><strong>查询返回结果</strong><br>根据在query中输入的关键词与向量模型进行数量积计算相似度，根据相似度的大小将检索到的新闻按序列出。如：query中输入“南海，菲律宾”，得到的检索结果如下：<br><img src="https://ooo.0o0.ooo/2017/07/09/5962393a9743b.png" alt=""><br><strong>前后端实现</strong><br>基于webpy界面设计搜索网页，建立交互的界面。在之前系统设计的基<br>础上，在webpy框架下，利用templates模板语言将后台结果与前端界面进行交互，并在服务器端使用GET和POST函数与客户端web交互并传递参数传递参数，将搜索新闻在网页上呈现出来。其主要步骤为：（1）客户端发送get请求，触发服务端get()函数，调用index.html网页，返回给客户端。（2）客户端发送搜索关键字并通过post方式给服务端，触发服务端post()函数，post()函数将收到的关键字传入之前设计的搜索系统中，得到返回值新闻条目。（3）通过webpy传递给result.html，得到html网页后发给客户端。<br><img src="https://ooo.0o0.ooo/2017/07/09/5962395e27566.png" alt=""> </p>
<h1 id="最终效果">3. 最终效果</h1><p>校内网网址：<a href="http://10.108.112.154:8080/" target="_blank" rel="external">http://10.108.112.154:8080/</a><br>例如想要查询与“习近平”“南海”相关的新闻，按下图输入，关键词之间要有空格。<br><img src="https://ooo.0o0.ooo/2017/07/09/5962397f56a5b.png" alt=""><br>点击search之后的网页界面如下，将我们之前抓取的与“习近平”及“南海”有关的新闻链接按照相似度大小排列，同时列出相应的时间、内容及热度。<br><img src="https://ooo.0o0.ooo/2017/07/09/59623992a4464.png" alt=""><br>如果输入的关键词并不在之前建立的索引中，则会出现如下界面：<br><img src="https://ooo.0o0.ooo/2017/07/09/596239a2c7fc9.png" alt=""> </p>
<h1 id="遇到的问题及解决方法">4. 遇到的问题及解决方法</h1><p>•   对Python语言不熟悉、甚至0基础：<br>阅读相关书籍，掌握for循环，try\except异常处理，list  dict 等基本数据结构的操作及语法，文件读写操作，数学运算等，快速上手。<br>•   Python程序运行打印之后不输出：<br>import sys<br>reload(sys)<br>sys.setdefaultencoding(‘utf-8’)<br>•   获取网页速度慢：<br>if response.info().get(‘Content-Encoding’) == ‘gzip’:<br>    buf = StringIO(response.read())<br>    f = gzip.GzipFile(fileobj=buf)<br>下载压缩的网页，速度更快<br>•   获取网页异常时，程序中断，导致不能源源不断地爬取到需要的网页：<br>利用try/except处理异常。<br>try:<br>    …<br>except urllib2.HTTPError as e:  # 处理HTTP异常<br>    …<br>except urllib2.URLError as e:#处理URL异常<br>   …<br>except:#处理全部类型异常，使程序不中断<br>•   beautifulsoup解析网页内容不全，无法获取新闻网页中关于评论数目的信息：<br>查看网页源代码发现评论数是js动态生成的，beautifulsoup不能用于获取动态生成的数据，经查阅网上资料，返现selenium包可以用于解析网页中js动态生成的数据，我们首先获取新闻id，访问新浪新闻评论链接，找到其中评论数据。<br>commenturl = ‘<a href="http://comment5.news.sina.com.cn/comment/skin/default.html?channel=gn&amp;newsid=comos-" target="_blank" rel="external">http://comment5.news.sina.com.cn/comment/skin/default.html?channel=gn&amp;newsid=comos-</a>‘ + newsid<br>driver = webdriver.PhantomJS()<br>driver.set_page_load_timeout(30)#设置延时<br>driver.get(commenturl)#获取网页<br>comment = driver.find_element_by_class_name(‘f_red’).text#获取元素<br>•   selenium运行报错：<br>需要添加环境变量，将PhantomJS文件所在文件夹添加到$PATH文件下：sudo vi /etc/paths<br>•   搜索时建立索引过程耗费时间<br>预先建立好索引，存储在内存中，搜索时直接利用已经建立好的索引进行搜索。<br>•   为每条新闻数据、query建立向量并存储速度慢、由于字典集合很大，导致向量稀疏、耗费资源，另外进行向量乘法运算计算相似度时产生不必要的浪费：<br>仅为每条新闻数据建立字典，存储包含的词和tf-idf权重值，计算query和每一个新闻条目的相似度时，只需要对query中包含的关键词在新闻条目中的权值进行运算即可（因为其它位都是0），简化运算。<br>•   新闻条目数量庞大，query与新闻的匹配计算量大、效率低：<br>给定query时，我们先访问query中关键词在索引中的倒排列表，只对其中的新闻与query进行相似度计算、排序、返回最终结果，极大程度上过滤掉与query不相关的新闻条目。<br>•   字典创建无序，不能按创建顺序输出结果：<br>利用OrderedDict有序字典，能够记录下字典的创建顺序，有序输出结果dict= collections.OrderedDict()<br>•   搜索结果优化：搜索返回的结果题目中不包含关键词：<br>对在新闻题目中出现的关键词增加权重，使得题目与关键词匹配度越高的新闻排名越靠前，符合真实需求。<br>•   webpy不能直接调用Python中的函数：<br>在webpy模板首行定义一个变量$def with (posts) 在Python中计算后利用将参数传入，可以是任意类型。<br>•   webpy使用template时，路径设置：<br>render = web.template.render(‘templates/‘)<br>打开render下的index.html：<br>render.index() </p>
]]></content>
      
        <categories>
            
            <category> Python </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 爬虫 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[转化率预估之贝叶斯平滑]]></title>
      <url>/2017/07/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5-%E8%BD%AC%E5%8C%96%E7%8E%87%E9%A2%84%E4%BC%B0%E4%B9%8B%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%B9%B3%E6%BB%91/</url>
      <content type="html"><![CDATA[<h1 id="问题描述">1. 问题描述</h1><p>在做比赛的过程中，我们发现了有转化率这个指标在大量数据下是有效的。理想情况下，例如某个广告点击量是10000次，转化量是100次，那转化率就是1%。但有时，例如某个广告点击量是2次，转化量是1次，这样算来转化率为50%。但此时这个指标在数学上是无效的。因为大数定律告诉我们，在试验不变的条件下，重复试验多次，随机事件的频率近似于它的概率。后者点击量只有2次，不满足“重复试验多次”的条件。</p>
<p>那么如何解决这个问题呢？</p>
<p><strong>整体思路</strong>：用估计值来模拟实际CVR。</p>
<h1 id="解决方案">2. 解决方案</h1><p>实际上，广告妆化率是随着时间迁移和用户喜好变化而变化的。因此我们可以利用先验知识来持续性地调整CVR。<a href="https://zhuanlan.zhihu.com/p/21724759" target="_blank" rel="external">计算广告训练与平滑思想</a>给出了一个很好的解决方案：贝叶斯平滑。</p>
<p>考虑到时序序列模型，我们把从第一天到第n天的所有先验知识汇总到第n天的结果，并以此来对第n+1天的CTR进行平滑。在广告平滑上，没有什么方法比贝叶斯平滑能够更好的利用先验知识了，而帮助贝叶斯平滑方法实现目标的就是Beta分布。Beta分布的强大之处在于，通过改变其中的两个参数α和β，你可以让Beta分布的图形变成任意形状，而且在加入先验知识前后，通过贝叶斯变换，对CTR的预估都可以表示为Beta分布。</p>
<p>Beta分布中参数α和β的本质含义，即：α表示点击数，β表示曝光数。因为贝叶斯平滑的具体公式就是：</p>
<p>$$SmoothCTR = \frac{(α + CurrentC - 1)}{( α + β + CurrentI -2)}$$</p>
<p>能不能直接把历史点击和历史曝光分别赋值给α和β来进行计算呢？显然不行，因为这么做就会犯之前我们提到的那些问题，比如不同日期的曝光、点击权重应该不一样。所以基础的贝叶斯平滑是不能解决我们刚才提到的问题的，我们需要深入研究Beta分布的特性，用一种新的方法通过先验知识求解α和β，从而计算SmoothCTR。</p>
<p>Beta分布除了两个显性的重要参数α和β外，还有两个相对隐形但同样重要的参数，平均值和中位数，通过平均值和众数可以唯一确定α和β的值，它们的数学关系如下：</p>
<p>$$均值=\frac{\alpha}{\alpha+\beta}$$<br>$$众数=\frac{\alpha-1}{\alpha+\beta-2}$$</p>
<p>因此，如果我们确定了平均值和中位数，那么α和β的值也就确定了（根据均值和中位数求解α和β的过程请读者自行推导），所以可以试着从平均值和中位数入手分析。让我们来看看beta分布的密度函数：<br><img src="https://ooo.0o0.ooo/2017/07/09/596235ef428c7.png" alt=""> </p>
<p>2017.7.9 好困，先回去休息。明日继续。</p>
<h1 id="代码">3. 代码</h1><pre><code>&apos;&apos;&apos;Python
#!/usr/bin/python
# coding=utf-8

import numpy
import random
import scipy.special as special
import pandas as pd
import time
import math
from math import log

class HyperParam(object):
    def __init__(self, alpha, beta):
        self.alpha = alpha
        self.beta = beta
    def sample_from_beta(self, alpha, beta, num, imp_upperbound):
        sample = numpy.random.beta(alpha, beta, num)
        I = []
        C = []
        for click_ratio in sample:
            imp = random.random() * imp_upperbound
            #imp = imp_upperbound
            click = imp * click_ratio
            I.append(imp)
            C.append(click)
        return I, C
    def update_from_data_by_FPI(self, tries, success, iter_num, epsilon):
        &apos;&apos;&apos;estimate alpha, beta using fixed point iteration&apos;&apos;&apos;
        for i in range(iter_num):
            new_alpha, new_beta = self.__fixed_point_iteration(tries, success, self.alpha, self.beta)
            if abs(new_alpha-self.alpha)&lt;epsilon and abs(new_beta-self.beta)&lt;epsilon:
                break
            self.alpha = new_alpha
            self.beta = new_beta
    def __fixed_point_iteration(self, tries, success, alpha, beta):
        &apos;&apos;&apos;fixed point iteration&apos;&apos;&apos;
        sumfenzialpha = 0.0
        sumfenzibeta = 0.0
        sumfenmu = 0.0
        sumfenzialpha = special.digamma(success+alpha) - special.digamma(alpha)
        print sumfenzialpha
        # for i in range(len(tries)):
        #     sumfenzialpha += (special.digamma(success[i]+alpha) - special.digamma(alpha))
        #     sumfenzibeta += (special.digamma(tries[i]-success[i]+beta) - special.digamma(beta))
        #     sumfenmu += (special.digamma(tries[i]+alpha+beta) - special.digamma(alpha+beta))
        return alpha*(sumfenzialpha/sumfenmu), beta*(sumfenzibeta/sumfenmu)
    def update_from_data_by_moment(self, tries, success):
        &apos;&apos;&apos;estimate alpha, beta using moment estimation&apos;&apos;&apos;
        mean, var = self.__compute_moment(tries, success)
        #print &apos;mean and variance: &apos;, mean, var
        #self.alpha = mean*(mean*(1-mean)/(var+0.000001)-1)
        self.alpha = (mean+0.000001) * ((mean+0.000001) * (1.000001 - mean) / (var+0.000001) - 1)
        #self.beta = (1-mean)*(mean*(1-mean)/(var+0.000001)-1)
        self.beta = (1.000001 - mean) * ((mean+0.000001) * (1.000001 - mean) / (var+0.000001) - 1)
    def __compute_moment(self, tries, success):
        &apos;&apos;&apos;moment estimation&apos;&apos;&apos;
        ctr_list = []
        # var = 0.0
        mean = (success / tries).mean()
        if len(tries) == 1:
            var = 0
        else:
            var = (success / tries).var()
        # for i in range(len(tries)):
        #     ctr_list.append(float(success[i])/tries[i])
        # mean = sum(ctr_list)/len(ctr_list)
        # for ctr in ctr_list:
        #     var += pow(ctr-mean, 2)
        return mean, var

def test():
    #设定初始值
    hyper = HyperParam(1, 1)
    #--------sample training data--------
    # I, C = hyper.sample_from_beta(10, 1000, 10000, 1000)
    # print I, C
    train_data = pd.read_csv(&apos;data.csv&apos;,nrows=10000)
    print &apos;read finish&apos;
    # 统计点击次数和转化次数
    key = [&apos;creativeID&apos;]
    train_data[&apos;count&apos;] = 1
    train_data = train_data.groupby(key).agg(&apos;sum&apos;).reset_index()
    # 此时，train_data[&apos;count&apos;]是点击次数
    # train_data[&apos;label&apos;]是点击次数
    print &apos;cal finish&apos;
    I = train_data[&apos;count&apos;]
    C = train_data[&apos;label&apos;]
    print key
    start = time.clock()
    #--------estimate parameter using fixed-point iteration--------
    # 计算平滑
    hyper.update_from_data_by_FPI(I, C, 1000, 0.00000001)
    end = time.clock()
    print hyper.alpha, hyper.beta
    print &apos;run time: &apos;,end - start

    start1 = time.clock()
    #--------estimate parameter using moment estimation--------
    hyper.update_from_data_by_moment(I, C)
    end1 = time.clock()
    print hyper.alpha, hyper.beta
    print &apos;EM run time: &apos;, end1 - start1

if __name__ == &apos;__main__&apos;:
    test()
&apos;&apos;&apos;
</code></pre><h1 id="参考文献">4. 参考文献</h1><ol>
<li><a href="https://zhuanlan.zhihu.com/p/21724759" target="_blank" rel="external">计算广告训练与平滑思想</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 腾讯算法大赛-CVR预估 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CVR,贝叶斯平滑 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[word embedding]]></title>
      <url>/2017/06/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5-CVR-word-embedding/</url>
      <content type="html"><![CDATA[<p>在做比赛的过程中，我曾用过word embedding生成app特征，对结果提升了有几个万分点。</p>
<p>论文：tem2vec: Neural Item Embedding for Collaborative Filtering</p>
<h1 id="思想">1. 思想</h1><p>这篇文章比较朴素，创新性不高，基本是参照了google的word2vec方法，应用到推荐场景的i2i相似度计算中，但实际效果看还有有提升的。主要做法是把item视为word，用户的行为序列视为一个集合，item间的共现为正样本，并按照item的频率分布进行负样本采样，缺点是相似度的计算还只是利用到了item共现信息，1).忽略了user行为序列信息; 2).没有建模用户对不同item的喜欢程度高低。</p>
<h1 id="实现">2. 实现</h1><p>主要代码来自于写论文的作者分享的<a href="https://github.com/Bereket123/Recommendation-based-on-sequence-" target="_blank" rel="external">代码</a></p>
<h1 id="参考文献">3. 参考文献</h1><ol>
<li><a href="https://zhuanlan.zhihu.com/p/24339183" target="_blank" rel="external">DNN论文分享 - Item2vec: Neural Item Embedding for Collaborative Filtering</a></li>
<li><a href="https://view.inews.qq.com/a/20170428A07XNU00" target="_blank" rel="external">达观数据推荐算法实现：协同过滤之item embedding</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 腾讯算法大赛-CVR预估 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 推荐 </tag>
            
            <tag> 腾讯算法大赛 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[不平衡类的处理]]></title>
      <url>/2017/06/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5-CVR-%E4%B8%8D%E5%B9%B3%E8%A1%A1%E7%B1%BB%E7%9A%84%E5%A4%84%E7%90%86/</url>
      <content type="html"><![CDATA[<p>最近在做比赛，发现在工业上，很多分类问题的标签分布都是不平衡的。如参考文献<a href="http://bourneli.github.io/machine-learning/prml/2016/12/19/compensating-for-class-priors.html" target="_blank" rel="external">标签倾斜修正方法记要</a>所属，比如用分类器去判断x光片中的癌症，这是一个二元分类问题，由于癌症的比例是非常小的，比如0.001。那么，将这些样本放到大多数分类模型中训练，模型的表现会非常相似，将所有数据都预测为没有癌症，因为这样也可以得到99.999%的准确率。</p>
<h1 id="常见的解决办法">1. 常见的解决办法</h1><p>参考文献<a href="https://www.jiqizhixin.com/articles/1dd8da6e-ae24-4fc5-ab90-ee39020bc5ff" target="_blank" rel="external">解决真实世界问题：如何在不平衡类上使用机器学习？</a>说，从不平衡数据中学习，是一项已被研究了 20 年之久的问题。它曾是许多论文、研讨会、特别议程的主题（一项最近的调查就有大约 220 个引用）。人们尝试了许多方法，但结果各不相同，所以至今没有得到明晰的答案。当数据科学家们第一次遇到这个问题，他们往往会问：「如果我的数据是不平衡的，我该怎么做？」而这一问题是没有固定答案的，就像你问「哪个学习算法是最好的」一样：<strong>答案取决于数据。</strong></p>
<p>一般来说，有下面几种方法：</p>
<ul>
<li><p>什么也不做</p>
</li>
<li><p>通过某些方法使得数据更加平衡：</p>
</li>
<li><ul>
<li>对少数类进行过采样</li>
</ul>
</li>
<li><ul>
<li>对多数类进行欠采样</li>
</ul>
</li>
<li><ul>
<li>合成新的少数类</li>
</ul>
</li>
<li><ul>
<li>舍弃所有少数类，切换成一个异常检测框架。</li>
</ul>
</li>
<li><p>在算法层面之上（或之后）：</p>
</li>
<li><ul>
<li>调整类的权重（错误分类成本）</li>
</ul>
</li>
<li><ul>
<li>调整决策阈值</li>
</ul>
</li>
<li><ul>
<li>使已有的算法对少数类更加敏感</li>
</ul>
</li>
<li><ul>
<li>构造一个在不平衡数据上表现更好的全新算法。</li>
</ul>
</li>
</ul>
<h1 id="一种标签倾斜修正方法">2. 一种标签倾斜修正方法</h1><p>参考文献<a href="">Practical Lessons from Predicting Clicks on Ads at<br>Facebook</a>6.3指出，欠采样可以加快训练速度，提升模型表现。需要注意的是，就算数据被欠采样，其实也可以通过在欠采样空间中对预测结果进行修正。例如，在采样之前CTR只有0.1%，那么我们对负样本欠采样0.01，那么CTR就会变为10%。为了修正结果，使得CTR恢复到0.1%,我们可以通过公式：<br>$$q=\frac{p}{p+(1-p)/w}$$<br>其中，$p$是欠采样空间下预测的概率，<br>$w$是对负样本的采样率。</p>
<p>在这里我决定先复习一下先验概率、后验概率</p>
<h2 id="先验概率、后验概率">2.1. 先验概率、后验概率</h2><p><strong>先验概率</strong>是指事件尚未发生，对该事件发生的概率的估计，是在缺乏某个事情的情况下描述一个变量。<br>先验概率可以通过已知的关于事件本身的先验知识得到，蒙特卡洛方法也可以用于计算先验概率。<br><strong>后验概率</strong>是指在事件已经发生的条件下，求该事件发生原因是由某个因素引起的可能性的大小，是考虑一个事件之后的条件概率。<br>后验概率可以基于 贝叶斯定理，通过先验概率乘以似然度，再归一化得到。具体来说，贝叶斯公式：<br>$$P(h|D)=\frac{P(D|h)P(h)}{p(D)}$$<br>其中，$P(h)$为$h$的先验概率，$P(h|D)$为$h$的后验概率。<br>通常，事件A在事件B（发生）的条件下的概率，与事件B在事件A（发生）的条件下的概率是不一样的；然而，这两者是有确定的关系的，贝叶斯定理就是这种关系的陈述。贝叶斯公式的一个用途在于通过已知的三个概率函数推出第四个。</p>
<h2 id="标签倾斜修正">2.2. 标签倾斜修正</h2><p>参考文献<a href="http://bourneli.github.io/machine-learning/prml/2016/12/19/compensating-for-class-priors.html" target="_blank" rel="external">标签倾斜修正方法记要</a>通过理论推导来验证这个结论。<br>上参考文献作者提到，PRML的1.5.4节中介绍了一种标签倾斜修正的方法。</p>
<p>首先，你的模型必须是一个软分类器，即预测值为0到1之间的概率。假设输入向量x，预测标签$C_k$，那么可以用条件概率表示，即计算$p(C_k|x)$的概率。根据贝叶斯公式，条件概率可以如下变化：<br>$$p(C_k|x)=\frac{p(x|C_k)p(C_k)}{p(x)}$$</p>
<p>上面是没有做重采样时，得到概率。当做重采样时，只是改变了标签$C_k$的先验概率$p(C_k)$，即将$p(C_k)$变为$p’(C_k)$（其实就是标签$C_k$的先验分布而已）。而$p(x)$是条件$x$发生的概率，不会变化。$p(x|C_k)$是后验概率，也不会变化。【问题，为什么不变？我感觉是因为特征是采样前的特征，因此这个没变】</p>
<p>因为是对负样本进行了抽样，假设对负样本抽样比例为$w$，抽样后：</p>
<p>$$n’(0)=n(0)\times w,n’(1)=n(1)$$</p>
<p>易知：<br>$$p(1)=\frac{n(1)}{n(1)+n(0)}=\frac{n’(1)}{n’(1)+n’(0)/ w}$$<br>$$=\frac{p’}{p’+(1-p’)/w}$$<br>其中，$n(C_k)$表示$C_k$的个数</p>
<p>我们推导出了先验概率$p’(C_k)$与$p(C_k)$的关系。那么，如果我们想修正$p(C_k|x)$，则：</p>
<p>$$p(1|x) = \frac{p(x|1)p(1)}{p(x)} = \frac{p(x|1)p’(1)p(1)}{p(x)p’(1)}$$<br>$$=p’(1|x)\frac{p(1)}{p’(1)}=p’(1|x)\frac{p}{p’}$$</p>
<p>而由之前的推导我们可知$p=\frac{p’}{p’+(1-p’)/w}$，代入得：<br>$$p(1|x)=p’(1|x)\frac{p}{p’}=p’(1|x)\frac{\frac{p’}{p’+(1-p’)/w}}{p’}$$<br>$$=p’(1|x)\frac{1}{p’+(1-p’)/w}$$</p>
<p>需要注意的是，$p’(1|x)$是预测出来的概率，$p’$是抽样之后正样本的比例，而在facebook的论文中，假设$p’\approx p’(1|x)$（也就是说，我们假设了预测集中，1出现的概率=预测出来的为1的概率。我的理解就是，我们完全信任了预测的结果），并记$q=p’(1|x)$则以上公式变为：</p>
<p>$$p(1|x)=\frac{q}{q+(1-q)/w}$$</p>
<p>【问题：在预测时，$p’$可不可以变为预测集的正样本比例$p’$】</p>
<h2 id="结论">2.3. 结论</h2><p>在欠采样中，假设对负样本采样率为$w$，则直接将结果按照如下公式修正即可：</p>
<p>$$p=\frac{q}{q+(1-q)/w}$$</p>
<p>其中：</p>
<ul>
<li>$q$是在欠采样之后，模型预测出来的概率。</li>
<li>$p$是修正后的概率。</li>
</ul>
<p>当w=0.1时，变换其实为：</p>
<p><img src="https://ooo.0o0.ooo/2017/06/10/593c0b680d2b7.png" alt=""> </p>
<p>上面是y1=q(不做变换)，下面是本变换y2。</p>
<p>而如果我们将y3=y1-y2绘出：<br><img src="https://ooo.0o0.ooo/2017/06/10/593c0bc5aa670.png" alt=""> </p>
<p>我们发现，概率大的压缩的小。<br>因为你负样本采样了之后，就是会预测的比实际的高一点，所以要给它压下去。</p>
<p>附上matlab代码：<br>    q=0.001:0.01:1;<br>    y1=1./(1+(1./q-1)./0.1);<br>    y2 = q;<br>    plot(q,y1);<br>    hold on;<br>    plot(q,y2);<br>    hold on;<br>    y3 = y2-y1;<br>    plot(q,y3)</p>
<h2 id="小trick（有错，删掉）">2.4. 小trick（有错，删掉）</h2><p>如果在已知样本中，正样本的概率$p$,那么：</p>
<p>$$p’(1)=\frac{n’(1)}{n’(1)+n’(0)}=\frac{n(1)}{n(1)+n(0)\times w}$$<br>$$=\frac{1}{1+\frac{n(0)\times w}{n(1)}}=\frac{1}{1+\frac{p(0)\times w}{p(1)}}$$<br>$$=\frac{p(1)}{p(1)+p(0)\times w}=\frac{p}{p+(1-p)\times w}$$</p>
<p>而因为：<br>$$p(1|x)=p’(1|x)\frac{p}{p’}$$</p>
<p>代入得：</p>
<p>$$p(1|x)=p’(1|x)\frac{p}{\frac{p}{p+(1-p)\times w}}$$<br>$$=p’(1|x)(p+(1-p)\times w)$$</p>
<p>这里的p是样本中，正样本的概率。</p>
<h1 id="参考文献">3. 参考文献</h1><ol>
<li><a href="http://bourneli.github.io/machine-learning/prml/2016/12/19/compensating-for-class-priors.html" target="_blank" rel="external">标签倾斜修正方法记要</a></li>
<li><a href="https://www.jiqizhixin.com/articles/1dd8da6e-ae24-4fc5-ab90-ee39020bc5ff" target="_blank" rel="external">解决真实世界问题：如何在不平衡类上使用机器学习？</a></li>
<li><a href="https://mqshen.gitbooks.io/prml/content/" target="_blank" rel="external">PRML(《模式识别和机器学习》)翻译</a></li>
<li><a href="http://bourneli.github.io/ml/2017/05/25/gdbt-lr-facebook-paper.html?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io" target="_blank" rel="external">GBDT特征转换+LR总结</a></li>
<li><a href="http://sighingnow.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/prior_posterior_probability_and_estimation.html" target="_blank" rel="external">先验和后验概率以及估计</a></li>
<li><a href="">Practical Lessons from Predicting Clicks on Ads at<br>Facebook</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 腾讯算法大赛-CVR预估 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 特征工程 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[腾讯社交广告APP转化率预估预估初赛&复赛思路总结]]></title>
      <url>/2017/06/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5-CVR-Tencent_CVR%E9%A2%84%E4%BC%B0%E5%88%9D%E8%B5%9B%E6%80%9D%E8%B7%AF%E6%80%BB%E7%BB%93/</url>
      <content type="html"><![CDATA[<p>“这一段奔波太过匆忙，有时来不及回头张望。”</p>
<p>腾讯“人工寻找trick”大赛初赛今天结束了。最终初赛线上logloss为0.099104，排名为64名：<img src="http://om1bxijvl.bkt.clouddn.com/2017-06-07-15-22-48.png" alt=""> </p>
<p>复赛成绩0.101941，排名26名：<img src="https://ooo.0o0.ooo/2017/07/11/59646ce45d3e0.png" alt=""> </p>
<p>虽然与前排大神的分相差甚远，虽结果不那么如人意，也是对这个领域入了个门。</p>
<h1 id="赛题">1. 赛题</h1><p>详细赛题见<a href="http://algo.tpai.qq.com/home/information/index.html" target="_blank" rel="external">官方网站</a></p>
<p><strong>已知</strong>：17-30天移动APP的广告、用户的转化情况，及相关上下文。<br><strong>预测</strong>：第31天指定用户和对应广告的转化率。</p>
<p><strong>评估方式</strong>：<br>$$logloss=-\frac{1}{N}\sum_{i=1}^N(y_ilog(p_i)+(1-y_i)log(1-p_i))$$</p>
<p>其中，</p>
<ul>
<li>N是测试样本总数</li>
<li>$y_i$是二值变量，取值为0或1，表示第i个样本的label</li>
<li>$p_i$是模型预测第i个样本label为1的概率</li>
</ul>
<p>总之，就是预测的越准越好（这不废话么2333）</p>
<h1 id="主要流程">2. 主要流程</h1><p>这是Kaggle上数据挖掘比赛的黄金流程图：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-06-07-15-44-01.png" alt=""> </p>
<p>其实对于这个比赛的初赛而言，线上是容易过拟合的。因为线上只有一个集，可反复提交多次来使得线上得分很高，但实际上模型是有些过拟合的。不过这不是重点。</p>
<p>接下来一步步做说明</p>
<h1 id="数据分析与清洗">3. 数据分析与清洗</h1><p>训练集train.csv没有大问题，我注意的只是后几天的一些数据没有回流的问题。</p>
<p>值得注意的是，本次竞赛的训练数据提供的截止第31天0点的广告日志，因此，对于最后几天的训练数据，也就是说后五天部分用户实际上是转化了，但广告主还没有来得及将这条转化汇报给广告系统，导致数据集中的label被误标记为了0（实际上是1）。（如果我还没有描述清楚，这里具体可以看官网赛题FAQ.1）</p>
<p>这里我采取了一种很暴力的方法，即去掉每个广告主最后一次回流之后的数据。</p>
<p>通过分析我们发现，其实有近一半的广告主还是尽职尽责的，直到30号23点还在反馈回流。只有有一部分广告主在30号下班后，或29号下班后就不回流了。所以我们将这些广告主最后一次回流之后的数据都删除（其实这些都是负样本），这样就在一定程度上减少了不准的负样本。</p>
<p>这样筛去了大概有3万条，也不算多。</p>
<h1 id="特征工程">4. 特征工程</h1><p>一开始的时候我们采用了很多基本特征，即各种ID（AppID,UserID,creativeID,pisitionID等）的onehot编码，又对单特征进行了一定的统计。后来看了大神“为情所困的少年”的分享，才反应过来其实无论是onehot还是对ID单维度的统计特征，其实都是对于一个特征的一种表达，从一定意义上是重复的。我个人感觉onehot之后的稀疏特征更适合于线性模型，如LR；而统计量的连续特征更适合于树模型，如GBDT。</p>
<p>回头来看，其实特征工程需要根据模型预先选择方向。李沐说过，模型是使用离散特征还是连续特征，其实是一个“海量离散特征+简单模型” 同 “少量连续特征+复杂模型”的权衡。既可以离散化用线性模型，也可以用连续特征加深度学习。就看是喜欢折腾特征还是折腾模型了。通常来说，前者容易，而且可以n个人一起并行做，有成功经验；后者目前看很赞，能走多远还须拭目以待。</p>
<p>就此题来说，有两个方向：</p>
<h2 id="海量离散特征-简单模型">4.1. 海量离散特征+简单模型</h2><p>如果我们懒得分析数据（初期我们就是这样），并且有还不错的设备（自以为64G内存很有优势），我们可以直接选择这个方向。</p>
<p>初期的时候，我们是选择的这条路。<br>当时只有简单的ID类特征，以及ID类特征的交叉组合，将这些特征onehot之后输入了LR模型。</p>
<p>关于特征组合，我在后面会介绍到。</p>
<p>做完特征和特征组合，将它onehot之后输入模型就可以了。</p>
<p>对于LR这种线性模型来说，它更适合于onehot类型的特征，首先它对于稀疏高维特征处理是无压力的，其次离散化后的特征对异常数据有很强的鲁棒性，这些在参考文献2<a href="http://blog.csdn.net/yang090510118/article/details/39478033" target="_blank" rel="external">逻辑回归LR的特征为什么要先离散化</a>中可以看到。</p>
<p>但由于ID类特征非常多，例如本题的UserID有好几百万个。这时就会带来维度灾难问题，见参考文献4<a href="https://zhuanlan.zhihu.com/p/26945814" target="_blank" rel="external">机器学习中的维度灾难</a>。不仅如此，这时基本上也就被设备问题限制死了。这很烦。于是我们就换模型了。</p>
<h2 id="少量连续特征-复杂模型">4.2. 少量连续特征+复杂模型</h2><p>这是我们暂定的一个方案，就是采用少量、但表现很不错的组合特征统计量，以及一些手工提取的特征（如用户历史安装次数、APP历史被安装次数），这些特征主要来源于群内“为情所困”大神分享的一张表。</p>
<p>模型我们采用的是GBDT，直接使用了陈天奇大牛的xgboost框架。模型我暂时还没有很认真地研究，只是熟悉了一些参数，为决赛做了一些准备。</p>
<h1 id="特征组合">5. 特征组合</h1><p>特征组合真是我遇到的一个大难题。</p>
<h2 id="怎么表达组合特征？">5.1. 怎么表达组合特征？</h2><p>说到特征组合，从统计的角度解释，基本特征仅仅是真实特征分布在低维空间的映射，不足以描述真实分布，加入组合特征是为了在更高维空间拟合真实分布，使得预测更准确。<br>组合特征我现在用过的有以下两种方式：</p>
<p><strong>对离散ID进行hash生成新特征</strong></p>
<p>在初期用LR的时候，我们采用的方式是hash。即对两个ID做hash运算，得到一个新特征。这是一个很巧妙的方法。例如下面这个表，我们做哈希：</p>
<p>$$age\times 10 + gendar$$</p>
<p>得到第三列：</p>
<table>
<thead>
<tr>
<th style="text-align:center">age</th>
<th style="text-align:center">gendar</th>
<th style="text-align:center">hash</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">10</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">1</td>
<td style="text-align:center">21</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">2</td>
<td style="text-align:center">32</td>
</tr>
</tbody>
</table>
<p>第三列的的特征的取值有两位，十位是age,个位是gendar。新特征是一种新的交叉特征的体现。</p>
<p><strong>对组合进行统计生成新特征</strong></p>
<p>像之前“为情所困”大神说过的那样，其实无论onehot还是统计特征，其实都是对于一个特征的一种表达。因为后期我们采用了GBDT，因此我们弃用了之前的hash组合方式，而选用统计量（即点击量、转化量和转化率）。这样就在一个维度上表达了这两个特征的组合，而且非常便于计算。</p>
<h2 id="选谁做特征组合？">5.2. 选谁做特征组合？</h2><p>需要注意的是，特征组合也不是随便从原来的特征里摘出来两列就做组合。这种随意地对特征堆叠其实会增加模型的负担，而且这些其实就像是“随机数一般的，毫无作用的特征”，可能会使得效果变差。</p>
<p>究竟对谁做组合，这也是一直困扰我们的问题。以下是我搜集到的几种方案：</p>
<p><strong>迭代选取方式</strong></p>
<p>Jerrylin大神曾经说过，可以先对一个组合做groupby分析，看看转化率的分布。可是我遇到了一个瓶颈——大多数特征的转化率分布都是不均匀的，组合起来就更不均匀了。不知道大神是怎么解决的，也许是计算这个分布的方差？【这是个问题，等来日解决，我再回来填坑】<br>大神刚才回我了，他说他是按照gbdt给的一个评分，选取评分较高的几个进行组合，然后再次输入模型进行迭代筛选。<br>在此我要再次偷偷感谢一下这位大神。要是没有他，我可能还会在二百名外挣扎。</p>
<p>刚才风，飞扬。。大神告诉我，其实xgb给的评分也是只能作为一个参考，因为不一定组合之后给会更高。</p>
<p>忆『凌』殇大神说，构造的特征很可能相关性很高，然后这两个特征的重要性肯定都不低。但是因为相关性高反而会影响性能。这个相关性可以计算这两个特征的相关系数corrcoef来得到。</p>
<p><strong>穷举后用卡方检验筛特征</strong></p>
<p>参考文献<a href="http://202.197.191.206:8080/30/text/chapter04/4_8.htm" target="_blank" rel="external">描述量选择及特征的组合优化</a>提到，由于任何非穷举的算法都不能确保所得结果是最优的，因此要得最优解，就必需采用穷举法，只是在搜索技术上采用一些技巧，使计算量有可能降低。</p>
<p>我的学长“酱紫”对此有一种建议就是直接对所有基本特征进行遍历两两组合，然后用卡方检验筛出来一些比较好的特征。这种方式很简单，大多数工作只需要交给模型来完成。</p>
<p><strong>循环特征消减和特征重要性评级</strong></p>
<p>参考文献<a href="http://www.jianshu.com/p/8f6f94f1d275" target="_blank" rel="external">scikit-learn系列之特征选择</a>中提到，在scikit-learn中有两种特征选择的方法，一种叫做循环特征消减(Recursive Feature Elimination)和特征重要性评级 (feature importance ranking)。</p>
<ul>
<li>循环特征消减：其实就是循环地移除变量和建立模型，通过模型的准确率来评估变量对模型的贡献。这种方式很暴力，但也很准确。但是问题是我们没有那么多的时间来等待模型训练这么多次。</li>
<li>特征重要性评级：“组合决策树算法”（例如Random Forest or Extra Trees）可以计算每一个属性的重要性。重要性的值可以帮助我们选择出重要的特征。</li>
</ul>
<p><strong>用GBDT筛特征</strong></p>
<p><em>主要思想</em>：<br>GBDT每棵树的路径直接作为LR输入特征使用。</p>
<p><em>原理</em>：<br>用已有特征训练GBDT模型，然后利用GBDT模型学习到的树来构造新特征，最后把这些新特征加入原有特征一起训练模型。构造的新特征向量是取值0/1的，向量的每个元素对应于GBDT模型中树的叶子结点。当一个样本点通过某棵树最终落在这棵树的一个叶子结点上，那么在新特征向量中这个叶子结点对应的元素值为1，而这棵树的其他叶子结点对应的元素值为0。新特征向量的长度等于GBDT模型里所有树包含的叶子结点数之和。</p>
<p>【这里其实不太懂，一会问问张思遥】</p>
<p><em>步骤</em>：</p>
<ol>
<li>首先要切分数据集，一部分用于训练GBDT，另一部分使用训练好的GBDT模型</li>
<li>GBDT模型的apply方法生成x在GBDT每个树中的index，然后通过onehot编码做成特征。</li>
<li>新的特征输入到分类（如LR）模型中训练分类器。</li>
</ol>
<p><em>实现</em>：<br>参考文献<a href="http://blog.csdn.net/shine19930820/article/details/71713680" target="_blank" rel="external">GBDT原理及利用GBDT构造新的特征-Python实现</a>的末尾有一个调用GBDT训练模型构建树，调用<a href="http://blog.csdn.net/shine19930820/article/details/71713680" target="_blank" rel="external">apply()</a>方法得到特征，然后将特征通过one-hot编码后作为新的模型输入LR进行训练。<a href="http://scikit-learn.org/stable/auto_examples/ensemble/plot_feature_transformation.html#example-ensemble-plot-feature-transformation-py" target="_blank" rel="external">feature trainsformation with ensembles of tree官方文档</a></p>
<h2 id="本赛题特征构造">5.3. 本赛题特征构造</h2><p><a href="https://github.com/z564808896/Tencent_Social_Ads" target="_blank" rel="external">竟然有这种操作队分享</a>总结得非常好，主要特征是分为以下几类：</p>
<ul>
<li>Trick特征：<br>通过观察原始数据是不难发现的,有很多只有clickTime和label不一样的重复数据，按时间排序发现重复数据如果转化，label一般标在头或尾，少部分在中间，在训练集上出现的情况在测试集上也会出现，所以标记这些位置后onehot，让模型去学习，再就是时间差特征，关于trick我比赛分享的这篇文章有较详细的说明。比赛后期发现了几个和这个trick相类似的文章1和文章2，可以参考。</li>
<li><p>统计特征：<br>原始特征主要三大类：广告特征、用户特征、位置特征，通过交叉组合算统计构造特征，由于机器限制，统计特征主要使用了转化率，丢掉了点击次数和转化次数。初赛利用了7天滑窗构造，决赛采用了周冠军分享的clickTime之前所有天算统计。三组合特征也来自周冠军分享的下载行为和网络条件限制，以及用户属性对app需求挖掘出。贝叶斯平滑user相关的特征特别废时间，初赛做过根据点击次数阈值来操作转化率，效果和平滑差不多但是阈值选择不太准。</p>
</li>
<li><p>活跃数特征：</p>
</li>
<li><p>特征构造灵感来自这里,比如某个广告位的app种数。</p>
</li>
<li><p>均值特征：</p>
</li>
<li><p>比如点击某广告的用户平均年龄</p>
</li>
<li><p>平均回流时间特征：<br>利用回流时间方式不对的话很容易造成leackage，这里参考了官方群里的分享，计算了每个appID的平均回流时间，没有回流的app用其所在类的平均回流时间代替</p>
</li>
<li><p>用户流水和历史特征：<br>利用installed文件关联user和app获得历史统计特征，利用actions进行7天滑动窗口获得用户和app流水特征。</p>
</li>
</ul>
<h2 id="一些特殊的东西">5.4. 一些特殊的东西</h2><p><strong>多线程抽特征</strong></p>
<p>决赛数据集太大，而我们组合特征非常多。因此我们采用了多线程抽特征的方式。<br>代码见<a href="https://github.com/zsyandjyhouse/TencentAD_contest" target="_blank" rel="external">TencentAD_contest</a>，extra_rate_thread_0623.py<br><strong>贝叶斯平滑</strong><br>在决赛时，我们还使用了贝叶斯平滑。针对Pandas，我们对网上已有的代码进行了改进。<br><a href="https://jiayi797.github.io/2017/07/09/%E8%BD%AC%E5%8C%96%E7%8E%87%E9%A2%84%E4%BC%B0%E4%B9%8B%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%B9%B3%E6%BB%91/" target="_blank" rel="external">贝叶斯平滑笔记</a><br><strong>word embedding</strong><br>这个我没有做过多研究，这里是<a href="https://jiayi797.github.io/2017/06/21/word-embedding/" target="_blank" rel="external">word embedding笔记</a><br><strong>SVD分解</strong><br>思路和代码主要看我这篇博客<a href="https://jiayi797.github.io/2017/07/10/SVD%E5%88%86%E8%A7%A3/" target="_blank" rel="external">SVD分解</a></p>
<h1 id="训练集构造">6. 训练集构造</h1><p>训练集特征做不好，就很容易造成泄露。这是我试过的两种方式：</p>
<ol>
<li>用滑动窗口，即每天的前七天的统计（统计指统计转化量、点击量、转化率，下同）来作为第本天的特征。并拿30号来做线下测试集。<br>如下图所示：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-06-07-21-49-53.png" alt=""><br>经测试我们发现，即使我们去掉了30号的部分负样本，还是有一些问题的。因此我们将时间区间改了一下：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-06-07-21-53-21.png" alt=""><br>这样做出于两种目的：一是尽量做到了线上线下统一，二是不让模型学习30号的样本数据，防止一些错误样本被模型学到。</li>
<li>用第一周统计，第二周做交叉验证并训练模型。如下图所示：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-06-07-21-59-59.png" alt=""> </li>
</ol>
<p>相信很多人都用的是这两种其中的一种。我是一个对自己极度不自信的人，来来回回换了好几次。最终觉得第2种方式很稳定，线上线下较统一。第1种方式特征更新较快，模型更准确，但带来的问题就是线上线下不太统一。</p>
<h1 id="模型训练和验证">7. 模型训练和验证</h1><p>至此特征工程已经完毕，开始训练。</p>
<p>训练其实没什么好说的，只要注意一下别过拟合就可以。</p>
<p>初赛我们采用的xgboost，决赛用的lightgbm。其实都是对GBDT的实现，两者都很好，但lightGBM更快一些，因为它只对部分节点进行生长。</p>
<h2 id="stacking">7.1. stacking</h2><p>在初赛的时候听到最多的就是stacking魔法了。文章<a href="https://www.qcloud.com/community/article/895055" target="_blank" rel="external">【SPA大赛】腾讯广告点击大赛：对stacking的一些基本介绍</a>非常详细地介绍了stacking大法。我觉得这句话很好：“在我看来stacking严格来说不能称为一种算法，我理解的是一种非常精美而复杂的对模型的集成策略。”</p>
<h1 id="总结">8. 总结</h1><p>平时在学习的过程中，过于注重理论的推导，只是在一遍遍地看那些公式。但没有切身实践过，感受不到模型真正的威力和缺憾。通过这次比赛，还是收获比较多的。注意到了平时学习过程中自以为不重要的、很容易被忽略的细节。</p>
<p>在初赛中，我们其实并没有注重模型的调参等，而是一直在做特征工程。其实我初期也不知道究竟该怎么办。但JerryLin大神用他的言行教会我，特征决定了结果的上限，而模型只是在不断地逼近这个上限而已。只有得到了好的特征，才会拿到好的模型。</p>
<p>做了这么久的特征工程，最大的感想就是，只有认认真真、踏踏实实分析数据，才能得到好的特征。过度依赖算法在工业上是不可靠的。</p>
<p>越来越发现务实基础的必要性。比如LR中为什么要采用正则化项，为什么GBDT能有筛特征的功效，为什么树模型容易过拟合，为什么为什么……这些为什么直接决定了在遇到问题的时候能不能独立解决。而不能像我现在一样，分分钟心态爆炸，宛如一只无头的苍蝇。</p>
<p>还有就是，写代码一定要认认真真地写。不能直接把别人的直接粘过来用，这样是极其不负责的，也非常容易出错。在比赛的过程中，我的xgboost预测的代码是直接粘贴的O2O优惠券使用预测的冠军的代码，但他那个的目标是auc，因此他将结果映射到了（0,1）区间上。这句话让我白白浪费了很久很久的时间去试特征，结果发现线上线下不统一，整个人直接崩溃。</p>
<p>希望自己在未来的日子里，能将周志华老师的《机器学习》和李航老师的《统计学习方法》这两本书吃透，而不是像现在这样，狗熊掰棒子。</p>
<p>失败乃成功之母。</p>
<p>天行健，君子以自强不息。</p>
<h1 id="项目代码">9. 项目代码</h1><p><a href="https://github.com/zsyandjyhouse/TencentAD_contest" target="_blank" rel="external">TencentAD_contest</a></p>
<h1 id="参考文献">10. 参考文献</h1><ol>
<li><a href="https://zhuanlan.zhihu.com/p/26820998" target="_blank" rel="external">Kaggle 数据挖掘比赛经验分享</a></li>
<li><a href="http://blog.csdn.net/yang090510118/article/details/39478033" target="_blank" rel="external">逻辑回归LR的特征为什么要先离散化</a></li>
<li><a href="http://breezedeus.github.io/2014/11/20/breezedeus-feature-hashing.html" target="_blank" rel="external">特征哈希（Feature Hashing）</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/26945814" target="_blank" rel="external">机器学习中的维度灾难</a></li>
<li><a href="http://blog.jasonding.top/2015/11/12/Feature%20Engineering/%E3%80%90%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E3%80%91%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E4%B8%8E%E7%89%B9%E5%BE%81%E5%AD%A6%E4%B9%A0/" target="_blank" rel="external">【特征工程】特征选择与特征学习</a></li>
<li><a href="http://202.197.191.206:8080/30/text/chapter04/4_8.htm" target="_blank" rel="external">描述量选择及特征的组合优化</a></li>
<li><a href="http://www.jianshu.com/p/8f6f94f1d275" target="_blank" rel="external">scikit-learn系列之特征选择</a></li>
<li><a href="http://blog.csdn.net/shine19930820/article/details/71713680" target="_blank" rel="external">GBDT原理及利用GBDT构造新的特征-Python实现</a></li>
<li><a href="http://www.bigbear2017.com/blog/2016/11/02/facebook-ctr-paper/" target="_blank" rel="external">很好的文献资料Facebook CTR Paper</a></li>
<li><a href="https://github.com/z564808896/Tencent_Social_Ads" target="_blank" rel="external">竟然有这种操作队分享</a></li>
<li><a href="https://www.qcloud.com/community/article/895055" target="_blank" rel="external">【SPA大赛】腾讯广告点击大赛：对stacking的一些基本介绍</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 腾讯算法大赛-CVR预估 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[特征选择与正则化]]></title>
      <url>/2017/05/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E4%B8%8E%E6%AD%A3%E5%88%99%E5%8C%96/</url>
      <content type="html"><![CDATA[<p>特征选择：很重要</p>
<p><strong>tip:冗余特征(redundant feature)</strong>：</p>
<ul>
<li>本特征能被其它特征中推演出来。它不一定有坏处，但也不一定有好处。例如：考虑立方体对象，若已有特征“长”、“宽”，则“底面积”是冗余特征。</li>
<li>冗余特征在很多时候不起作用，会增加学习过程的负担。</li>
<li>但如果学习目标是估算立方体体积，则“底面积”特征会对学习更好。</li>
</ul>
<p>结论：如果某冗余特征恰好对应完成学习任务所需的“中间概念”，则该冗余特征是有益的。</p>
<h1 id="子集搜索与评价">1. 子集搜索与评价</h1><p>特征选取时，若没有任何领域知识进行先验假设，只能遍历所有可能子集。–&gt;不可取！</p>
<p><strong>可行做法</strong>:<br>产生个“候选子集”，评价它的好坏，基于评价结果产生下一个候选子集。</p>
<h2 id="问题一，如何评价结果获取下一个候选特征子集？">1.1. 问题一，如何评价结果获取下一个候选特征子集？</h2><p><strong>子集搜索</strong></p>
<ol>
<li>前向搜索</li>
</ol>
<ul>
<li>给定特征集合${a_1,a_2,…,a_d}$,将每个特征看做一个候选子集。对d个候选单特征子集进行评价，假定${a_2}$最优，将${a_2}$做为第一轮选定集；</li>
<li>加入一个新特征，构成包含两个特征的候选子集，假定在这$d-1$个候选两特征子集中${a_2,a_4}$最优，则将${a_2,a_4}$作为本轮选定集；</li>
<li>…</li>
<li>k+1轮时，不再更好，停止迭代</li>
</ul>
<ol>
<li>后向搜索<br>每次都删除掉一个特征</li>
</ol>
<h2 id="问题二，如何评价候选特征子集？">1.2. 问题二，如何评价候选特征子集？</h2><p><strong>信息增益</strong></p>
<ul>
<li>给定数据集$D$,假定$D$中第$i$类样本所占的比例为$p_i(i=1,2,…,|Y|)$.</li>
<li>假定所有样本属性均为离散型</li>
<li>对属性子集$A$,假定根据其取值将$D$分成了$V$个子集${D^1,D^2,…,D^V}$,每个子集中的样本在A上取值相同，则属性子集$A$的信息增益为：</li>
</ul>
<p>$$Gain(A)=Ent(D)-\sum_{v=1}^V\frac{|D^v|}{|D|}Ent(D^v)$$</p>
<p>其中信息熵定义为：</p>
<p>$$Ent(D)=-\sum_{k=1}^{|y|}p_klog_2p_k$$</p>
<p>信息增益$Gain(A)$越大，特征子集A包含的有助于分类的信息越多。</p>
<h2 id="总结">1.3. 总结</h2><p>特征选择方法=子集搜索+子集评价</p>
<p>常见特征选择方法：</p>
<ul>
<li>过滤式(filter)</li>
<li>包裹式(wrapper)</li>
<li>嵌入式(embedding)</li>
</ul>
<h1 id="过滤式选择-filter">2. 过滤式选择(filter)</h1><p>概念：先特征选择，再训练模型</p>
<p>特点：特征选择与模型学习无关</p>
<p>===来日填坑===</p>
<h1 id="包裹式选择">3. 包裹式选择</h1><p>概念：把最终将要使用的学习器的性能作为特征子集的评价准则</p>
<p>特点：需要多次训练学习器</p>
<p>===来日填坑===</p>
<h1 id="嵌入式选择与L1正则化">4. 嵌入式选择与L1正则化</h1><p>概念：将特征选择过程与学习器训练过程融为一体，两者在同一个优化过程中完成</p>
<p>给定数据集$D={(x_1,y_1),(x_2,y_2),…(x_m,y_m)}$,其中$x\in R^d,y\in R$.</p>
<p>考虑最简单的线性回归，以平方误差为损失函数，则优化目标为：</p>
<p>$$min_w\sum_{i=1}^m(y_i-w^Tx_i)^2$$</p>
<p>当样本特征很多，而样本数较少时，上式很容易陷入过拟合。解决方案，正则化项。</p>
<p>$L_2$范数正则化（“岭回归”(redge regression)）：</p>
<p>$$min_w\sum_{i=1}^m(y_i-w^Tx_i)^2+\lambda ||w||_2^2$$</p>
<p>$L_1$范数正则化：</p>
<p>$$min_w\sum_{i=1}^m(y_i-w^Tx_i)^2+\lambda ||w||_1$$</p>
<p>区别：$L_2$比$L_1$更容易获得“稀疏”(sparse)解，即它求得的$w$会有更少的非零分量。<br>（这里一定要看一下西瓜书-253页的解释）</p>
<h2 id="正则化的理解">4.1. 正则化的理解</h2><p>以以下的拟合为例：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-05-30-18-21-29.png" alt=""> </p>
<p>在图二中，明显是因为高次项的系数$\theta_3,\theta_4$过大造成的。</p>
<p>因此我们加入正则化项：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-05-30-18-24-26.png" alt=""> </p>
<p>即给目标函数加一点东西。</p>
<p>现在，如果我们要最小化这个函数，那么为了最小化这个新的代价函数，我们要让$θ3$和$θ4$尽可能小。因为，如果你在原有代价函数的基础上加上1000乘以$θ3$这一项，那么这个新的代价函数将变得很大，<strong>所以，当我们最小化这个新的代价函数时，我们将使$θ3$的值接近于0，同样$θ4$的值也接近于0，</strong>就像我们忽略了这两个值一样。如果我们做到这一点（$θ3$和$θ4$接近0），那么我们将得到一个近似的二次函数。</p>
<p>更一般地：</p>
<p>$L_2$范数正则化：</p>
<p>$$min_w\sum_{i=1}^m(y_i-w^Tx_i)^2+\lambda ||w||_2^2 $$<br>$$= min_w\sum_{i=1}^m(y_i-w^Tx_i)^2+\lambda\sqrt{\sum_{n=1}^nw_i^2}$$</p>
<p>(其中,m是数据个数，n是特征维度)<br>因此在正则化里，我们要做的事情，就是把减小我们的代价函数（例子中是线性回归的代价函数）所有的参数值，因为我们并不知道是哪一个或哪几个要去缩小。</p>
<p>因此，我们需要修改代价函数，在这后面添加一项，就像我们在方括号里的这项。当我们添加一个额外的正则化项的时候，我们收缩了每个参数。</p>
<p>$$ min_w\frac{1}{2m}[\sum_{i=1}^m(y_i-w^Tx_i)^2+\lambda\sqrt{\sum_{n=1}^nw_i^2}]$$</p>
<h1 id="参考文献">5. 参考文献</h1><ol>
<li><a href="http://www.cnblogs.com/jianxinzhou/p/4083921.html" target="_blank" rel="external">机器学习之正则化（Regularization）</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 机器学习算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 特征工程 </tag>
            
            <tag> 正则化 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[java-Buffer]]></title>
      <url>/2017/05/22/Java-Buffer/</url>
      <content type="html"><![CDATA[<p><strong>引言</strong></p>
<p>说到缓冲区，不得不提Java NIO。</p>
<p>Java NIO(New IO)是一个可以替代标准Java IO API的IO API（从Java 1.4开始)，Java NIO提供了与标准IO不同的IO工作方式。</p>
<p>Java NIO: Channels and Buffers（通道和缓冲区）</p>
<h1 id="什么是缓冲区">1. 什么是缓冲区</h1><p><strong>Buffer定义</strong></p>
<p>代码的角度来讲（可以查看JDK中Buffer、ByteBuffer、DoubleBuffer等的源码），Buffer类内部其实就是一个基本数据类型的数组，以及对这个缓冲数组的各种操作；</p>
<p>常见的缓冲区如ByteBuffer、IntBuffer、DoubleBuffer…内部对应的数组依次是byte、int、double…</p>
<p><strong>Buffer与通道的关系</strong></p>
<p>标准的IO基于字节流和字符流进行操作的，而NIO是基于通道（Channel）和缓冲区（Buffer）进行操作，数据总是<em>从通道读取到缓冲区中</em>，或者<em>从缓冲区写入到通道中</em>。</p>
<p><strong>继承结构</strong></p>
<p>以ByteBuffer为例：</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-05-22-20-31-24.png" alt=""> </p>
<p>Buffer是顶层抽象类，ByteBuffer继承Buffer，也是抽象类，ByteBuffer最常见的两个具体实现类如下：</p>
<p>DirectByteBuffer（JVM堆外部、通过unsafe.allocateMemory实现）、HeapByteBuffer（JVM堆）</p>
<p><strong>缓冲区用途</strong></p>
<p>写，然后读出</p>
<h1 id="缓冲区的四个属性">2. 缓冲区的四个属性</h1><ul>
<li><p>容量(capacity)<br>capacity指的是缓冲区能够容纳元素的最大数量，这个值在缓冲区创建时被设定，而且不能够改变，如下，我们创建了一个最大容量为10的字节缓冲区；</p>
<pre><code>ByteBuffer bf = ByteBuffer.allocate(10);
</code></pre></li>
<li><p>上界（limit）<br>limit指的是缓冲区中第一个不能读写的元素的数组下标索引，也可以认为是缓冲区中实际元素的数量；</p>
</li>
<li><p>位置（position）<br>position指的是下一个要被读写的元素的数组下标索引，该值会随get()和put()的调用自动更新；</p>
</li>
<li><p>标记（mark）<br>一个备忘位置，调用mark()方法的话，mark值将存储当前position的值，等下次调用reset()方法时，会设定position的值为之前的标记值；</p>
</li>
<li><p>四个属性值之间的关系<br>根据以上四个属性的定义，我们可以总结出它们之间的关系如下：<br>0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity</p>
</li>
</ul>
<h1 id="缓冲区调用一般步骤">3. 缓冲区调用一般步骤</h1><ol>
<li>写入数据到 Buffer</li>
<li>调用flip()方法</li>
<li>从 Buffer 中get()数据</li>
<li>调用clear()方法或者compact()方法</li>
</ol>
<h1 id="参考文献">4. 参考文献</h1><ol>
<li><a href="http://www.cnblogs.com/chenpi/p/6475510.html" target="_blank" rel="external">Java NIO中的缓冲区Buffer（一）缓冲区基础</a></li>
<li>[Java编程思想2]</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Buffer </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[内存映射文件]]></title>
      <url>/2017/05/21/%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%AF%94%E8%B5%9B-%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84%E6%96%87%E4%BB%B6/</url>
      <content type="html"><![CDATA[<p>内存映射文件：利用虚拟内存实现将文件“映射”到内存中。文件对应于内存中的一个字节数组，对文件的操作变为对这个字节数组的操作，而字节数组的操作直接映射到文件上。这样这个文件就可以当做是一个内存数组一样的访问，这比传统的文件操作要快得多。</p>
<p>映射：<strong>硬盘上文件</strong>的位置与进程<strong>逻辑地址空间</strong>中一块大小相同的区域之间的一一对应</p>
<p>不过，这种映射是操作系统提供的一种假象，文件一般不会马上加载到内存，操作系统只是记录下了这回事，当实际发生读写时，才会按需加载。</p>
<p>这种按需加载的方式，使得内存映射文件可以方便处理非常大的文件，内存放不下整个文件也不要紧，操作系统会自动进行处理，将需要的内容读到内存，将修改的内容保存到硬盘，将不再使用的内存释放。</p>
<p>内存映射文件也有局限性，比如，它不太适合处理小文件，它是按页分配内存的，对于小文件，会浪费空间，另外，映射文件要消耗一定的操作系统资源，初始化比较慢。</p>
<h1 id="java使用内存映射">1. java使用内存映射</h1><h2 id="步骤">1.1. 步骤</h2><ul>
<li>引入java.nio包</li>
<li><p>从文件中获得一个通道(channel)。</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">FileChannel channel = FileChanne.open(path,options)</div></pre></td></tr></table></figure>
</li>
<li><p>通过调用FileChannel类的map方法从这个通道中获得一个ByteBuffer,它代表内存中的字节数组。其中，映射文件区域与映射模式支持三种方式：</p>
<h2 id="–-FileChannel-MapMode-READ-ONLY-缓冲区只读">1.2. – FileChannel.MapMode.READ_ONLY:缓冲区只读</h2><p>FileChannel.MapMode.READ_WRITE：可读写。任何缓冲区的修改都会写回文件（非立即）<br>– FileChannel.MapMode.PRIVATE：缓冲区可写，但修改不会传播到文件中</p>
</li>
</ul>
<p>映射完成后，文件就可以关闭了，后续对文件的读写可以通过MappedByteBuffer。</p>
<p>例：以读写模式映射文件”abc.dat”，代码可以为：</p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">RandomAccessFile file = <span class="keyword">new</span> RandomAccessFile(<span class="string">"abc.dat"</span>,<span class="string">"rw"</span>);</div><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">    MappedByteBuffer buf = file.getChannel().map(MapMode.READ_WRITE, <span class="number">0</span>, file.length());</div><div class="line">    <span class="comment">//使用buf...</span></div><div class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">    e.printStackTrace();</div><div class="line">&#125;<span class="keyword">finally</span>&#123;</div><div class="line">    file.close();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><p>##　</p>
<h1 id="参考文献">2. 参考文献</h1><p>1.<a href="https://juejin.im/post/58626ac361ff4b006cf14faf" target="_blank" rel="external">计算机程序的思维逻辑 (61) - 内存映射文件及其应用 - 实现一个简单的消息队列</a><br>2.<a href="http://blog.csdn.net/king_is_everyone/article/details/28096583" target="_blank" rel="external">java流的性能优化2-内存映射文件</a></p>
]]></content>
      
        <categories>
            
            <category> 中间件比赛 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OpenMessaging源码阅读2-demo]]></title>
      <url>/2017/05/19/%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%AF%94%E8%B5%9B-OpenMessaging%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB2-demo/</url>
      <content type="html"><![CDATA[<h1 id="producer操作">1. producer操作</h1><p>tips:以下涉及到的代码是关键步骤代码。</p>
<ol>
<li><p>====================构造n个<strong>Topic</strong>和n个<strong>Queue</strong>====================</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">String topic1 = <span class="string">"TOPIC1"</span>; <span class="comment">//实际测试时大概会有100个Topic左右</span></div><div class="line">String queue2 = <span class="string">"QUEUE2"</span>; <span class="comment">//实际测试时，queue数目与消费线程数目相同</span></div><div class="line">List&lt;Message&gt; messagesForTopic1 = <span class="keyword">new</span> ArrayList&lt;&gt;(<span class="number">1024</span>);</div><div class="line">List&lt;Message&gt; messagesForQueue1 = <span class="keyword">new</span> ArrayList&lt;&gt;(<span class="number">1024</span>);</div></pre></td></tr></table></figure>
</li>
<li><p>====================向Topic和Queue中<strong>create</strong>数据====================</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">messagesForTopic1.add(producer.createBytesMessageToTopic(topic1,  (topic1 + i).getBytes()));</div></pre></td></tr></table></figure>
</li>
</ol>
<ul>
<li>调用<code>producer</code>的<code>producer.createBytesMessageToTopic()</code>方法来创建<code>BytesMessage</code></li>
<li>将上一步产生的标准消息扔进messagesForTopic1中，即调用了每个<code>messagesForTopic1.add()</code>来向这个<code>Topic</code>中添加消息</li>
</ul>
<p>需要注意的是：</p>
<ul>
<li>messageFactory,而createBytesMessageToTopic()正是通过messageFactory.createBytesMessageToTopic(topic, body);来创建消息；</li>
<li>messageFactory.createBytesMessageToTopic(topic, body);仅仅只是将消息的body和header放入了一个defaultBytesMessage类型的消息中，并返回</li>
<li>每个producer对应一个messageStore<br><strong>总结：这一步将producer产生的数据放入消息列表messagesForTopic/Queue中</strong></li>
</ul>
<p>3.====================<strong>send</strong>数据====================</p>
<p>方式：</p>
<pre><code>producer.send(messagesForTopic1.get(i));
</code></pre><p>然后<code>send()</code>内部是：</p>
<pre><code>String topic = message.headers().getString(MessageHeader.TOPIC);
messageStore.putMessage(topic或queue, message);
</code></pre><p>需要注意的是：</p>
<ul>
<li>每个producer有一个messageStore，通过调用它的putMessage()来进行发送消息（将消息存储在硬盘中）</li>
<li>MessageStore类有一个成员变量<code>Map &lt;String, ArrayList&lt;Message&gt;&gt; messageBuckets</code>用来装消息，其中键是topic或queue的名字，值是new ArrayList&lt;&gt;(1024)(这里有一点疑问？)</li>
</ul>
<p>而putMessage：</p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">putMessage</span><span class="params">(String bucket, Message message)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (!messageBuckets.containsKey(bucket)) &#123;</div><div class="line">        messageBuckets.put(bucket, <span class="keyword">new</span> ArrayList&lt;&gt;(<span class="number">1024</span>));</div><div class="line">    &#125;</div><div class="line">    ArrayList&lt;Message&gt; bucketList = messageBuckets.get(bucket);</div><div class="line">    bucketList.add(message);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><ul>
<li>如果本messageStore的messageBuckets没有本bucket(Topic或Queue)，则将这个buket加入到messageBuckets中,并使得其键值为new ArrayList&lt;&gt;(1024)</li>
<li>从本messageBuckets拿出(get)本bucket，放入消息列表bucketList中</li>
<li>再将本message加入消息列表bucketList</li>
</ul>
<p><strong>总结：将Topic或Queue放入MessageStore的messageBuckets中，将消息体放入bMessageStore的ucketList中</strong></p>
<h1 id="consumer操作">2. consumer操作</h1><ol>
<li>====================进行消息订阅<strong>attach</strong>====================</li>
</ol>
<p>操作：</p>
<pre><code>consumer1.attachQueue(queue1, Collections.singletonList(topic1));
</code></pre><p>备注：</p>
<ul>
<li>singletonList(T) 方法用于返回一个只包含指定对象的不可变列表</li>
</ul>
<p>然后DefaultPullConsumer的attachQueue如下：</p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">attachQueue</span><span class="params">(String queueName, Collection&lt;String&gt; topics)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (queue != <span class="keyword">null</span> &amp;&amp; !queue.equals(queueName)) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> ClientOMSException(<span class="string">"You have alreadly attached to a queue "</span> + queue);</div><div class="line">    &#125;</div><div class="line">    queue = queueName;</div><div class="line">    buckets.add(queueName);</div><div class="line">    buckets.addAll(topics);</div><div class="line">    bucketList.clear();</div><div class="line">    bucketList.addAll(buckets);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><ul>
<li>buckets是DefaultPullConsumer的一个成员变量：private Set<string> buckets = new HashSet&lt;&gt;();</string></li>
<li>bucketList是DefaultPullConsumer的一个成员变量：private List<string> bucketList = new ArrayList&lt;&gt;();</string></li>
<li>将本queue以及其下的所有topic都加入到buckets中</li>
<li>将bukets都加入到bucketList中</li>
</ul>
<p>2.====================进行消息拉取<strong>pull</strong>====================</p>
<p>操作：</p>
<p>Message message = consumer1.poll();</p>
<p>其中，poll为：</p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> Message <span class="title">poll</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (buckets.size() == <span class="number">0</span> || queue == <span class="keyword">null</span>) &#123;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">//use Round Robin</span></div><div class="line">    <span class="keyword">int</span> checkNum = <span class="number">0</span>;</div><div class="line">    <span class="keyword">while</span> (++checkNum &lt;= bucketList.size()) &#123;</div><div class="line">        String bucket = bucketList.get((++lastIndex) % (bucketList.size()));</div><div class="line">        Message message = messageStore.pullMessage(queue, bucket);</div><div class="line">        <span class="keyword">if</span> (message != <span class="keyword">null</span>) &#123;</div><div class="line">            <span class="keyword">return</span> message;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><ul>
<li>遍历每个bucketList（bucketList装的是本consumer订阅的topics以及对应的queue）</li>
<li>对遍历到的每个bucket，从messageStore拉取消息</li>
</ul>
<p>而 messageStore.pullMessage为：</p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> Message <span class="title">pullMessage</span><span class="params">(String queue, String bucket)</span> </span>&#123;</div><div class="line">    ArrayList&lt;Message&gt; bucketList = messageBuckets.get(bucket);</div><div class="line">    <span class="keyword">if</span> (bucketList == <span class="keyword">null</span>) &#123;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">    &#125;</div><div class="line">    HashMap&lt;String, Integer&gt; offsetMap = queueOffsets.get(queue);</div><div class="line">    <span class="keyword">if</span> (offsetMap == <span class="keyword">null</span>) &#123;</div><div class="line">        offsetMap = <span class="keyword">new</span> HashMap&lt;&gt;();</div><div class="line">        queueOffsets.put(queue, offsetMap);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">int</span> offset = offsetMap.getOrDefault(bucket, <span class="number">0</span>);</div><div class="line">    <span class="keyword">if</span> (offset &gt;= bucketList.size()) &#123;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">    &#125;</div><div class="line">    Message message = bucketList.get(offset);</div><div class="line">    offsetMap.put(bucket, ++offset);</div><div class="line">    <span class="keyword">return</span> message;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><ul>
<li>先从messageStore的messageBuckets中get到本bucket的bucketList</li>
<li>将这个consumer绑定的queue放入本messageStore的queueOffsets中</li>
<li>然后我就有点疑惑了？？</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 中间件比赛 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OpenMessaging </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[RocketMQ简介]]></title>
      <url>/2017/05/17/%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%AF%94%E8%B5%9B-RocketMQ%E7%AE%80%E4%BB%8B/</url>
      <content type="html"><![CDATA[<p>RocketMQ:分布式开放消息系统</p>
<h1 id="消息中间件需要解决哪些问题？">1. 消息中间件需要解决哪些问题？</h1><h2 id="发布订阅（Publish-Subscribe）">1.1. 发布订阅（Publish/Subscribe）</h2><p>发布订阅是消息中间件的最基本功能，也是相对于传统RPC通信而言。在此不再详述。</p>
<h2 id="消息优先级（Message-Priority）">1.2. 消息优先级（Message Priority）</h2><p>两种方式：</p>
<ol>
<li>严格优先级，例如0-65535。开销大，精准，但可能没有必要。</li>
<li>档位优先级。高、中、低，或其他。每个优先级可以用不同的topic表示，发消息时，指定不同的topic来表示优先级。精确性低。</li>
</ol>
<h2 id="消息有序性（Message-Order）">1.3. 消息有序性（Message Order）</h2><ol>
<li>一个订单的发出的消息顺序不能变</li>
<li>订单之间是可以并行消费</li>
</ol>
<h2 id="消息过滤（Message-Filter）">1.4. 消息过滤（Message Filter）</h2><h3 id="消息协商器（Broker端）消息过滤">1.4.1. 消息协商器（Broker端）消息过滤</h3><p>在Broker中，按照Consumer的要求做过滤</p>
<ol>
<li>优点是减少了对于Consumer无用消息的网络传输。</li>
<li>缺点是增加了Broker的负担，实现相对复杂。</li>
</ol>
<p>淘宝Notify支持多种过滤方式：<br>包含直接按照消息类型过滤，灵活的语法表达式过滤，几乎可以满足最苛刻的过滤需求。</p>
<p>淘宝RocketMQ支持按照简单的Message Tag过滤，也支持按照Message Header、body进行过滤。</p>
<p>CORBA Notification规范中也支持灵活的语法表达式过滤。</p>
<h3 id="Consumer端消息过滤">1.4.2. Consumer端消息过滤</h3><p>这种过滤方式可由应用完全自定义实现，但是缺点是很多无用的消息要传输到Consumer端。</p>
<h3 id="消息持久化（Message-Persistence）">1.4.3. 消息持久化（Message Persistence）</h3><p>持久化（Persistence）：即把数据（如内存中的对象）保存到可永久保存的存储设备中（如磁盘）。持久化的主要应用是将内存中的对象存储在数据库中，或者存储在磁盘文件中、XML数据文件中等等。</p>
<p>消息中间件通常采用的几种持久化方式：</p>
<ol>
<li>持久化到数据库，例如Mysql。</li>
<li>持久化到KV存储，例如levelDB、伯克利DB等KV存储系统。</li>
<li>文件记录形式持久化，例如Kafka，RocketMQ</li>
<li>对内存数据做一个持久化镜像，例如beanstalkd，VisiNotify</li>
<li>(1)、(2)、(3)三种持久化方式都具有将内存队列Buffer进行扩展的能力，(4)只是一个内存的镜像，作用是当Broker挂掉重启后仍然能将之前内存的数据恢复出来。</li>
</ol>
<p>JMS与CORBA Notification规范没有明确说明如何持久化，但是持久化部分的性能直接决定了整个消息中间件的性能。</p>
<p>RocketMQ充分利用Linux文件系统内存cache来提高性能。</p>
<h3 id="消息可靠性（Message-Reliablity）">1.4.4. 消息可靠性（Message Reliablity）</h3><p>响消息可靠性的几种情况：</p>
<ol>
<li>Broker正常关闭</li>
<li>Broker异常Crash</li>
<li>OS Crash</li>
<li>机器掉电，但是能立即恢复供电情况。</li>
<li>机器无法开机（可能是cpu、主板、内存等关键设备损坏）</li>
<li>磁盘设备损坏</li>
</ol>
<p>(1)、(2)、(3)、(4)四种情况都属于硬件资源可立即恢复情况，RocketMQ在这四种情况下能保证消息不丢，或者丢失少量数据（依赖刷盘方式是同步还是异步）。</p>
<p>(5)、(6)属于单点故障，且无法恢复，一旦发生，在此单点上的消息全部丢失。RocketMQ在这两种情况下，通过异步复制，可保证99%的消息不丢，但是仍然会有极少量的消息可能丢失。通过同步双写技术可以完全避免单点，同步双写势必会影响性能，适合对消息可靠性要求极高的场合，例如与Money相关的应用。</p>
<p>RocketMQ从3.0版本开始支持同步双写。</p>
<h1 id="参考文献">2. 参考文献</h1><ol>
<li><a href="http://jm.taobao.org/2017/01/12/rocketmq-quick-start-in-10-minutes/" target="_blank" rel="external">十分钟入门RocketMQ</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 中间件比赛 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> openMessaging </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[转化率预估资料]]></title>
      <url>/2017/05/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5-CVR-%E8%BD%AC%E5%8C%96%E7%8E%87%E9%A2%84%E4%BC%B0%E8%B5%84%E6%96%99/</url>
      <content type="html"><![CDATA[<ol>
<li><a href="http://www.flickering.cn/category/ads/" target="_blank" rel="external">火光摇曳</a></li>
<li><a href="http://tech.meituan.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0" target="_blank" rel="external">美团点评技术团队</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 腾讯算法大赛-CVR预估 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CVR预估 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[阿里中间件初赛-李健胜解决方案]]></title>
      <url>/2017/05/14/%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%AF%94%E8%B5%9B-%E6%9D%8E%E5%81%A5%E8%83%9C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
      <content type="html"><![CDATA[<h1 id="参考资料">1. 参考资料</h1><ol>
<li><a href="http://blog.jesonlee.me/19/" target="_blank" rel="external">李健胜，阿里中间件大赛初赛解题思路</a></li>
<li><a href="https://github.com/Jesonlee1997/open-message" target="_blank" rel="external">1对应的代码</a></li>
</ol>
<h1 id="题目要求">2. 题目要求</h1><p><strong>主角</strong>：消息中间件<br><strong>目的</strong>：实现消息中间件的推拉模式。即生产者制造消息，使用消息队列储存消息，消费者从消息队列拉取消息。<br><strong>要点</strong>：持久化的消息队列</p>
<h2 id="Producer需要实现">2.1. Producer需要实现</h2><ul>
<li><p>创建一个消息，给消息指定Topic（可以由多个Consumer消费）<br><code>BytesMessage createBytesMessageToTopic(String topic, byte[] body);</code></p>
</li>
<li><p>创建一个消息，给消息指定Queue（只能由一个Consumer消费）<br><code>BytesMessage createBytesMessageToQueue(String queue, byte[] body);</code></p>
</li>
<li><p>发送消息，message中应当包含目的地（Queue，Topic只能选其一），对于发往同一个Topic和Queue的message顺序要保持一致。<br><code>void send(Message message);</code></p>
</li>
</ul>
<h2 id="PullConsumer需要实现">2.2. PullConsumer需要实现</h2><ul>
<li>绑定到一个Queue，并订阅topics，即从这些topic和Queue读取消息。<br><code>void attachQueue(String queueName, Collection topics);</code></li>
<li>规范要求实现阻塞的接口，由properties来设置阻塞时间，但本赛题不需要用到该特性， 请实现一个非阻塞(也即阻塞时间为0)调用, 也即没有消息则返回null<br><code>Message poll();</code></li>
</ul>
<h2 id="测试流程">2.3. 测试流程</h2><ul>
<li>创建<code>Topic</code>，创建<code>Queue</code> 创建<code>Producer</code>，多个<code>Producer</code>创建指定<code>Topic</code>和指定<code>Queue</code>的Message，调用<code>send</code>方法发送</li>
<li>将数据保存到磁盘中</li>
<li><code>kill Producer</code>进程，另取进程进行消费<br>创建<code>PullConsumer</code>线程进行消费，一个<code>Consumer</code>对应一个线程，<code>Consumer</code>连接到一个<code>Queue</code>，可以订阅多个<code>Topic</code>。 </li>
<li>不断的调用poll拉取队列的消息，直到完全读完，读取的消息要相对有序。</li>
</ul>
<p>补充：<br>一个<code>Producer</code>对应一个线程，线程先创建对应的Message，再将Message 发送到对应的队列或<code>topic</code>中，实际情况中会有多个<code>Producer</code>。 一个<code>Consumer</code>对应一个<code>Queue</code>，多个<code>Consumer</code>同时从队列中拉取消息。</p>
<h2 id="技术难点">2.4. 技术难点</h2><ol>
<li>大量的消息产生 </li>
<li>并发写 </li>
<li>并发读 </li>
<li>序列化&amp;反序列化</li>
</ol>
<ol>
<li>大量消息<br>首先根据题目描述，Produce过程会运行5分钟，这个过程中多线程进行消息的发送，然后再考虑将消息持久化。我用自己的程序测试了一下，（不是典型值，只作为参考，在文章的最后我会贴上我的一系列测试结果），多线程发送一亿条消息的时间为27s，而这一亿条消息占据磁盘的大小为将近4G！可以想象在5分钟内会产生多少的消息量，如何将消息存储，如何读取消息都将成为一个非常棘手的问题。</li>
<li>并发写<br>并发写的问题也非常显而易见。我们一般情况下为了实现消息队列会选择使用一个List或数组来存储Producer产生的消息。这就引发了一个问题，怎样保证向同一个队列中发送消息的线程不产生竞争条件。</li>
<li>并发读<br>最麻烦的一个部分，每个线程都需要读取磁盘上的消息内容，每个线程读取的位置又不尽相同，消息数又那么多不可能全部加载到内存中，这个问题曾让我伤透了脑筋，直到我遇到了mmap(后面详细介绍)。</li>
<li>序列化和反序列化的问题<br>大赛刚开始时，我写了一个使用Java自身序列化来实现持久化的版本，这个版本的缺点非常显而易见，就是慢，而这个缺点又是极为致命的。我意识到我需要自己定制一个序列化协议来将消息转化为字节数组，再通过其他方式（如FileOutputStream）写入磁盘，同时再使用这个协议将其从磁盘中恢复。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> 中间件比赛 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OpenMessaging </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OpenMessaging源码阅读1]]></title>
      <url>/2017/05/13/%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%AF%94%E8%B5%9B-OpenMessaging%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB1/</url>
      <content type="html"><![CDATA[<p>考虑到自己记性实在太差，还是好好记笔记吧。<br>本节主要看以下几个接口：</p>
<ul>
<li>Meaasage</li>
<li>Producer</li>
<li>PullConsumer</li>
</ul>
<h1 id="Message-java">1. Message.java</h1><p>Message接口是所有OMS消息中的根接口。最常用的消息就是BytesMessage。</p>
<p><strong>标准Message</strong><br>大多消息导向（message-oriented）的中间件（MOM）产品更趋向于将消息认做轻实体，这个轻实体包含一个header和一个body：</p>
<ul>
<li>header:包含用来路由和识别的信息域；</li>
<li>body:包含将会被发送的应用信息；</li>
</ul>
<p><strong>本Message</strong><br>本消息是一个仅包含与具体消息对象相关的property(财产)的轻量级实体。主要包含以下几个方面：</p>
<ul>
<li>Header:所有消息都有同样的header域。header域的值用来给客户端(clients)和提供商（providers）唯一标示消息，以及路由消息。</li>
<li>Properties(财产，特性)：每个消息都有一个消息自有的部分，这部分用来提供“应用定义(application-defined)”的property(财产)值。这一部分为支持“应用定义”消息的过滤提供了很有效的机制。</li>
</ul>
<p><strong>源码解读</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Message</span> </span>&#123;</div><div class="line">     <span class="comment">/*headers()返回Message对象的header域，返回值类型是keyValue。*/</span></div><div class="line">    <span class="function">KeyValue <span class="title">headers</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">    <span class="comment">/*properties()返回消息自有的property域。返回值类型是keyValue。*/</span></div><div class="line">    <span class="function">KeyValue <span class="title">properties</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">     <span class="comment">/*putHeaders(String key, int value)将输入(String key, int value)全部传入header*/</span></div><div class="line">    <span class="comment">/*参数key:headers的关键字*/</span></div><div class="line">    <span class="comment">/*参数values:与key对应的值*/</span></div><div class="line">    <span class="function">Message <span class="title">putHeaders</span><span class="params">(String key, <span class="keyword">int</span> value)</span></span>;</div><div class="line">    <span class="function">Message <span class="title">putHeaders</span><span class="params">(String key, <span class="keyword">long</span> value)</span></span>;</div><div class="line">    <span class="function">Message <span class="title">putHeaders</span><span class="params">(String key, <span class="keyword">double</span> value)</span></span>;</div><div class="line">    <span class="function">Message <span class="title">putHeaders</span><span class="params">(String key, String value)</span></span>;</div><div class="line"></div><div class="line"></div><div class="line">    <span class="comment">/*将key和value全部存入header*/</span></div><div class="line">    <span class="comment">/*参数key:headers的关键字*/</span></div><div class="line">    <span class="comment">/*参数values:与key对应的值*/</span></div><div class="line">    <span class="function">Message <span class="title">putProperties</span><span class="params">(String key, <span class="keyword">int</span> value)</span></span>;</div><div class="line">    <span class="function">Message <span class="title">putProperties</span><span class="params">(String key, <span class="keyword">long</span> value)</span></span>;</div><div class="line">    <span class="function">Message <span class="title">putProperties</span><span class="params">(String key, <span class="keyword">double</span> value)</span></span>;</div><div class="line">    <span class="function">Message <span class="title">putProperties</span><span class="params">(String key, String value)</span></span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="Producer-java">2. Producer.java</h1><p>Producer是一个用来发送消息的简单对象，它是<code>MessagingAccessPoint</code>的一个具体实现。<br><strong>创建Producer对象</strong>：<br><code>Producer</code>的具体实例是通过<code>MessagingAccessPoint#createProducer()</code>方法创建的。<br>这个方法提供了多种定点发送消息的方式，其中，目的地可以是<code>MessageHeader#TOPIC</code>或<code>MessageHeader#QUEUE</code>。</p>
<p><strong>Producer#send(Message)</strong><br>同步定点发送消息方法。<br>当发送请求完成时，线程将会关闭(block)。</p>
<p><strong>Producer#sendAsync(Message)</strong><br>异步定点发送消息方法。<br>当发送请求完成时，线程不会很快关闭，而会立即返回一个<code>Promise</code>作为发送结果。</p>
<p><strong>Producer#sendOneway(Message)</strong><br>one way定点发送消息方法。<br>当发送请求完成时，线程不会很快关闭，而是立即返回。线程发起者不关心发送结果，同时server也对返回值没有责任。</p>
<p><strong>源码解读</strong></p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Producer</span> <span class="keyword">extends</span> <span class="title">MessageFactory</span>, <span class="title">ServiceLifecycle</span> </span>&#123;</div><div class="line">     <span class="comment">/*返回本实例的properties*/</span></div><div class="line">     <span class="comment">/*返回值的变化不会反应在Producer本身上，并且这个变化可以用ResourceManager#setProducerProperties(String, KeyValue)来修改。（Changes to the return &#123;@code KeyValue&#125; are not reflected in physical &#123;@code Producer&#125;,and use &#123;@link ResourceManager#setProducerProperties(String, KeyValue)&#125; to modify.）*/</span></div><div class="line">    <span class="function">KeyValue <span class="title">properties</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">    <span class="comment">/*同步定点发送message方法*/</span></div><div class="line">    <span class="comment">/*发送目的地应该预置在MessageHeader中。当然其它类型的header域也可以*/</span></div><div class="line">    <span class="comment">/*异常OMSRuntimeException：当由于内部原因发送失败时*/</span></div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">send</span><span class="params">(Message message)</span></span>;</div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">send</span><span class="params">(Message message, KeyValue properties)</span></span>;<span class="comment">/*properties是属性值*/</span></div><div class="line"></div><div class="line">    <span class="comment">/*异步定点发送消息方法*/</span></div><div class="line">    <span class="comment">/*返回值是Promise类型。同时，登记过的PromiseListener将会被通知*/</span></div><div class="line">    <span class="function">Promise&lt;Void&gt; <span class="title">sendAsync</span><span class="params">(Message message)</span></span>;</div><div class="line">    <span class="function">Promise&lt;Void&gt; <span class="title">sendAsync</span><span class="params">(Message message, KeyValue properties)</span></span>;</div><div class="line"></div><div class="line">    <span class="comment">/*oneway定点发送消息方法*/</span></div><div class="line">    <span class="comment">/*无返回值，也没有thrown。因为oneway发送不在乎发送结果*/</span></div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">sendOneway</span><span class="params">(Message message)</span></span>;</div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">sendOneway</span><span class="params">(Message message, KeyValue properties)</span></span>;</div><div class="line"></div><div class="line">    <span class="function">BatchToPartition <span class="title">createBatchToPartition</span><span class="params">(String partitionName)</span></span>;</div><div class="line"></div><div class="line">    <span class="function">BatchToPartition <span class="title">createBatchToPartition</span><span class="params">(String partitionName, KeyValue properties)</span></span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><h1 id="PullConsumer-java">3. PullConsumer.java</h1><p><code>PullConsumer</code>对象能从特定的队列中poll消息。而且支持通过‘ack’方式提交消费结果。</p>
<p><strong>源码分析</strong></p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">PullConsumer</span> </span>&#123;</div><div class="line">    <span class="comment">/*返回本PullConsumer实例的properties*/</span></div><div class="line">    <span class="comment">/* Changes to the return &#123;@code KeyValue&#125; are not reflected in physical &#123;@code PullConsumer&#125;,and use &#123;@link ResourceManager#setConsumerProperties(String, KeyValue)&#125; to modify.*/</span></div><div class="line">    <span class="function">KeyValue <span class="title">properties</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * 规范要求实现阻塞的接口，由properties来设置阻塞时间，但本赛题不需要用到该特性，请实现一个非阻塞(也即阻塞时间为0)调用, 也即没有消息则返回null</div><div class="line">     */</div><div class="line"></div><div class="line">    <span class="comment">/*抽取下一条为本pullconsumer生产的消息*/</span></div><div class="line">    <span class="comment">/*除非一条消息被产生了，或者本pullConsumer被关闭了，本调用会一直block*/</span></div><div class="line">    <span class="comment">/*返回为本PullConsumer生产的下一条消息；当本PullConsumer被同时关闭时返回null*/</span></div><div class="line">    <span class="comment">/*当本PullConsumer由于一些内部原因而抽取下一条消息失败时，throw OMSRuntimeException*/</span></div><div class="line">    <span class="function">Message <span class="title">poll</span><span class="params">()</span></span>;</div><div class="line">    <span class="function">Message <span class="title">poll</span><span class="params">(<span class="keyword">final</span> KeyValue properties)</span></span>;<span class="comment">/*properties是一些参数*/</span></div><div class="line"></div><div class="line">    <span class="comment">/*用消息id回确认指定的已消费的消息*/</span></div><div class="line">    <span class="comment">/*若某消息已被接收，但还未被回确认，那它可能会被重新投递*/</span></div><div class="line">    <span class="comment">/*有OMSRuntimeException*/</span></div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">ack</span><span class="params">(String messageId)</span></span>;</div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">ack</span><span class="params">(String messageId, <span class="keyword">final</span> KeyValue properties)</span></span>;</div><div class="line"></div><div class="line">    <span class="comment">/* 绑定到一个Queue，并订阅topics，即从这些topic读取消息*/</span></div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">attachQueue</span><span class="params">(String queueName, Collection&lt;String&gt; topics)</span></span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre>]]></content>
      
        <categories>
            
            <category> 中间件比赛 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OpenMessaging </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[多线程]]></title>
      <url>/2017/05/12/Java-%E5%A4%9A%E7%BA%BF%E7%A8%8B/</url>
      <content type="html"><![CDATA[<p><strong>线程(thread)</strong>：每个任务称为一个线程<br><strong>线程和进程区别</strong>：</p>
<ol>
<li>每个进程有自己独立的变量，而线程则共享数据。</li>
<li>线程是进程的执行单元</li>
<li>线程是进程的组成部分。一个进程可以有多个线程，一个线程必须有一个父进程。</li>
<li>线程可以拥有自己的堆栈、自己的程序计数器和自己的局部变量，但不拥有系统资源（与父进程其它线程共享该进程则资源）</li>
</ol>
<h1 id="线程的创建">1. 线程的创建</h1><p>有以下两种方法：</p>
<ol>
<li>通过继承Thread来创建线程</li>
<li>通过实现Runnable接口创建线程</li>
</ol>
<h2 id="通过继承Thread来创建线程">1.1. 通过继承Thread来创建线程</h2><p>要点：通过继承<code>Thread</code>类创建并启动多线程<br>步骤：</p>
<ol>
<li>定义Thread类的子类，并重写<code>run()</code>方法（线程执行体）</li>
<li>创建<code>Thread</code>子类的实例(创建线程对象)</li>
<li><p>调用<code>start()</code>（启用该线程）</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FirstThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</div><div class="line">        System.out.println(<span class="string">"run\t"</span>+getName()+<span class="string">"\t"</span>);<span class="comment">//getName()返回thread name</span></div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</div><div class="line">        <span class="keyword">new</span> FirstThread().start();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ol>
<p>以上代码输出：</p>
<pre><code>run  Thread-0
</code></pre><p><strong>一个有意思的现象</strong></p>
<p>运行如下代码时：</p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FirstThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</div><div class="line">        System.out.println(<span class="string">"run\t"</span>+getName()+<span class="string">"\t"</span>);<span class="comment">//getName()返回thread name</span></div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</div><div class="line">        <span class="comment">//调用currentThread()获取当前线程</span></div><div class="line">        System.out.println(<span class="string">"currentThread : "</span>+Thread.currentThread().getName());</div><div class="line">        <span class="keyword">new</span> FirstThread().start();</div><div class="line">        System.out.println(<span class="string">"currentThread : "</span>+Thread.currentThread().getName());</div><div class="line">        <span class="keyword">new</span> FirstThread().start();</div><div class="line">        System.out.println(<span class="string">"currentThread : "</span>+Thread.currentThread().getName());</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><p>按照以前的理解，应该是：</p>
<pre><code>currentThread : main
run Thread-0 
currentThread : main 
run Thread-1    
currentThread : main
</code></pre><p>实际输出：（也有可能是其它顺序）</p>
<pre><code>currentThread : main
currentThread : main
run Thread-0    
run Thread-1    
currentThread : main
</code></pre><p>新发现：其实<code>start</code>一个线程的时候，<code>main</code>线程在继续运行。<code>main</code>线程不会等<code>start</code>完事儿之后再运行下一句！</p>
<h2 id="通过实现Runnable接口创建线程">1.2. 通过实现Runnable接口创建线程</h2><pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SecondThread</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</div><div class="line">        System.out.println(<span class="string">"run\t"</span>+Thread.currentThread().getName()+<span class="string">"\t"</span>);<span class="comment">//getName()返回thread name</span></div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</div><div class="line">        SecondThread st = <span class="keyword">new</span> SecondThread();</div><div class="line">        <span class="keyword">new</span> Thread(st,<span class="string">"new_thread_1"</span>).start();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><p>区别：<br>需要通过<code>Thread.currentThread().getName()</code>来获取getName()<br>main不同</p>
<p><strong>多线程共享变量</strong></p>
<p>以下是一个多线程共享变量<code>i</code>的情况：</p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SecondThread</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">int</span> i;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</div><div class="line">        <span class="keyword">while</span>(i&lt;<span class="number">5</span>)&#123;</div><div class="line">            System.out.println(<span class="string">"run\t"</span>+Thread.currentThread().getName()+<span class="string">"\t"</span>+i);<span class="comment">//getName()返回thread name</span></div><div class="line">            i++;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</div><div class="line">        SecondThread st = <span class="keyword">new</span> SecondThread();</div><div class="line">        <span class="keyword">new</span> Thread(st,<span class="string">"thread_name_1"</span>).start();</div><div class="line">        <span class="keyword">new</span> Thread(st,<span class="string">"thread_name_2"</span>).start();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><p>两次运行结果：</p>
<pre><code>run thread_name_1    0
run thread_name_1    1
run thread_name_1    2
run thread_name_1    3
run thread_name_2    3
run thread_name_1    4

run thread_name_1    0
run thread_name_2    0
run thread_name_1    1
run thread_name_2    2
run thread_name_1    3
run thread_name_2    4
</code></pre><p><strong>发现</strong>：</p>
<ol>
<li>两个线程共有变量<code>i</code></li>
<li>线程间抢占资源</li>
</ol>
<h2 id="使用Callable和Future创建线程">1.3. 使用Callable和Future创建线程</h2>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 多线程 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OpenMessaging简介]]></title>
      <url>/2017/05/11/%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%AF%94%E8%B5%9B-OpenMessaging%E7%AE%80%E4%BB%8B/</url>
      <content type="html"><![CDATA[<p>OpenMessaging的主要关系如下图所示：</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-05-12-16-24-52.png" alt=""> </p>
<p>其中，各部分的内容和关系见下述。</p>
<h1 id="Namespace">1. Namespace</h1><p>Namespace就像一个cgroup namespace,是用来创建一个有安全保障的独立的空间。每个namespace都有自己的producer,consumer,topic,queue等等。OpenMessaging用 ​<strong>MessagingAccessPoint</strong>​（消息访问点）来访问/读/写指定namespace的<strong>​资源</strong>​。</p>
<h1 id="Producer">2. Producer</h1><p>Openmessaging定义了两种Producer:<strong>​Producer</strong>​和 <strong>​SequenceProducer</strong>​</p>
<ul>
<li><strong>​Producer</strong>​:提供各种send方法，用来将一个消息送往指定的destination,<strong>Topic</strong>或者<strong>Queue</strong>。支持三种方式：同步、异步、单向(oneway)</li>
<li><strong>SequenceProducer</strong>:重点在于速度，且支持批处理。能发送多个数据并一次提交。</li>
</ul>
<h1 id="Consumer">3. Consumer</h1><p>Openmessaging定义了两种Consumer::<strong>PullConsumer</strong>、<strong>PushConsumer</strong>和<strong>StreamConsumer</strong>.每种Consumer仅支持来自于<strong>Queue</strong>的consume消息。</p>
<ul>
<li><strong>PullConsumer</strong>:从指定队列中pulls消息。支持“submit the consume<br>result by acknowledgement at any time”。每个PullConsumer仅能从固定的队列中pull消息。</li>
<li><strong>PushConsumer</strong>:可从多个队列中接收消息，且这个消息是由MOM server push上去的。PushConsumer可依附于多个独立的、具有不同的MessageListener的队列，并且可以随时通过<strong>ReceivedMessageContext</strong>提交结果。</li>
<li><strong>StreamingConsumer</strong>:一种崭新的consumer类型，是一种面向流的consumer,面向留信息的一体化信息系统。</li>
</ul>
<h1 id="Topic-Queue-and-Routing">4. Topic Queue and Routing</h1><p>这三个概念非常相近。虽然Topic和Queue有不同的用途，但它们总让人迷惑。</p>
<h2 id="Topic">4.1. Topic</h2><p>Topic是原始信息的载体，用来holding消息。消息的分发方式和有序性是没有定义的。</p>
<h2 id="Routing">4.2. Routing</h2><p>Topic中的消息是原始的，是待处理的，一般不易引起consumers的注意。总之，Topic中的数据是producer-orented（导向）的，而不是consumer-oriented。</p>
<p>因此Routing负责加工Topic中的原始消息，并routing去Queue中。每个Routing有一个<strong>操作管线（operator pipeline）</strong>，包含着一系列的操作。消息会通过操作管线从Topic流向Queue。</p>
<p><strong>操作（operator）</strong>是用来处理在Routing流通的消息的。有很多操作，例如expression operator, deduplicator operator, joiner operator, filter operator, rpc<br>operator等等。</p>
<h2 id="Queue-队列">4.3. Queue(队列)</h2><p>现在消息已经被routed到Queue中了。现在消息就可以被consumers使用了。</p>
<p>需要注意的是，一个Queue可能会被分为几部分，消息可能通过MessageHeader#SHARDING_KEY被routed到某个特殊的部分中。</p>
<h2 id="Topic与Queue比较">4.4. Topic与Queue比较</h2><ul>
<li>都是消息的载体</li>
<li>Topic是preducer-oriented的，而Queue是consumer-oriented的</li>
<li>Topic中的消息来自于Producer,而Queue中的消息来自于Topic或者Producer</li>
<li>Queue包含几个部分，而Topic形状未定义</li>
<li>在大多数情况下，Queue是Topic的一个子集</li>
<li>Queue的创建、销毁都很容易，且与producer无关</li>
</ul>
<h1 id="参考文献">5. 参考文献</h1><ol>
<li><a href="openmessaging.github.io">原始文档</a></li>
<li><a href="https://github.com/pugwoo/c/blob/master/linux_ipc/shm/shmqueue.h" target="_blank" rel="external">pugwoo用c写的</a></li>
<li><a href="https://github.com/openmessaging/openmessaging" target="_blank" rel="external">原始文档扒的API</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 中间件比赛 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OpenMessaging </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[中间件入门]]></title>
      <url>/2017/05/11/%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%AF%94%E8%B5%9B-%E4%B8%AD%E9%97%B4%E4%BB%B6%E5%85%A5%E9%97%A8/</url>
      <content type="html"><![CDATA[<h1 id="中间件概念">1. 中间件概念</h1><p><strong>中间件</strong>：处于操作系统和应用程序之间的软件。</p>
<p>中间件简单解释，可以理解为面向信息系统交互，集成过程中的通用部分的集合，屏蔽了底层的通讯，交互，连接等复杂又通用化的功能，以产品的形式提供出来，系统在交互时，直接采用中间件进行连接和交互即可，避免了大量的代码开发和人工成本。</p>
<p>其实，理论上来讲，中间件所提供的功能通过代码编写都可以实现，只不过开发的周期和需要考虑的问题太多，逐渐的，这些部分，以中间件产品的形式进行了替代。</p>
<p>比如常见的消息中间件，即系统之间的通讯与交互的专用通道，类似于邮局，系统只需要把传输的消息交给中间件，由中间件负责传递，并保证传输过程中的各类问题，如网络问题，协议问题，两端的开发接口问题等均由消息中间件屏蔽了，出现了网络故障时，消息中间件会负责缓存消息，以避免信息丢失。相当于你想给美国发一个邮包，只需要把邮包交给邮局，填写地址和收件人，至于运送过程中的一系列问题你都不需要关心了。</p>
<h1 id="中间件分类">2. 中间件分类</h1><ol>
<li>消息中间件（MOM：Message-Oriented Middleware）</li>
<li>数据中间件（Database Middleware）</li>
<li>远程过程调用中间件（RPC：Remote Process Call）</li>
<li>对象请求代理中间件（ORB：Object Request Broker）</li>
<li>事务处理中间件（TP Monitor：Transaction Process Monitor）</li>
<li>J2EE中间件</li>
</ol>
<h1 id="Open-Messaging">3. Open-Messaging</h1><p>是一个建立行业内的指引和消息的协议（charter）。它的streaming规范提供了一个可用于电子商务、物联网和大数据的基础框架。它的主要目标是建立一个在分布式异构环境中面向云、简单、灵活和独立于语言的环境。协议的一致性似的它可以跨平台开发异构消息应用程序。</p>
<p><strong>域结构</strong><br><img src="http://om1bxijvl.bkt.clouddn.com/2017-05-11-17-16-52.png" alt=""> </p>
<h1 id="消息中间件-Message-Queue">4. 消息中间件 Message Queue</h1><p>Message Queue是一种应用程序对应用程序的通信方法。程序之间通过在消息中发送数据进行通信，而不是通过直接调用彼此来通信，直接调用通常是用于诸如远程过程调用的技术。排队指的是应用程序通过队列来通信。队列的使用除去了接收和发送应用程序同时执行的要求。</p>
<p>提及消息中间件的时候，还会涉及生产者和消费者两个概念。消息中间件是负责接收来自生产者的消息，并存储并转发给对应的消费者，生产者可以按 topic 发布各样消息，消费者也可以按 topic 订阅各样消息。生产者只管往消息队列里推送消息，不用等待消费者的回应；消费者只管从消息队列中取出数据并处理，可用可靠性等问题都交由消息中间件来负责。<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-05-12-15-43-09.png" alt=""><br>生产者和消费者通常有两种对应关系，一个生产者对应一个消费者，以及一个生产者对应多个消费者。</p>
<h1 id="参考文献">5. 参考文献</h1><p>1.<a href="https://www.zhihu.com/question/19730582/answer/16390709" target="_blank" rel="external">知乎FireJones的回答</a><br>2.<a href="http://wiki.jikexueyuan.com/project/redis/middleware.html" target="_blank" rel="external">极客学院，消息中间件</a></p>
]]></content>
      
        <categories>
            
            <category> 中间件比赛 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OpenMessaging </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[python——os模块]]></title>
      <url>/2017/05/04/Python-os%E6%93%8D%E4%BD%9C/</url>
      <content type="html"><![CDATA[<h1 id="os模块">1. os模块</h1><p>os模块的作用：</p>
<p>　　os，语义为操作系统，所以肯定就是操作系统相关的功能了，可以处理文件和目录这些我们日常手动需要做的操作，就比如说：显示当前目录下所有文件/删除某个文件/获取文件大小……</p>
<p>　　另外，os模块不受平台限制，也就是说：当我们要在linux中显示当前命令时就要用到pwd命令，而Windows中cmd命令行下就要用到这个，额…我擦，我还真不知道，（甭管怎么着，肯定不是pwd），这时候我们使用python中os模块的os.path.abspath(name)功能，甭管是linux或者Windows都可以获取当前的绝对路径。</p>
<h1 id="文件夹操作">2. 文件夹操作</h1><h2 id="检验文件夹是否存在">2.1. 检验文件夹是否存在</h2><pre><code>os.path.exists(directory)
</code></pre><h2 id="创建文件夹">2.2. 创建文件夹</h2><pre><code>os.makedirs(directory)
</code></pre><p>实例：<br>检验文件夹是否存在，若不存在，则创建之</p>
<pre><code><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_dir</span><span class="params">(directory)</span>:</span></div><div class="line">    flag=os.path.exists(directory)</div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> flag:</div><div class="line">        os.makedirs(directory)</div></pre></td></tr></table></figure>
</code></pre><h2 id="遍历指定目录名，显示目录下所有文件">2.3. 遍历指定目录名，显示目录下所有文件</h2><pre><code><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">pathDir =  os.listdir(filepath)</div><div class="line">    <span class="keyword">for</span> allDir <span class="keyword">in</span> pathDir:</div><div class="line">        <span class="keyword">print</span> allDir</div></pre></td></tr></table></figure>
</code></pre><h1 id="参考文献">3. 参考文献</h1><ol>
<li><a href="http://www.cnblogs.com/MnCu8261/p/5483657.html" target="_blank" rel="external">python基础之模块之os模块</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> Python </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[pandas相关技巧]]></title>
      <url>/2017/05/04/Python-pandas%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<h1 id="用pandas求差集">1. 用pandas求差集</h1><p>从df1中去除掉df2的内容</p>
<p>data={‘id’:[1,2,3]}<br>data2={‘id’:[3,1,4]}<br>df1=pd.DataFrame(data)<br>df2=pd.DataFrame(data2)<br>print df1<br>print df2<br>df3=df1[~df1[‘id’].isin(df2[‘id’])]<br>print df3</p>
<h1 id="求某个时间区间的数据集">2. 求某个时间区间的数据集</h1><p>tart_t=’2016-04-05 00:00:00’<br>end_t=’2016-04-16 00:00:00’<br>action.time=pd.to_datetime(action.time,format=’%Y-%m-%d %H:%M:%S’)<br>starttime=pd.to_datetime(start_t,format=’%Y-%m-%d %H:%M:%S’)<br>endtime=pd.to_datetime(end_t,format=’%Y-%m-%d %H:%M:%S’)<br>action=action[(action.time<endtime)&(action.time>=starttime)]</endtime)&(action.time></p>
<h1 id="dummies">3. dummies</h1><p>我理解get_dummies是将拥有不同值的变量转换为0/1数值。打个比方，小明有黄、红、蓝三种颜色的帽子，小明今天戴黄色帽子用1表示，红色帽子用2表示，蓝色帽子用3表示。但1、2、3数值大小本身是没有意义的，只是用于区分帽子的颜色，因此在实际分析时，需要将1、2、3转化为0、1，如下代码所示：</p>
<pre><code>import pandas as pd
xiaoming=pd.DataFrame([1,2,3],index=[&apos;yellow&apos;,&apos;red&apos;,&apos;blue&apos;],columns=[&apos;hat&apos;])
print(xiaoming)
hat_ranks=pd.get_dummies(xiaoming[&apos;hat&apos;],prefix=&apos;hat&apos;)
print(hat_ranks.head())

            hat
yellow    1
red       2
blue      3
        hat_1  hat_2  hat_3
yellow      1      0      0
red         0      1      0
blue        0      0      1
</code></pre><h1 id="其它to-DataFrame">4. 其它to DataFrame</h1><h2 id="dict-to-DataFrame">4.1. dict to DataFrame</h2><pre><code>pd.DataFrame(d.items())
</code></pre><h1 id="fillna">5. fillna</h1><h2 id="用同组的均值填补">5.1. 用同组的均值填补</h2><pre><code>&gt;&gt;&gt; df
  name  value
0    A      1
1    A    NaN
2    B    NaN
3    B      2
4    B      3
5    B      1
6    C      3
7    C    NaN
8    C      3
&gt;&gt;&gt; df[&quot;value&quot;] = df.groupby(&quot;name&quot;).transform(lambda x: x.fillna(x.mean()))
&gt;&gt;&gt; df
  name  value
0    A      1
1    A      1
2    B      2
3    B      2
4    B      3
5    B      1
6    C      3
7    C      3
8    C      3
</code></pre><h1 id="ipython运行python">6. ipython运行python</h1><p>启动新的namespace运行： %run main.py</p>
<p>在原有的namespace运行：%run -i main.py</p>
]]></content>
      
        <categories>
            
            <category> Python </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[java学习笔记3-Object（equal/hashCode/toString）]]></title>
      <url>/2017/05/04/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-3-Object/</url>
      <content type="html"><![CDATA[<h1 id="Object特性">1. Object特性</h1><ul>
<li>所有类的超类</li>
<li>可以引用任何对象</li>
</ul>
<h1 id="equals方法">2. equals方法</h1><p><code>Object</code>类中的<code>equals</code>方法判断两对象是否有相同的<strong>引用</strong></p>
<h2 id="equals的重写">2.1. equals的重写</h2><p>在实际coding中，一般我们都会对<code>equals</code>方法进行重写，例:</p>
<ol>
<li><p>对于超类<code>Employee</code>：</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Employee</span></span>&#123;</div><div class="line">    ...</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object otherObject)</span></span>&#123;</div><div class="line">        <span class="comment">//如果otherObject与this是同一个引用</span></div><div class="line">        <span class="keyword">if</span>(<span class="keyword">this</span> == therObject) <span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line"></div><div class="line">        <span class="comment">//如果therObject为空</span></div><div class="line">        <span class="keyword">if</span>(therObject == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line"></div><div class="line">        <span class="comment">//如果类型不同</span></div><div class="line">        <span class="keyword">if</span>(getClass() != otherObject.getClass()) <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line"></div><div class="line">        <span class="comment">//现在我们已经确认了otherObject是一个非空的Employee对象</span></div><div class="line">        <span class="comment">//为了比较实例域，我们将otherObject转换为Employee类型</span></div><div class="line">        Employee other = (Employee) otherObject</div><div class="line"></div><div class="line">        <span class="comment">//检测实例域是否相等</span></div><div class="line">        <span class="keyword">return</span> name.equals(other.name)</div><div class="line">            &amp;&amp; salary == other.salary</div><div class="line">            &amp;&amp; hireDay.equals(other.hireDay);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p> 为了防止<code>this.name</code>或<code>this.hireDay</code>可能为<code>null</code>的情况，将最后一句改为：</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">return</span> Obejcts.equals(name,other.name)</div><div class="line">    &amp;&amp; salary == other.salary</div><div class="line">    &amp;&amp; Objects.equals(hireDay,other.hireDay);</div></pre></td></tr></table></figure>
<p> <strong><code>Obejcts.equals(a,b)</code>运行过程</strong>：</p>
<ul>
<li>如果<code>a</code>和<code>b</code>都为<code>null</code>，则返回true</li>
<li>如果其中一个为<code>null</code>，返回false</li>
<li>如果都不为<code>null</code>，则调用<code>a.equals(b)</code></li>
</ul>
</li>
<li><p>对于<code>Employee</code>的子类<code>Manager</code></p>
</li>
</ol>
<p>在子类中定义<code>euqals</code>方法时，要首先调用超类的euqals，然后比较子类中的实例域。</p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Manager</span> <span class="keyword">extends</span> <span class="title">Employee</span></span>&#123;</div><div class="line">    ...</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object otherObject)</span></span>&#123;</div><div class="line">        <span class="comment">//先调用超类的equals方法，检验this与otherObject是否属于同一class</span></div><div class="line">        <span class="keyword">if</span>(!<span class="keyword">super</span>.equals(otherObject)) <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">        Manager other = (Manager) otherObejct;</div><div class="line">        <span class="keyword">return</span> bonus == other.bonus</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><h2 id="equals方法的特性">2.2. equals方法的特性</h2><ul>
<li>自反性：若<code>x!=null</code>,则<code>x.equals(x)</code>应返回<code>true</code></li>
<li>对称性：<code>y.equals(x)</code>与<code>x.euqals(y)</code>应返回同样结果</li>
<li>传递性：若<code>x.equals(y)</code>返回<code>true</code>,且<code>y.equals(z)</code>返回<code>true</code>，则<code>x.equals(z)</code>也必须返回<code>true</code></li>
<li>一致性：若x与y的引用对象没有发生变化，则反复调用<code>x.equals(y)</code>应返回同样结果</li>
<li>对任意非空引用x，则<code>x.equals(null)</code>应该返回false</li>
</ul>
<h2 id="相等测试">2.3. 相等测试</h2><p><strong>问题</strong><br>如果隐式（this）和显式（传入的）的参数不属于同一类，equals方法如何处理？</p>
<p><strong>解决方法一</strong><br>在上例中，我们用到了<code>getClass()</code>：</p>
<pre><code>//如果类型不同
      if(getClass() != otherObject.getClass()) return false;
</code></pre><p><strong>解决方法二</strong><br>有的程序员喜欢用<code>instanceof</code>检测：<br>(instanceof 运算符是用来在运行时指出对象是否是特定类的一个实例)</p>
<pre><code>if(!(otherObeject instanceof Employee)) return false;
</code></pre><p><strong>方法一存在的问题</strong><br>若<code>e</code>是一个<code>Employee</code>对象，<code>m</code>是一个<code>Manager</code>对象，且两者具有相同姓名、薪水和雇用日期。</p>
<p>如果<code>Manager</code>没有重新实现<code>equals</code>方法，那么当<code>m1.equals(m2)</code>比较时，就会使用到<code>e.getClass() != m2.getClass()</code>来进行比较，显然结果返回<code>false</code>，因此这不是正确的比较。</p>
<p><strong>方法二存在的问题</strong><br>那么对于<code>e.equals(m)</code>来说，<code>instanceof</code>返回<code>true</code>.（<code>Manager</code>是<code>Employee</code>的一个实例）<br>但对于<code>m.equals(e)</code>来说，<code>instanceof</code>返回<code>false</code></p>
<p>！！！！！违反了对称性！</p>
<p><strong>总结</strong></p>
<ul>
<li>如果子类拥有自己的相等概念，例如若两个<code>Manager</code>对象的姓名、薪水和雇用日期（父类Employee的域）均相等，而奖金（子类Manager的域）不相等，就认为两个<code>Manager</code>不相等。此时可以用<code>getClass</code>检测</li>
<li>如果使用雇员ID(父类Employee的域)来作为相等检测标准，并这个标准适合所有的子类，就可以用<code>instanceof</code>检测，并将<code>Employee</code>的<code>equals</code>申明为<code>final</code></li>
</ul>
<p><strong>完美的equals</strong>：</p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object otherObject)</span></span>&#123;</div><div class="line">    <span class="comment">//检测this与otherObject是否引用同一对象</span></div><div class="line">    <span class="keyword">if</span>(<span class="keyword">this</span>==otherObject)<span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">    <span class="comment">//检测otherObject是否为null</span></div><div class="line">    <span class="keyword">if</span>(otherObject == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">    <span class="comment">//比较this与Object是否属于同一个类，有以下两种方案：</span></div><div class="line">    <span class="comment">//如果equals的语义在每个子类中都有改变，就用getClass:</span></div><div class="line">    <span class="keyword">if</span>(getClass() != otherObject.getClass()) <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">    <span class="comment">//如果所有子类都有统一equals语义，则用instanceof检测：</span></div><div class="line">    <span class="keyword">if</span>(!(otherObject <span class="keyword">instanceof</span> ClassName)) <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">    <span class="comment">//将otherObject转换为相应的类类型</span></div><div class="line">    ClassName other = (ClassName) otherObject</div><div class="line">    <span class="comment">//对所需要的域进行比较</span></div><div class="line">    <span class="keyword">return</span> field1 == other.field1 </div><div class="line">        &amp;&amp; field2 == other.field2</div><div class="line">        &amp;&amp; Objects.equals(field3,other field3)</div><div class="line">        &amp;&amp; ...;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><p><strong>注意</strong>：如果在子类中重新定义<code>equals</code>，则要在其中包含调用<code>super.equals(other)</code></p>
<h1 id="hashCode方法">3. hashCode方法</h1><p>hashCode : 散列码</p>
<p>使用：</p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> hash = <span class="number">0</span></div><div class="line"><span class="keyword">for</span> ( <span class="keyword">int</span> i = <span class="number">0</span> ; i &lt; lenth() ; i++ )&#123;</div><div class="line">    hash = <span class="number">31</span> * hash + charAt(i)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><p><strong>注意</strong></p>
<ul>
<li>每个对象都有一个<em>默认的散列码</em>，值为对象的<em>存储地址</em></li>
<li>字符串的散列码是由内容导出的，因此<code>s</code>和<code>t</code>有相同hashcode</li>
<li>如果重新定义了equals方法，就必须重新定义hashCode方法，且通过equal测试的两个对象的hashCode应该也是相等的，以便用户可以将对象插入到散列表中</li>
<li>hashCode方法应该返回一个整型数值，并使得不同对象的hashCode更均匀。</li>
</ul>
<p>例如：</p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Employee</span></span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span></span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="number">7</span> * name.hashCode()</div><div class="line">            + <span class="number">11</span> * <span class="keyword">new</span> Double(salary).hashCode()</div><div class="line">            + <span class="number">13</span> * hireDay.hashCode();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><p>更方便的方法：</p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span></span>&#123;</div><div class="line">    <span class="keyword">return</span> Objects.hash(name,salary,hireDay);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><h1 id="toString方法">4. toString方法</h1><p>用途：返回表示对象值的字符串</p>
<p>例如：</p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span></span>&#123;</div><div class="line">    <span class="keyword">return</span> getClass().getName()</div><div class="line">        + <span class="string">"[name="</span> + name</div><div class="line">        + <span class="string">",salary="</span> + salary</div><div class="line">        + <span class="string">",hireDay="</span> + hireDay</div><div class="line">        +<span class="string">"]"</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><p>特别地：</p>
<ol>
<li>只要对象与一个字符串通过操作符“+”连接起来，或使用System.out.println(x)，Java编译就会自动调用toString方法。</li>
<li>Object类定义了toString方法，用来打印输出对象所属的类名和散列码。</li>
<li>有趣的是，数组继承了object类的toString方法。修正的方法是采用Array.toString.例如<code>String s = Array.toString(luckyNumbers)</code>。多维数组需要调用<code>Array.deepToString</code>方法。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[xgboost参数调节完全指南（Python版）]]></title>
      <url>/2017/04/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6-xgboost%E5%8F%82%E6%95%B0/</url>
      <content type="html"><![CDATA[<p>本文大多来自于参考文献2.的翻译。</p>
<h1 id="Xgboost参数">1. Xgboost参数</h1><p>XGBoost作者将参数分为3类：</p>
<ol>
<li>基本(General)参数：指导整体函数</li>
<li>提升(Booster)参数：在每一步指导每个提升（树或回归）</li>
<li>学习任务(Learning Task Parameters)参数：指导优化模型表现</li>
</ol>
<h2 id="基本参数">1.1. 基本参数</h2><h3 id="booster">1.1.1. booster</h3><ol>
<li>默认值：gbtree</li>
<li>含义：在每次迭代中的模型类型，有两种选择：</li>
</ol>
<ul>
<li>gbtree:树模型</li>
<li>gblinear:线性模型</li>
</ul>
<h3 id="silent">1.1.2. silent</h3><ol>
<li>默认值：0</li>
<li>含义</li>
</ol>
<ul>
<li>0=运行时打印running messages</li>
<li>1=不打running messages</li>
</ul>
<h3 id="nthread">1.1.3. nthread</h3><ol>
<li>运行时的最大线程数</li>
<li>默认值：占当前计算机的最大线程</li>
</ol>
<h2 id="提升参数">1.2. 提升参数</h2><p>这里仅仅介绍树模型（gbtree）的相关参数。</p>
<h3 id="eta">1.2.1. eta</h3><ol>
<li>学习步长</li>
<li>default=0.3</li>
<li>一般调整下限为0.01-0.2</li>
</ol>
<h3 id="min-child-weight">1.2.2. min_child_weight</h3><ol>
<li>表示所有孩子节点(all observations required in a child)的最小权重和</li>
<li>一般都用来控制过拟合。</li>
<li>但如果调得太高就会导致欠拟合。</li>
<li>default=1</li>
</ol>
<h3 id="max-depth">1.2.3. max_depth</h3><ol>
<li>default=6</li>
<li>用来控制过拟合</li>
<li>一般在3-10之间</li>
</ol>
<h3 id="gamma">1.2.4. gamma</h3><ol>
<li>default=0</li>
<li>range: [0,∞]</li>
<li>模型在默认情况下，对于一个节点的划分只有在其损失函数得到结果大于0的情况下才进行，而gamma给定了所需的最低损失函数的值</li>
<li>gamma值使得算法更conservation，且其值依赖于损失函数，在模型中应该进行调参。</li>
</ol>
<h3 id="max-delta-step">1.2.5. max_delta_step</h3><ol>
<li>default=0</li>
<li>在最大化步长的时候，我们允许每个树的权重去估算它。</li>
<li>当max_delta_step=0时，意味着没有误差</li>
<li>当max_delta_step&gt;0时，意味着结果更保守</li>
<li>一般不需要调参。但当类别及不平衡的逻辑回归时可能会用到。</li>
</ol>
<h3 id="subsample-default-1">1.2.6. subsample [default=1]</h3><p>Same as the subsample of GBM. Denotes the fraction of observations to be randomly samples for each tree.<br>Lower values make the algorithm more conservative and prevents overfitting but too small values might lead to under-fitting.<br>Typical values: 0.5-1</p>
<h3 id="colsample-bytree-default-1">1.2.7. colsample_bytree [default=1]</h3><p>Similar to max_features in GBM. Denotes the fraction of columns to be randomly samples for each tree.</p>
<p>Typical values: 0.5-1</p>
<h3 id="colsample-bylevel-default-1">1.2.8. colsample_bylevel [default=1]</h3><p>Denotes the subsample ratio of columns for each split, in each level.<br>I don’t use this often because subsample and colsample_bytree will do the job<br>for you. but you can explore further if you feel so.</p>
<h3 id="lambda-default-1">1.2.9. lambda [default=1]</h3><p>L2 regularization term on weights (analogous to Ridge regression)<br>This used to handle the regularization part of XGBoost. Though many data scientists don’t use it often, it should be explored to reduce overfitting.</p>
<h3 id="alpha-default-0">1.2.10. alpha [default=0]</h3><p>L1 regularization term on weight (analogous to Lasso regression)<br>Can be used in case of very high dimensionality so that the algorithm runs faster when implemented</p>
<h3 id="scale-pos-weight-default-1">1.2.11. scale_pos_weight [default=1]</h3><p>A value greater than 0 should be used in case of high class imbalance as it helps in faster convergence.<br>Control the balance of positive and negative weights, useful for unbalanced classes. A typical value to consider: sum(negative cases) / sum(positive cases) See Parameters Tuning for more discussion. Also see Higgs Kaggle competition demo for examples: R, py1, py2, py3</p>
<p>控制正负样本权重的平衡。一般对非平衡的很有用。一个很特殊的取值是：负样本个数/正样本个数。</p>
<h3 id="不均衡数据在xgboost中的处理">1.2.12. 不均衡数据在xgboost中的处理</h3><p><a href="https://github.com/dmlc/xgboost/blob/master/doc/how_to/param_tuning.md" target="_blank" rel="external">官方文档</a>:</p>
<p>对于一些case，比如：广告点击日志，数据集极不平衡。这会影响xgboost模型的训练，有两个方法来改进它。</p>
<p>如果你关心的预测的ranking order（AUC)： – 通过scale_pos_weight来平衡正负类的权重 – 使用AUC进行评估</p>
<p>如果你关心的是预测的正确率： – 不能再平衡（re-balance）数据集 – 将参数max_delta_step设置到一个有限的数（比如：1）可以获得效果提升.</p>
<h2 id="学习任务参数">1.3. 学习任务参数</h2><h3 id="objective-default-reg-linear">1.3.1. objective [default=reg:linear]</h3><ol>
<li>default=reg:linear</li>
<li>定义学习任务及相应的学习目标，可选的目标函数如下：</li>
</ol>
<ul>
<li>“reg:linear” –线性回归。</li>
<li>“reg:logistic” –逻辑回归。</li>
<li>“binary:logistic” –二分类的逻辑回归问题，输出为概率。</li>
<li>“binary:logitraw” –二分类的逻辑回归问题，输出的结果为wTx。</li>
<li>“count:poisson” –计数问题的poisson回归，输出结果为poisson分布。在poisson回归中，max_delta_step的缺省值为0.7。(used to safeguard optimization)</li>
<li>“multi:softmax” –让XGBoost采用softmax目标函数处理多分类问题，同时需要设置参数num_class（类别个数）</li>
<li>“multi:softprob” –和softmax一样，但是输出的是ndata * nclass的向量，可以将该向量reshape成ndata行nclass列的矩阵。没行数据表示样本所属于每个类别的概率。</li>
<li>“rank:pairwise” –set XGBoost to do ranking task by minimizing the pairwise loss</li>
<li></li>
</ul>
<h3 id="eval-metric">1.3.2. eval_metric</h3><ol>
<li>默认值根据objective参数调整</li>
<li>用来验证数据的参数</li>
<li>几个典型值：</li>
</ol>
<ul>
<li>rmse – root mean square error</li>
<li>mae – mean absolute error</li>
<li>logloss – negative log-likelihood</li>
<li>error – Binary classification error rate (0.5 threshold)</li>
<li>merror – Multiclass classification error rate</li>
<li>mlogloss – Multiclass logloss</li>
<li>auc: Area under the curve</li>
</ul>
<h3 id="seed-default-0">1.3.3. seed [default=0]</h3><p>The random number seed.<br>Can be used for generating reproducible results and also for parameter tuning.</p>
<h1 id="例：CTR问题的正样本过少">2. 例：CTR问题的正样本过少</h1><p>参考文献[xgboost导读和实战]</p>
<p>《xgboost导读和实战》中提到，CTR问题的正样本很稀疏，根据理论推导，会导致叶子节点权重变大，进而导致每一步的估计step过大。</p>
<p>这时可以调节以下参数：</p>
<p><code>min_child_weight</code></p>
<p>默认为1.是每个叶子里h的和至少是多少。对正负样本不均衡时的0-1分类而言，假设h在0.01附近，min_child_weight为1意味着叶子节点中最少需要包含100 个样本。这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。</p>
<p><code>eta</code><br>shrinkage 参数，用于更新叶子节点权重时，乘以该系数，避免步长过大。参数值越大，越可能无法收敛。把学习率eta设置的小一些，小学习率可以使得后面的学习更加仔细。</p>
<p><code>scale_pos_weight</code><br>如果优化的是仅仅展示排序，就是AUC的话，可以采用平衡正负样本权重的<br>办法调大正样本权重。设置 scale_pos_weight就可以把正样本权重乘这个系数。如果还需要优化回归的性能，还需要在此基础上做下 recalibration。</p>
<p><code>max_delta_step</code><br>如果设立了该值，对叶子节点的权重值做了约束在 [max_delta_step,max_delta_step]。以防在某些 loss 下权重值过大，默认是 0（其实代表 inf)。可以试试把这个参数设置到 1-10 之间的一个值。这样会防止做太大的更新步子，<br>使得更新更加平缓。</p>
<h1 id="交叉验证">3. 交叉验证</h1><p>xgboost自带的交叉验证据说很好用。</p>
<p>下面是参考文献3给出的一个使用案例：</p>
<pre><code>cvresult = xgb.cv(xgb_param, 
                    xgtrain, num_boost_round=alg.get_params()[&apos;n_estimators&apos;],
                    nfold=cv_folds,
                    metrics=&apos;auc&apos;, early_stopping_rounds=early_stopping_rounds, show_progress=False)
</code></pre><p>其中：</p>
<ul>
<li>xgb_params：参数</li>
<li>xgtrain:训练集</li>
<li>num_boost_round：树个数（迭代次数）</li>
<li>nfold:kfold的k</li>
<li>metrics:在CV中的评价度量指标</li>
<li>early_stopping_rounds：Activates early stopping. CV error needs to decrease at least every <early_stopping_rounds> round(s) to continue. Last entry in evaluation history is the one from best iteration.</early_stopping_rounds></li>
</ul>
<h1 id="参考文献">4. 参考文献</h1><ol>
<li>《xgboost导读和实战》</li>
<li><a href="http://wepon.me/2016/05/07/XGBoost%E6%B5%85%E5%85%A5%E6%B5%85%E5%87%BA/" target="_blank" rel="external">Xgboost深入浅出</a></li>
<li><a href="https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/" target="_blank" rel="external">Complete Guide to Parameter Tuning in XGBoost (with codes in Python)</a></li>
<li><a href="http://xgboost.readthedocs.io/en/latest/parameter.html" target="_blank" rel="external">xgboost参数官方文档</a></li>
<li><a href="http://blog.csdn.net/u010657489/article/details/51952785" target="_blank" rel="external">XGBoost参数调优完全指南（附Python代码）</a></li>
<li><a href="http://d0evi1.com/sklearn/imbalanced_classes/" target="_blank" rel="external">如何处理偏斜类(imbalanced classes)</a></li>
<li><a href="https://github.com/dmlc/xgboost/blob/master/doc/parameter.md" target="_blank" rel="external">XGBoost Parameters</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 机器学习框架 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[特征工程]]></title>
      <url>/2017/04/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5-O2O%E4%BC%98%E6%83%A0%E5%88%B8%E9%A2%84%E6%B5%8B-%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/</url>
      <content type="html"><![CDATA[<h1 id="特征工程">1. 特征工程</h1><h2 id="别人的例子">1.1. 别人的例子</h2><p><img src="http://om1bxijvl.bkt.clouddn.com/2017-04-25-16-54-35.png" alt=""><br><img src="http://om1bxijvl.bkt.clouddn.com/2017-04-25-16-54-53.png" alt=""> </p>
<h2 id="特征选择">1.2. 特征选择</h2><p>特征选择，就是从多个特征中，挑选出一些对结果预测最有用的特征。因为原始的特征中可能会有冗余和噪声。<br>特征选择和降维有什么区别呢？前者只踢掉原本特征里和结果预测关系不大的， 后者做特征的计算组合构成新特征。</p>
<h3 id="过滤型">1.2.1. 过滤型</h3><ul>
<li>方法：  评估单个特征和结果值之间的相关程度， 排序留下Top相关的特征部分。 </li>
<li>评价方式：Pearson相关系数， 互信息， 距离相关度。 </li>
<li>缺点：只评估了单个特征对结果的影响，没有考虑到特征之间的关联作用， 可能把有用的关联特征误踢掉。因此工业界使用比较少。 </li>
<li>python包：SelectKBest指定过滤个数、SelectPercentile指定过滤百分比。</li>
</ul>
<h3 id="包裹型">1.2.2. 包裹型</h3><ul>
<li>方法：把特征选择看做一个特征子集搜索问题， 筛选各种特<br>征子集， 用模型评估效果。 </li>
<li>典型算法：“递归特征删除算法”。 </li>
<li>应用在逻辑回归的过程：用全量特征跑一个模型；根据线性模型的系数(体现相关性)，删掉5-10%的弱特征，观察准确率/auc的变化；逐步进行， 直至准确率/auc出现大的下滑停止。 </li>
<li>python包：RFE 
　　</li>
</ul>
<h3 id="嵌入型">1.2.3. 嵌入型</h3><ul>
<li>方法：根据模型来分析特征的重要性，最常见的方式为用正则化方式来做特征选择。 </li>
<li>举例：最早在电商用LR做CTR预估， 在3-5亿维的系数特征上用L1正则化的LR模型。上一篇介绍了L1正则化有截断作用，剩余2-3千万的feature， 意味着其他的feature重要度不够。 </li>
<li>python包：feature_selection.SelectFromModel选出权重不为0的特征。</li>
</ul>
<h1 id="参考文献">2. 参考文献</h1><ol>
<li><a href="https://ask.julyedu.com/question/7114" target="_blank" rel="external">四月机器学习算法班—特征工程笔记</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> o2o优惠券使用预测 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 特征工程 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[linux常见命令]]></title>
      <url>/2017/04/14/linux%E5%B8%B8%E8%A7%81%E5%91%BD%E4%BB%A4/</url>
      <content type="html"><![CDATA[<h1 id="IO">1. IO</h1><h2 id="linux-windows互传">1.1. linux/windows互传</h2><p>需要安装：yum install -y lrzsz</p>
<p>从Windows上传文件<code>[root@localhost src]# rz</code><br>从Linux下载文件<code>sz nginx-1.6.2.tar.gz</code></p>
<h2 id="linux互传">1.2. linux互传</h2><ol>
<li>从服务器下载文件<br> scp username@servername:/path/filename /tmp/local_destination<br> 例如scp codinglog@192.168.0.101:/home/kimi/test.txt  把192.168.0.101上的/home/kimi/test.txt的文件下载到 /tmp/local_destination</li>
<li>上传本地文件到服务器<br> scp /path/local_filename username@servername:/path<br> 例如scp /var/www/test.php  codinglog@192.168.0.101:/var/www/  把本机/var/www/目录下的test.php文件上传到192.168.0.101这台服务器上的/var/www/目录中</li>
<li>从服务器下载整个目录<br> scp -r username@servername:remote_dir/ /tmp/local_dir<br> 例如:scp -r codinglog@192.168.0.101 /home/kimi/test  /tmp/local_dir</li>
<li>上传目录到服务器<br> scp  -r /tmp/local_dir username@servername:remote_dir<br> 例如：scp -r test      codinglog@192.168.0.101:/var/www/把当前目录下的test目录上传到服务器的/var/www/目录</li>
</ol>
<h1 id="文件夹">2. 文件夹</h1><p>新建文件夹<code>mkdir name</code></p>
<h1 id="杂絮">3. 杂絮</h1><p>查看硬盘情况<code>df -h</code><br>合并文件<code>cat *.csv  &gt; full.csv</code><br>查看文件<code>$ ps -ef | grep 关键字</code></p>
<h1 id="解压">4. 解压</h1><h2 id="批量解压-zip">4.1. 批量解压.zip</h2><p>两种方式：（经测试第一种好用）</p>
<pre><code>ls *.zip | xargs -n1 unzip
unzip &quot;*.zip&quot;
</code></pre><h2 id="批量解压-tar-gz">4.2. 批量解压.tar.gz</h2><pre><code>ls *.tar.gz | xargs -n1 tar xzvf    
</code></pre><h1 id="vim">5. vim</h1><p><code>i</code>——进入插入模式<br><code>ESC+:wq!</code>：保存，退出<br><code>ESC+:q!</code>：不保存，退出</p>
<h1 id="VNC-tiger">6. VNC-tiger</h1><p>安装：<br><a href="http://www.jianshu.com/p/35640fc5672b" target="_blank" rel="external">CentOs 7安装配置VNC Server</a><br><a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-vnc-remote-access-for-the-gnome-desktop-on-centos-7" target="_blank" rel="external">digitalOcean,How to install vncserver in centos 7</a></p>
<p>使用：</p>
<p>help:<code>vncserver -help</code><br>开启：<code>vncserver :1</code><br>按照一定比例输出（屏幕旋转）：<code>vncserver 900x1440 :1</code><br>停止：<code>vncserver -kill: 1</code><br>临时文档：<code>/tmp/.X11-unix</code>.</p>
<h1 id="用sublime搭建简单的python">7. 用sublime搭建简单的python</h1><p>安装 Python，安装时选择添加路径到系统中，或者稍后自己添加也可<br>随便写个 demo，Ctrl + B 就可以运行了</p>
<p><a href="http://docs.sublimetext.info/en/latest/getting_started/install.html?highlight=ln" target="_blank" rel="external">sublime官方文档</a><br><a href="https://www.zhihu.com/question/22904994" target="_blank" rel="external">各路方法</a></p>
<p>中文无法输入问题解决<a href="http://www.jianshu.com/p/bf05fb3a4709" target="_blank" rel="external">解决Ubuntu下Sublime Text 3无法输入中文</a><br><a href="http://www.brightempty.com/?p=91" target="_blank" rel="external">装python包</a></p>
<h1 id="nohup">8. nohup</h1><pre><code>nohup command &gt; nohup.out &amp;
</code></pre><p>nohup相关：<br>将nohup后面的<code>command</code>设置成后台运行，并且将标准输出的日志重定向至文件nohup.out。<br>查看运行状态：jobs<br>查看日志内容：tail -f nohup.out (ctrl + c 退出查看)<br>查看进程信息：<br>ps -ef |grep java<br>ps -ef | grep rm<br>停止运行 kill %n<br>很好的参考文献：<a href="http://blog.sina.com.cn/s/blog_90546d6f0101en9y.html" target="_blank" rel="external">http://blog.sina.com.cn/s/blog_90546d6f0101en9y.html</a></p>
<h1 id="更改某个目录的权限">9. 更改某个目录的权限</h1><pre><code>chown -R -v ubuntu:ubuntu info
</code></pre>]]></content>
      
        <categories>
            
            <category> linux </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[python实现某网站自动打卡]]></title>
      <url>/2017/04/05/Python-python%E5%AE%9E%E7%8E%B0%E6%9F%90%E7%BD%91%E7%AB%99%E8%87%AA%E5%8A%A8%E6%89%93%E5%8D%A1/</url>
      <content type="html"><![CDATA[<p>最近学校出了个科学上网的小网站，但流量有限，可以通过每天打卡来获取几十兆流量。奈何自己记性很差，总忘记打卡。因此决定写一个自动打卡的小程序。</p>
<h1 id="思路总结">1. 思路总结</h1><ol>
<li>用抓包工具仔细分析下登陆以及回帖时post了哪些数据，这些数据从何而来（chrome）</li>
<li>python requests库，用requests.Session().post来登陆和回帖，用get来读取页面内容；</li>
<li>登陆之后，正则找到“签到”或”不能签到”，来进行下一步</li>
<li>若能签到，就发出签到URL的请求（因为链接从原来上来说是一种URL）</li>
<li>记录每次签到的log</li>
<li>最后的最后，使用写个.sh脚本，里面运行这个python程序，配置个相应的plist，每天自动执行（MAC OS）</li>
</ol>
<h1 id="模拟登陆原理">2. 模拟登陆原理</h1><h2 id="浏览器访问服务器的过程">2.1. 浏览器访问服务器的过程</h2><p>一次完整的HTTP请求过程从TCP三次握手建立连接成功后开始。</p>
<ol>
<li>用户发起请求（点击等）</li>
<li>浏览器向WEB服务器发出一个请求<strong>Http Request（请求）</strong></li>
<li>Web服务器发相应<strong>Http Response</strong></li>
<li>浏览器解析</li>
</ol>
<h2 id="HTTP消息">2.2. HTTP消息</h2><p>更多关于HTTP请求过程，见参考资料<a href="https://foofish.net/http-request-process.html" target="_blank" rel="external">一次完整的HTTP请求过程</a></p>
<p>HTTP 是一种无状态的协议,协议本身不保留之前的一切请求信息和响应信息，也就是说，对于一个刚刚发送了 HTTP 请求的客户端再次发起请求时，服务端并不知道之前访问过。这样设计的理由是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设计如此简单。<br>但是，无状态导致业务处理就变得棘手了，一个简单的例子就是网上购物的时候，当我在一个页面把商品加入购物车的时候，正当我要跳转到支付页面时，如果没有一种机制来保持我的登录状态，那么之前选的商品全部丢失了。<br>因此，为了在无状态的HTTP协议之上维护会话状态，使服务器可以知道当前是和哪个客户端打交道，于是Cookie技术应运而生，Cookie通俗的理解就是服务端分配给客户端的一个标识。</p>
<h2 id="Cookie原理">2.3. Cookie原理</h2><p>Cookie原理其实也非常简单，总共4个步骤维护HTTP会话。<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-04-05-15-55-17.png" alt=""> </p>
<ol>
<li>浏览器第一次发起HTTP请求时，没有携带任何Cookie信息，服务器收到请求并返回给浏览器的HTTP响应，同时HTTP响应包括了一个响应头Set-Cookie字段，它的值是要设置的Cookie。 </li>
<li>浏览器收到来自服务器的HTTP响应，响应头中发现有Set-Cookie字段，就会将该字段的值保存在内存或者硬盘中。 </li>
<li>浏览器下次给该服务器发送HTTP请求时，会将Cookie信息附加在HTTP请求的头字段Cookie中。 </li>
<li>服务器收到这个HTTP请求，发现请求头中有Cookie字段，便知道之前就和这个用户打过交道了。 </li>
</ol>
<p>理解了Cookie的基本原理之后，我们就可以尝试用Python来实现模拟登录。 </p>
<h1 id="点击登陆后，究竟发生了什么？">3. 点击登陆后，究竟发生了什么？</h1><p>为了看看浏览器究竟做了什么，我们首先进入登录界面，随便输入一个密码，点击登录。打开Chrome开发者工具条(F12)。选择Network下的Headers：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-04-05-16-12-54.png" alt=""> </p>
<p>从上图我们可以发现以下关键信息：</p>
<ol>
<li>登陆的URL地址是General下面的Request URL的那个。</li>
<li>登录需要提供的表单（Form Data）有三个，email(用户名),passwd（密码）,remember_me(就是那个“记住我”的选项，我们可以从它的html中搜索得出，如下图)。<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-04-05-16-20-21.png" alt=""> </li>
</ol>
<p>到这里，基本上摸清了浏览器登录时所需要的数据是如何获取的了，那么现在就可以开始撸代码用Python模拟浏览器来登录。</p>
<p>由于我今天登陆的网站实在是太简易了，也不需要分析header就可以登陆。所以此处省略header的分析。</p>
<p>我打算基于python的requests库来完成这一过程。</p>
<h1 id="python实现模拟登陆">4. python实现模拟登陆</h1><pre><code><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">email=<span class="string">'jiayi797@163.com'</span></div><div class="line">password=<span class="string">'这里加密了'</span></div><div class="line">loginurl = <span class="string">'https://ssr.0v0.loan/auth/login'</span></div><div class="line"><span class="comment"># 这行代码，是用来维持cookie的，你后续的操作都不用担心cookie，他会自动带上相应的cookie</span></div><div class="line">s = requests.Session()</div><div class="line"><span class="comment"># 我们需要带表单的参数</span></div><div class="line">loginparams=&#123;<span class="string">'email'</span>:email,<span class="string">'passwd'</span>:password,<span class="string">'remember_me'</span>:<span class="string">'ture'</span>&#125;</div><div class="line"><span class="comment"># post 数据实现登录</span></div><div class="line">r = s.post(loginurl,data=loginparams)</div><div class="line"><span class="comment"># 验证是否登陆成功，抓取首页看看内容</span></div><div class="line">r = s.get(loginurl)</div></pre></td></tr></table></figure>
</code></pre><p>运行完这些后，我们发现r已经有内容了。接下来我们进行自动签到。</p>
<h1 id="签到">5. 签到</h1><p>我们查看r._content的内容，是主页的html内容。很长。为了方便分析，我只拿出“签到”标签下的内容：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"col-md-6"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"box box-primary"</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"box-header"</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"fa fa-pencil"</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">h3</span> <span class="attr">class</span>=<span class="string">"box-title"</span>&gt;</span>签到获取流量<span class="tag">&lt;/<span class="name">h3</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line">        <span class="comment">&lt;!-- /.box-header --&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"box-body"</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">p</span>&gt;</span> 每24小时可以签到一次。<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">p</span>&gt;</span>上次签到时间：<span class="tag">&lt;<span class="name">code</span>&gt;</span>2017-04-04 17:11:22<span class="tag">&lt;/<span class="name">code</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">p</span> <span class="attr">id</span>=<span class="string">"checkin-btn"</span>&gt;</span></div><div class="line">                <span class="tag">&lt;<span class="name">button</span> <span class="attr">id</span>=<span class="string">"checkin"</span> <span class="attr">class</span>=<span class="string">"btn btn-success  btn-flat"</span>&gt;</span>签到<span class="tag">&lt;/<span class="name">button</span>&gt;</span></div><div class="line">            <span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">p</span> <span class="attr">id</span>=<span class="string">"checkin-msg"</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line">        <span class="comment">&lt;!-- /.box-body --&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line">    <span class="comment">&lt;!-- /.box --&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line"><span class="comment">&lt;!-- /.col (right) --&gt;</span></div></pre></td></tr></table></figure>
<p>需要注意的还有以下这个脚本：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">&lt;script&gt;</div><div class="line">    $(<span class="built_in">document</span>).ready(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</div><div class="line">        $(<span class="string">"#checkin"</span>).click(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</div><div class="line">            $.ajax(&#123;</div><div class="line">                <span class="attr">type</span>: <span class="string">"POST"</span>,</div><div class="line">                <span class="attr">url</span>: <span class="string">"/user/checkin"</span>,</div><div class="line">                <span class="attr">dataType</span>: <span class="string">"json"</span>,</div><div class="line">                <span class="attr">success</span>: <span class="function"><span class="keyword">function</span> (<span class="params">data</span>) </span>&#123;</div><div class="line">                    $(<span class="string">"#checkin-msg"</span>).html(data.msg);</div><div class="line">                    $(<span class="string">"#checkin-btn"</span>).hide();</div><div class="line">                &#125;,</div><div class="line">                <span class="attr">error</span>: <span class="function"><span class="keyword">function</span> (<span class="params">jqXHR</span>) </span>&#123;</div><div class="line">                    alert(<span class="string">"发生错误："</span> + jqXHR.status);</div><div class="line">                &#125;</div><div class="line">            &#125;)</div><div class="line">        &#125;)</div><div class="line">    &#125;)</div><div class="line">&lt;<span class="regexp">/script&gt;</span></div></pre></td></tr></table></figure>
<p>从脚本中我们读到，签到的类型是post，url是/user/checkin，<br>因此我们试一下post一个这样的url会有什么后果。</p>
<pre><code><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">checkinUrl=<span class="string">"https://ssr.0v0.loan/user/checkin"</span></div><div class="line">r=s.post(checkinUrl)<span class="comment">#执行签到</span></div><div class="line">r = s.get(loginurl)<span class="comment">#查看签到结果</span></div></pre></td></tr></table></figure>
</code></pre><p>我们发现，签到栏的HTML已经变成了；</p>
<pre><code><figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"col-md-6"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"box box-primary"</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"box-header"</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"fa fa-pencil"</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">h3</span> <span class="attr">class</span>=<span class="string">"box-title"</span>&gt;</span>签到获取流量<span class="tag">&lt;/<span class="name">h3</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line">        <span class="comment">&lt;!-- /.box-header --&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"box-body"</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">p</span>&gt;</span> 每24小时可以签到一次。<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">p</span>&gt;</span>上次签到时间：<span class="tag">&lt;<span class="name">code</span>&gt;</span>2017-04-05 14:08:02<span class="tag">&lt;/<span class="name">code</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">                <span class="tag">&lt;<span class="name">p</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">"btn btn-success btn-flat disabled"</span> <span class="attr">href</span>=<span class="string">"#"</span>&gt;</span>不能签到<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">p</span> <span class="attr">id</span>=<span class="string">"checkin-msg"</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line">        <span class="comment">&lt;!-- /.box-body --&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line">    <span class="comment">&lt;!-- /.box --&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line"><span class="comment">&lt;!-- /.col (right) --&gt;</span></div></pre></td></tr></table></figure>
</code></pre><p>即：</p>
<pre><code>&lt;button id=&quot;checkin&quot; class=&quot;btn btn-success  btn-flat&quot;&gt;签到&lt;/button&gt;
</code></pre><p>变成了：</p>
<pre><code>&lt;a class=&quot;btn btn-success btn-flat disabled&quot; href=&quot;#&quot;&gt;不能签到&lt;/a&gt;
</code></pre><p>大题框架搭完了。接下来要做的就是一些细节。</p>
<h1 id="判断是否已签到">6. 判断是否已签到</h1><p>接下来要做的就是用正则，找到“签到”或者“不能签到”的对应标签，来获得一个当前状态。</p>
<p>首先我想到的是最简单的方式，用python自带的<code>re.search()</code>。</p>
<pre><code><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">check</span><span class="params">(str)</span>:</span></div><div class="line">    hasCheckIn=<span class="string">'&lt;button id="checkin" class="btn btn-success  btn-flat"&gt;'</span></div><div class="line">    noChecked=<span class="string">'&lt;a class="btn btn-success btn-flat disabled" href="#"&gt;'</span></div><div class="line">    yes=re.search(hasCheckIn,str)</div><div class="line">    <span class="keyword">if</span> yes==<span class="keyword">None</span>:</div><div class="line">        no=re.search(noChecked,str)</div><div class="line">        <span class="keyword">if</span> no==<span class="keyword">None</span>:</div><div class="line">            <span class="keyword">return</span> <span class="number">-1</span> <span class="comment">#什么都没找到</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">return</span> <span class="number">0</span><span class="comment">#找到了“不能签到”</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">1</span><span class="comment">#找到了“签到”</span></div></pre></td></tr></table></figure>
</code></pre><h1 id="获取当前流量">7. 获取当前流量</h1><p>先找到流量的对应标签：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dl</span> <span class="attr">class</span>=<span class="string">"dl-horizontal"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">dt</span>&gt;</span>总流量<span class="tag">&lt;/<span class="name">dt</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">dd</span>&gt;</span>1.53GB<span class="tag">&lt;/<span class="name">dd</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">dt</span>&gt;</span>已用流量<span class="tag">&lt;/<span class="name">dt</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">dd</span>&gt;</span>253.36MB<span class="tag">&lt;/<span class="name">dd</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">dt</span>&gt;</span>剩余流量<span class="tag">&lt;/<span class="name">dt</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">dd</span>&gt;</span>1.29GB<span class="tag">&lt;/<span class="name">dd</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">dl</span>&gt;</span></div></pre></td></tr></table></figure>
<p>想要获取标签内的内容（而不是暴力地匹配字符串），我们就需要用到另一种匹配方式——正则表达式</p>
<p>举个例子，我们想要获取<a href=""></a>之间的内容，那么我们可以这么写：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#正则表达式获取&lt;tr&gt;&lt;/tr&gt;之间内容  </span></div><div class="line">res_tr = <span class="string">r'&lt;tr&gt;(.*?)&lt;/tr&gt;'</span>  </div><div class="line">m_tr =  re.findall(res_tr,language,re.S|re.M)  </div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> m_tr:  </div><div class="line">    <span class="keyword">print</span> line  </div><div class="line">    <span class="comment">#获取表格第一列th 属性  </span></div><div class="line">    res_th = <span class="string">r'&lt;th&gt;(.*?)&lt;/th&gt;'</span>    </div><div class="line">    m_th = re.findall(res_th,line,re.S|re.M)  </div><div class="line">    <span class="keyword">for</span> mm <span class="keyword">in</span> m_th:  </div><div class="line">        <span class="keyword">print</span> unicode(mm,<span class="string">'utf-8'</span>),  <span class="comment">#unicode防止乱  </span></div><div class="line">    <span class="comment">#获取表格第二列td 属性值  </span></div><div class="line">    res_td = <span class="string">r'&lt;td&gt;(.*?)&lt;/td&gt;'</span>  </div><div class="line">    m_td = re.findall(res_td,line,re.S|re.M)  </div><div class="line">    <span class="keyword">for</span> nn <span class="keyword">in</span> m_td:  </div><div class="line">        <span class="keyword">print</span> unicode(nn,<span class="string">'utf-8'</span>)</div></pre></td></tr></table></figure>
<p>其中，res是匹配模式。<br><code>r’</code>是匹配模式的开头，<br><code>&lt;tr</code>是先匹配字符串<code>&lt;tr</code><br><code>.</code>是匹配任意字符，除了换行符<br><code>*</code>是匹配0个或多个的表达式<br><code>?</code>是匹配0个或1个由前面的正则表达式定义的片段，非贪婪方式<br>依次类推</p>
<p><code>re.S</code>使<code>.</code>匹配包括换行在内的所有字符<br><code>re.M</code>:多行匹配，影响 ^ 和 $</p>
<p>因此，我们的思路是，匹配<code>&lt;dt&gt;总流量&lt;/dt&gt;</code>到<code>&lt;/dd&gt;&lt;/dl&gt;</code>之间的内容。</p>
<p>改写以上匹配式子为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">match_flows</span><span class="params">(str)</span>:</span></div><div class="line">    res = <span class="string">r'&lt;dl class="dl-horizontal"&gt;(.*?)&lt;/dl&gt;'</span></div><div class="line">    mm = re.findall(</div><div class="line">        res, str, re.S | re.M)</div><div class="line">    res=<span class="string">r'&lt;dd&gt;(.*?)&lt;/dd&gt;'</span></div><div class="line">    mm= re.findall(</div><div class="line">        res, mm[<span class="number">0</span>], re.S | re.M)</div><div class="line">    <span class="keyword">return</span> mm</div></pre></td></tr></table></figure>
<h1 id="记录当前操作">8. 记录当前操作</h1><p>首先</p>
<pre><code>import logging
</code></pre><p>然后：</p>
<pre><code># 配置日志文件和日志级别
logging.basicConfig(filename=&apos;logger.log&apos;, level=logging.INFO)

nowtime=time.strftime(&apos;%Y-%m-%d&apos;,time.localtime(time.time()))#获取当前时间
str= nowtime+&apos;,\t总流量：&apos;+lastFlows[0]+&apos;,\t已用流量：&apos;+lastFlows[1]+&apos;,\t剩余流量：&apos;+lastFlows[2]
logging.info(str)#写入日志
</code></pre><h1 id="操作系统定期执行Python脚本">9. 操作系统定期执行Python脚本</h1><p>见参考文献4.</p>
<h1 id="全部代码">10. 全部代码</h1><pre><code><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#! /usr/bin/env python</span></div><div class="line"><span class="comment"># coding:utf-8</span></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">import</span> logging</div><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="comment"># 配置日志文件和日志级别</span></div><div class="line">logging.basicConfig(filename=<span class="string">'logger.log'</span>, level=logging.INFO)</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">check</span><span class="params">(str)</span>:</span></div><div class="line">    hasCheckIn=<span class="string">'&lt;button id="checkin" class="btn btn-success  btn-flat"&gt;'</span></div><div class="line">    noChecked=<span class="string">'&lt;a class="btn btn-success btn-flat disabled" href="#"&gt;'</span></div><div class="line">    yes=re.search(hasCheckIn,str)</div><div class="line">    <span class="keyword">if</span> yes==<span class="keyword">None</span>:</div><div class="line">        no=re.search(noChecked,str)</div><div class="line">        <span class="keyword">if</span> no==<span class="keyword">None</span>:</div><div class="line">            <span class="keyword">return</span> <span class="number">-1</span> <span class="comment">#什么都没找到</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">return</span> <span class="number">0</span><span class="comment">#找到了“不能签到”</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">1</span><span class="comment">#找到了“签到”</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">match_flows</span><span class="params">(str)</span>:</span></div><div class="line">    res = <span class="string">r'&lt;dl class="dl-horizontal"&gt;(.*?)&lt;/dl&gt;'</span></div><div class="line">    mm = re.findall(</div><div class="line">        res, str, re.S | re.M)</div><div class="line">    res=<span class="string">r'&lt;dd&gt;(.*?)&lt;/dd&gt;'</span></div><div class="line">    mm= re.findall(</div><div class="line">        res, mm[<span class="number">0</span>], re.S | re.M)</div><div class="line">    <span class="keyword">return</span> mm</div><div class="line">    <span class="comment">## 这段代码是用于解决中文报错的问题</span></div><div class="line">reload(sys)</div><div class="line">sys.setdefaultencoding(<span class="string">"utf8"</span>)</div><div class="line">email=<span class="string">'你的账号'</span></div><div class="line">password=<span class="string">'你的密码'</span></div><div class="line">loginurl = <span class="string">'https://ssr.0v0.loan/auth/login'</span></div><div class="line"><span class="comment"># 这行代码，是用来维持cookie的，你后续的操作都不用担心cookie，他会自动带上相应的cookie</span></div><div class="line">s = requests.Session()</div><div class="line"><span class="comment"># 我们需要带表单的参数</span></div><div class="line">loginparams=&#123;<span class="string">'email'</span>:email,<span class="string">'passwd'</span>:password,<span class="string">'remember_me'</span>:<span class="string">'ture'</span>&#125;</div><div class="line"><span class="comment"># post 数据实现登录</span></div><div class="line">r = s.post(loginurl,data=loginparams)</div><div class="line"><span class="comment"># 验证是否登陆成功，抓取首页看看内容</span></div><div class="line">r = s.get(loginurl)</div><div class="line">res=check(r.content)<span class="comment">#0=不能签到;1=可以签到;-1=什么都没找到;</span></div><div class="line"><span class="keyword">if</span>(res==<span class="number">1</span>):<span class="comment">#可以签到</span></div><div class="line">    checkinUrl=<span class="string">"https://ssr.0v0.loan/user/checkin"</span></div><div class="line">    r=s.post(checkinUrl)</div><div class="line">    r = s.get(loginurl)</div><div class="line">lastFlows=match_flows(r.content)</div><div class="line">nowtime=time.strftime(<span class="string">'%Y-%m-%d'</span>,time.localtime(time.time()))<span class="comment">#获取当前时间</span></div><div class="line">str= nowtime+<span class="string">',\t总流量：'</span>+lastFlows[<span class="number">0</span>]+<span class="string">',\t已用流量：'</span>+lastFlows[<span class="number">1</span>]+<span class="string">',\t剩余流量：'</span>+lastFlows[<span class="number">2</span>]</div><div class="line"><span class="keyword">print</span> str</div><div class="line">logging.info(str)</div></pre></td></tr></table></figure>
</code></pre><h1 id="参考文献">11. 参考文献</h1><ol>
<li><a href="http://geek.csdn.net/news/detail/189850" target="_blank" rel="external">微信群分享：用Python模拟知乎自动登录</a></li>
<li><a href="http://www.runoob.com/python/python-reg-expressions.html" target="_blank" rel="external">Python正则表达式</a></li>
<li><a href="http://blog.csdn.net/eastmount/article/details/51082253" target="_blank" rel="external">常用正则表达式爬取网页信息及分析HTML标签总结</a></li>
<li><a href="http://www.cnblogs.com/thingk/p/4309122.html" target="_blank" rel="external">操作系统定期定时执行PYTHON脚本</a></li>
</ol>
<p>签到成功后：</p>
]]></content>
      
        <categories>
            
            <category> Python </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[《Improving Regressors Using Boosting Techniques》论文笔记]]></title>
      <url>/2017/04/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%BF%9B%E9%98%B6-%E3%80%8AImproving-Regressors-Using-Boosting-Techniques%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<h1 id="introduction部分">1. introduction部分</h1><p><strong>Bagging和boosting用途</strong></p>
<p>Bagging和boosting主要是用多重预测来解决以下两个问题：</p>
<ol>
<li>在回归问题中获取最小误差；</li>
<li>在分类问题中获取最小错误率。</li>
</ol>
<p><strong>Bagging和Boosting共性</strong><br>都是通过训练不同的数据集来得到回归模型。</p>
<p><strong>不同点</strong></p>
<p><strong>bagging</strong></p>
<ol>
<li>从$N_1$个原始样本中，有放回地抽样(可能overlap)得到$N_1$个样本</li>
<li>独立训练模型</li>
<li>得到不同的预测</li>
<li>求所有预测的平均得到最终结果</li>
</ol>
<p>由于模型之间独立，因此可以对训练过程采取分布式或并行的方式。</p>
<p><strong>boosting</strong></p>
<p>模型是依次训练出来的。</p>
<ol>
<li>从训练集中挑出$N_1$个样本，训练出第一个模型</li>
<li>挑出误差最大的样本</li>
<li>增大这些样本在下次被抽到的概率</li>
<li>再次进行训练，最终得到多个模型</li>
<li>最终对模型进行不同权重的加权，权重公式如下定义：</li>
</ol>
<p>设已知训练集$(y_i,x_i),i=1,…,N_1$。其中，$x$是$M$维的向量，且$(y_i,x_i)$唯一但未知(fixed but unknown)<br>我们将预测函数表示为$y^{(p)}(x)$，则：</p>
<p><strong>sample modeling error</strong>:<br> $$PE=\frac{1}{N_2}\sum_{i=1}^{N_2}[y_i-y_i^{(p)}(x_i)]^2$$<br><strong>prediction error</strong>:<br> $$ME=\frac{1}{N_2}\sum_{i=1}^{N_2}[y_i^{(t)}-y_i^{(p)}(x_i)]^2$$</p>
<p>其中，<br>$y_i^{(p)}(x_i)$表示第$i$个测试集的预测值<br>$y_i$表示第$i$个测试集的观测值<br>$y^{(t)}_i$是实际值<br>$y^{(p)}(x)$的参数p是从$N_2$个测试集的观测值中获得的，但是上面的累加的式子中的$y_i$和$x_i$是从从未被seen过的测试集的观测值$N_2$获得的。</p>
<ol>
<li><p>看到这里突然发现有点跑偏了。决定先暂停这篇论文的研究。</p>
</li>
</ol>
]]></content>
      
        <categories>
            
            <category> 机器学习进阶 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Boosting </tag>
            
            <tag> Bagging </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[2017腾讯题——字符十六进制输出]]></title>
      <url>/2017/04/03/ACM-2017%E8%85%BE%E8%AE%AF%E9%A2%98%E2%80%94%E2%80%94%E5%AD%97%E7%AC%A6%E5%8D%81%E5%85%AD%E8%BF%9B%E5%88%B6%E8%BE%93%E5%87%BA/</url>
      <content type="html"><![CDATA[<h1 id="题目">1. 题目</h1><p>编写代码，接收从屏幕输入的长度为16字节整数倍的字符串。回车后，按实例格式排版输出。</p>
<p>实例：</p>
<p>屏幕输入（均为可见字符）：<br>abcdefghigklmnopqrstuvwxyzabcdefghigklmnopqrstuvwxyzabcdefghigkl</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-04-03-21-24-41.png" alt=""> </p>
<h1 id="代码">2. 代码</h1><pre><code>#include &lt;iostream&gt;
#include&lt;cstring&gt;
#include&lt;cstdio&gt;
using namespace std;
int main()
{
    //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin);
    char c[16];
    int count=0;
    int level=0;
    int temp=0;
    char in;
    while(true){
        c[count]=getchar();
        if(c[count]==-1){
            break;
        }
        if(count==16){
            printf(&quot;%08d&quot;,level*10);
            printf(&quot;  &quot;);
            for(int i=0;i&lt;16;i++){
                if(i==8){
                    printf(&quot; &quot;);
                }
                temp=c[i]+16*level;
                printf(&quot;%02X&quot;,c[i]);
                printf(&quot; &quot;);
            }
            printf(&quot; &quot;);
            for(int i=0;i&lt;16;i++){
                std::cout&lt;&lt;c[i];
            }
            printf(&quot;\n&quot;);
            ++level;
            count=0;
        }
        ++count;
    }
    return 0;
}
</code></pre>]]></content>
      
        <categories>
            
            <category> ACM </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[BUPT_ACM_2017_F_Simple_recursion]]></title>
      <url>/2017/04/03/ACM-BUPT-2017-F-Simple-recursion/</url>
      <content type="html"><![CDATA[<p>本文是2017年北京邮电大学第十一届程序设计竞赛网络热身赛的F. Simple recursion题解。</p>
<h1 id="题目">1. 题目</h1><p>题目描述<br>r_clover shows you a BIIIIIIIIIIG water problem:<br>if $f(0)=1,f(1)=1$,$f(n)=2f(n-1)+3f(n-2)$, what is $f(n)mod1000000007$?</p>
<p>输入格式<br>A single integer n(0≤n≤10000000000).</p>
<p>输出格式<br>A single integer, which is the answer for f(n)mod1000000007.</p>
<p>输入样例<br>10<br>输出样例<br>29525</p>
<h1 id="思路">2. 思路</h1><p>一开始想的是用递归。但经测试发现递归的时间、空间复杂度都太高，导致超时。</p>
<p>正确打开方式：求出递推关系，并用快速幂取模方法计算结果。</p>
<h1 id="递推关系求解">3. 递推关系求解</h1><p>《组合数学》内容————常系数线性齐次递推关系的求解。公式见后面的附1。<br>求解题目中所给的递推关系：<br>$$f(n)=2f(n-1)+3f(n-2)$$<br>$$f(0)=1,f(1)=1$$<br>它的特征方程为：<br>$$x^2-2x-3=0$$<br>解方程得：<br>$$x_1=3,x_2=-1$$<br>所以递推关系的通解为：<br>$$f(n)=c_13^n+c_2(-1)^n$$<br>代入初值$f(0)=1,f(1)=1$，得到：<br>$$f(0)=c_1+c_2=1$$<br>$$f(1)=3c_1-c_2=1$$<br>解得:$c_1=c_2=0.5$<br>因此该递推关系的解为$$f(n)=0.5(3)^n+0.5(-1)^n$$</p>
<p>代码实现：</p>
<pre><code><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">long</span> <span class="title">f</span><span class="params">(<span class="keyword">long</span> <span class="keyword">long</span> n,<span class="keyword">int</span> modNum)</span></span>&#123;</div><div class="line">    <span class="keyword">long</span> <span class="keyword">long</span> a=<span class="number">3</span>;</div><div class="line">    <span class="keyword">long</span> <span class="keyword">long</span> b=<span class="number">1</span>;</div><div class="line">    a= quick_algorithm(a,n,modNum);<span class="comment">//(a的n次方)mod(modNum),是快速求幂取模的方法，详细见后面的推导</span></div><div class="line">    <span class="keyword">if</span>(n%<span class="number">2</span>==<span class="number">1</span>)&#123;</div><div class="line">        b=<span class="number">-1</span>;</div><div class="line">    &#125;</div><div class="line">    a=<span class="number">0.5</span>*a+<span class="number">0.5</span>*b;</div><div class="line">    <span class="keyword">return</span> a;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><h1 id="常系数线性齐次递归关系的求解">4. 常系数线性齐次递归关系的求解</h1><p><strong>递推关系：</strong></p>
<p>$$f(n)=c_1f(n-1)+c_2f(n-2)+…+c_kf(n-k)$$</p>
<p><strong>递推关系的特征方程</strong>：</p>
<p>$$x^k-c_1x^{k-1}-c_2x^{k-2}-…-c_k=0$$</p>
<p><strong>递归关系的特征根：</strong></p>
<p>特征方程的k个根（可能重根）：$$q_1,q_2,…,q_k$$</p>
<p><strong>递归关系的特解：</strong></p>
<p>设q是非零复数，则$f(n)=q^n$是递推关系的解，当且仅当q是它的特征根。</p>
<p><strong>递归关系的通解：</strong></p>
<p>设$q_1,q_2,…,q_k$是递推关系的k个互不相等的特征根，则<br>$$f(n)=b_1q_1^n+b_2q_2^n+b_3q_3^n+…+b_kq_k^n$$是递推关系的通解。</p>
<h1 id="快速大数幂运算">5. 快速大数幂运算</h1><p>这是一种很神奇的方法。</p>
<p>首先引入一些基础知识。</p>
<p><strong>幂取模运算的一个性质</strong></p>
<p>$$(a\times b)mod(c)=(((a)mod(c))\times ((b) mod(c)))mod(c)$$</p>
<p><strong>大数幂运算</strong><br>核心思想：将大数的幂运算拆解成了相对应的乘法运算，利用上面的式子，始终将我们的运算的数据量控制在c的范围以下。</p>
<p>对于目标：<br>$$a^bmodc$$<br>我们将b表示为二进制：<br>$$b=b_0+b_12+b_22^2+…+b_n2^n$$<br>那么，<br>$$a^b=a^b_1\times a^{b_22^2} \times a^{b_32^3} \times … \times a^{b_n2^n}$$<br>其中$b_k$要么为0，要么为1<br>去掉所有的0后，我们得到<br>$$a^b=a^{b_k2^k} \times … \times a^{b_n2^n}$$<br>上式的模可以表示为：<br>$$a^b mod c =a^{b_k2^k} mod c\times … \times a^{b_n2^n}mod c$$<br>易发现：<br>$$A_k=a^{b_k2^k} mod c$$<br>$$…$$<br>$$A_n=a^{b_n2^n} mod c$$</p>
<p>即：$A(n)$是$A(n-1)$的平方倍！</p>
<p>实现：</p>
<pre><code><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">quick</span><span class="params">(<span class="keyword">int</span> a,<span class="keyword">int</span> b,<span class="keyword">int</span> c)</span></span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">int</span> ans=<span class="number">1</span>;   <span class="comment">//记录结果</span></div><div class="line">    a=a%c;   <span class="comment">//预处理，使得a处于c的数据范围之下</span></div><div class="line">    <span class="keyword">while</span>(b!=<span class="number">0</span>)</div><div class="line">    &#123;</div><div class="line">        <span class="keyword">if</span>(b&amp;<span class="number">1</span>) ans=(ans*a)%c;   <span class="comment">//如果b的二进制位不是0，那么我们的结果是要参与运算的</span></div><div class="line">        b&gt;&gt;=<span class="number">1</span>;    <span class="comment">//二进制的移位操作，相当于每次除以2，用二进制看，就是我们不断的遍历b的二进制位</span></div><div class="line">        a=(a*a)%c;   <span class="comment">//不断的加倍</span></div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> ans;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><h1 id="代码">6. 代码</h1><pre><code>#include &lt;iostream&gt;
#include&lt;cstdio&gt;
#include&lt;cmath&gt;
#include&lt;cstdlib&gt;
#include&lt;cstring&gt;
#include&lt;string&gt;
#include&lt;algorithm&gt;
#include &lt;math.h&gt;
using namespace std;
long quick_algorithm(long long a,long long n,int modNum){
    a=a%modNum ;
    long long ans=1 ;
    //这里我们不需要考虑b&lt;0，因为分数没有取模运算
    while(n!=0){
        if(n&amp;1)
            ans=(ans*a)%modNum ;
        n&gt;&gt;=1  ;
        a=(a*a)%modNum;
    }
    return ans;
}
long set2(long long n,int modNum){
    long long a=3;
    long long b=1;
    /*for(long long i=0;i&lt;n;i++){
        a=a*3;
        a=a%modNum;
    }*/
    a= quick_algorithm(a,n,modNum);
    if(n%2==1){
        b=-1;
    }
    //a=a;
    a=0.5*a+0.5*b;
    return a;
}

int main()
{
    int modNum=1000000007;
    long long input=999999999;
    scanf(&quot;%lld&quot;,&amp;input);
    if(input==0||input==1){
        printf(&quot;%lld\n&quot;,1);
    }else{
        long long out=set2(input,modNum);
        printf(&quot;%lld\n&quot;,out);
    }
    return 0;
}
</code></pre><h1 id="参考文献">7. 参考文献</h1><ol>
<li>《组合数学引论》</li>
</ol>
<p>附上本题的艰辛史。<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-04-03-13-55-57.png" alt=""> </p>
]]></content>
      
        <categories>
            
            <category> ACM </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 递推关系 </tag>
            
            <tag> 快速幂取模 </tag>
            
            <tag> 长整型 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[QR分解]]></title>
      <url>/2017/03/31/%E6%95%B0%E5%AD%A6-QR%E5%88%86%E8%A7%A3/</url>
      <content type="html"><![CDATA[<h1 id="QR分解">1. QR分解</h1><p><strong>引理</strong>：</p>
<ol>
<li>对于任意的$A\in C^{n\times n}$,若存在$n$阶正交矩阵$Q$和$n$阶上三角矩阵$R$，使得$A=QR$，则称$QR$为$A$的$QR$分解。</li>
<li>若$A\in C^{n\times n}$可逆，则存在正交矩阵$Q$和正对角元的上三角矩阵$R$，使得$A=QR$，且表示式唯一。</li>
</ol>
<p>备注：正交矩阵：$A^{-1}=A^T$<br><strong>QR分解定理</strong>：<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-31-12-06-04.png" alt=""><br>，则A有QR分解：<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-31-12-06-23.png" alt=""><br>Q是m<em>m的正交矩阵<br>R是n</em>n的有非负对角元的上三角阵</p>
<p>当m=n，且A非奇异时，上述分解唯一。</p>
<p><strong>计算QR分解的方法</strong><br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-31-22-28-42.png" alt=""> </p>
<p>备注：<br>计算A(j:m,j:n)=(I(m-j+1)-bvvT)A(j:m,j:n)时，<br>I(m-j+1)-bvvT可以表示为：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-04-01-21-24-25.png" alt=""> </p>
<p><strong>QR分解的存储方法</strong><br><img src="http://om1bxijvl.bkt.clouddn.com/2017-04-01-21-54-20.png" alt=""> </p>
<p><strong>用QR分解解线性方程组</strong><br>$Ax=b$<br>$QRx=b$<br>$Rx=Q^{-1}b$<br>$x=R^{-1}Q^{-1}b$<br>$x=R^{-1}Q^Tb$</p>
<h1 id="householder方法">2. householder方法</h1><p>利用Householder变换逐步将A化为上三角矩阵。</p>
<p>使用Gauss变换将矩阵化为上三角的理论依据————对于一个给定的向量x，可构造一个初等下三角阵L，使得$Lx=ae_1$，其中$e_1$是I的第一列，a是实数。（I是单位矩阵）</p>
<p>householder变换目的：<br>求一个初等正交矩阵，使其具有矩阵L的功能。</p>
<p>使得：<br>可以通过一系列初等正交变换来完成矩阵的上三角化任务。</p>
<p><strong>Householder变换</strong><br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-31-22-03-16.png" alt=""> </p>
<p>其中：<br>I是单位矩阵<br>w是实的单位列向量（单位正交矩阵），$ww^T=I$</p>
<p>HouseHolder变换可以将一个向量映射到一个超平面上。 </p>
<p><strong>Householder变换的性质</strong></p>
<ol>
<li>对称性。$H^T=H$</li>
<li>正交性。$H^TH=I$</li>
<li>对合性。$H^2=I$</li>
<li>反射性(householder变换的物理意义)：<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-31-22-09-23.png" alt=""><br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-31-22-10-12.png" alt=""> </li>
</ol>
<p><strong>Householder变换的用途</strong></p>
<p>它能如Gauss变换一样，可以通过适当选取单位向量w，把一个给定向量的若干指定的分量变为零。<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-31-22-12-23.png" alt=""><br>由以上定理可知，对于任意的x，都可以构造出Householder矩阵H，使得Hx的后n-1个分量为零。</p>
<p><strong>Householder变换方法</strong><br>计算某一行向量的houser变换：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-31-22-24-15.png" alt=""><br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-31-22-24-37.png" alt=""><br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-31-22-24-58.png" alt=""> </p>
]]></content>
      
        <categories>
            
            <category> 数学 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[求线代方程的解]]></title>
      <url>/2017/03/30/%E6%95%B0%E5%AD%A6-%E6%B1%82%E7%BA%BF%E4%BB%A3%E6%96%B9%E7%A8%8B%E7%9A%84%E8%A7%A3/</url>
      <content type="html"><![CDATA[<h1 id="LU分解条件">1. LU分解条件</h1><p>如果n阶方阵A的各阶顺序主子式<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-29-19-34-31.png" alt=""> ，即A的各阶顺序主子矩阵Ak都可逆，则存在唯一的单位下三角矩阵L与唯一的非奇异上三角矩阵U，使得A=LU</p>
<p>其中k阶顺序主子式指<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-29-19-36-08.png" alt=""> </p>
<h1 id="LU分解方法">2. LU分解方法</h1><p>由于L存在可逆矩阵L’，即LL’=E<br>则L’A=LL’U=U<br>因此得出一般的分解方法：<br>通过对(A,E)做初等行变换得到(U,L’),再由L’得到L.</p>
<p>其中：</p>
<ol>
<li>L是单位下三角矩阵（对角线上的系数都为1的下三角矩阵）；L’也是单位上三角矩阵；</li>
<li>U是非奇异上三角矩阵；</li>
</ol>
<h1 id="求解方法">3. 求解方法</h1><p>对于一般的线性方程组：<br>$$Ax=b$$<br>如果我们能将A分解成$A=LU$,即一个下三角阵和一个上三角阵U的乘积，那原方程组的解x便可由下面两步得到：</p>
<ol>
<li>用前代法解$Ly=b$的y；<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-30-16-20-29.png" alt=""> </li>
<li>用回代法解$Ux=y$的x.<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-30-16-31-08.png" alt=""> </li>
</ol>
<p>对于列主元消去法，求线性方程组$Ax=b$的计算过程可以按照以下步骤进行：</p>
<ol>
<li>求A的列主元LU分解$PA=LU$</li>
<li>解下三角形方程组$Ly=Pb$</li>
<li>解上三角形方程组$Ux=y$</li>
</ol>
<h1 id="实现">4. 实现</h1><p>前代法：<br>需要注意的是，回代法在计算的过程中需要考虑到主元位置序列，并同时对b进行调整。</p>
<pre><code>double * forwardSub(double *lu,int n,double *b,int *p){
    //double *y=new double[n];
    double temp;
      //按qivot对b行变换，与LU匹配
      for(int i=0; i&lt;n-1; i++)  
      {
            temp = b[p[i]];
            b[p[i]] = b[i];
            b[i]=temp;
      }
    for(int i=0; i&lt;n; i++)
            for(int j=0; j&lt;i; j++)
                b[i]=b[i]-lu[n*i+j]*b[j];
    b[n-1]=b[n-1];
    return b;
}
</code></pre><p>回代法：<br>由于U是上三角矩阵，所以要从x[n-1]开始计算。</p>
<pre><code>double * backSub(double *b,double *lu,int n){
     for(int i=n-1; i&gt;=0; i--)
      {
            for(int j=n-1; j&gt;i; j--)
                b[i]=b[i]-lu[n*i+j]*b[j];
            b[i]=b[i]/lu[n*i+i];
      }
    return b;
}
</code></pre><p>计算：</p>
<pre><code>bool guass(double *lu,int *p,double*b,int n){
    double * y = forwardSub(lu,n,b,p);
    double * x = backSub(y,lu,n);
    std::cout&lt;&lt;endl&lt;&lt;&quot;the sulution is ; &quot;&lt;&lt;endl;
    for(int i=0;i&lt;n;i++){
        std::cout&lt;&lt;x[i]&lt;&lt;&quot;\t&quot;;
    }
    std::cout&lt;&lt;endl;
}
</code></pre><p>输出：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-31-11-02-01.png" alt=""> </p>
<p>代码：</p>
<pre><code>#include &lt;iostream&gt;
#include&lt;cstdio&gt;
#include&lt;cstdlib&gt;
#include&lt;iomanip&gt;
#define LIM -100000000
using namespace std;
double *luReult;
void printmat(double *mat,int n,string s){
    std::cout&lt;&lt;endl&lt;&lt;endl&lt;&lt;s&lt;&lt;endl;
    for(int i=0;i&lt;n;i++){
        for(int j=0;j&lt;n;j++){
            printf(&quot;%.5f\t&quot;,mat[i*n+j]);
        }
        std::cout&lt;&lt;endl;
    }
}
void printarr(int *mat,int n,string s){
    std::cout&lt;&lt;endl&lt;&lt;endl&lt;&lt;s&lt;&lt;endl;
    for(int i=0;i&lt;n;i++){
        std::cout&lt;&lt;mat[i]&lt;&lt;&quot;\t&quot;;
        //printf(&quot;%s\t&quot;,mat[i]);
    }
}
int findMainNumber(double *a,int n,int r){
    float maxa=-99999;
    int maxaIdx=-1;
    //printmat(a,n,&quot;a is now :&quot;);
    for(int i=r;i&lt;n;i++){
        if(a[i*n+r]&gt;maxa){
            maxa=a[i*n+r];
            maxaIdx=i;
        }
    }
    return maxaIdx;
}
void exchange(double *a,int n,int e,int r){
    float temp=0;
    for(int i=0;i&lt;n;i++){
        temp = a[r*n+i];
        a[r*n+i]=a[e*n+i];
        a[e*n+i]=temp;
    }
}
bool lu(double* a, int* pivot, int n)//矩阵LU分解
{
      for(int k=0;k&lt;n;k++){
        //寻找第k列的主元
        int p = findMainNumber(a,n,k);
        exchange(a,n,p,k);//交换k行和p行
        pivot[k]=p;//记录置换矩阵p
        if(a[k*n+k]!=0){
                for(int i=k+1;i&lt;n;i++){//部分下三角L
                    a[i*n+k]=a[i*n+k]/a[k*n+k];
                }
                for(int i=k+1;i&lt;n;i++){//计算上三角U
                    for(int j=k+1;j&lt;n;j++){
                        a[i*n+j]=a[i*n+j]-a[i*n+k]*a[k*n+j];
                    }
                }
        }else{
            return true;//矩阵奇异
        }
      }
      /*
      //计算下三角L
      double temp=0;
       for(int i=0; i&lt;n-2; i++)//i行k列
            for(int k=i+1; k&lt;n-1;k++)
            {
                    temp=a[n*pivot[k] + i];
                    a[n*pivot[k] + i]=a[k*n + i];
                    a[k*n + i]=temp;
            }
        */
      luReult=a;
      printmat(a,n,&quot;lu&quot;);
      return false ;
}
double radio(int a,int b){
    return (double)(a)/(double)(b);
}
void buildHilbert(double *a,double *b,int n){
    for(int r=0;r&lt;n;r++){
        for(int j=0;j&lt;n;j++){
            a[r*n+j]=radio(1,j+r+1);
            b[r]=b[r]+a[r*n+j];
        }
    }
}
void exchangeb(double *b,int n,int r,int e){
    double temp=0;
    temp=b[e];
    b[e]=b[r];
    b[r]=temp;
    /*r(int i=0;i&lt;n;i++){
        temp=b[r*n+i];
        b[r*n+i]=b[e*n+i];
        b[e*n+i]=temp;
    }*/
}
double * forwardSub(double *lu,int n,double *b,int *p){
    //double *y=new double[n];
    double temp;
      //按qivot对b行变换，与LU匹配
      for(int i=0; i&lt;n-1; i++)
      {
            temp = b[p[i]];
            b[p[i]] = b[i];
            b[i]=temp;
      }
    for(int i=0; i&lt;n; i++)
            for(int j=0; j&lt;i; j++)
                b[i]=b[i]-lu[n*i+j]*b[j];
    b[n-1]=b[n-1];
    return b;
}

double * backSub(double *b,double *lu,int n){
     for(int i=n-1; i&gt;=0; i--)
      {
            for(int j=n-1; j&gt;i; j--)
                b[i]=b[i]-lu[n*i+j]*b[j];
            b[i]=b[i]/lu[n*i+i];
      }
    return b;
}

bool guass(double *lu,int *p,double*b,int n){
    double * y = forwardSub(lu,n,b,p);
    double * x = backSub(y,lu,n);
    std::cout&lt;&lt;endl&lt;&lt;&quot;the sulution is ; &quot;&lt;&lt;endl;
    for(int i=0;i&lt;n;i++){
        std::cout&lt;&lt;x[i]&lt;&lt;&quot;\t&quot;;
    }
    std::cout&lt;&lt;endl;
}
int main()
{
    int n=6;//矩阵是n*n的
    double *b=new double[n];
    double *a=new double[n*n];
    /*double input[n*n]={0.001,1.00,1.00,2.00};
    a=input;
    double inputb[n]={1.00,3.00};
    b=inputb;*/
    buildHilbert(a,b,n);
    printmat(a,n,&quot;a:&quot;);
    int *pivot=new int[n*n];
    luReult=new double[n*n];
    lu(a,pivot,n);
    printarr(pivot,n,&quot;p:&quot;);
     guass(luReult,pivot,b,n);
    //cout &lt;&lt; &quot;Hello world!&quot; &lt;&lt; endl;
    return 0;
}
</code></pre>]]></content>
      
        <categories>
            
            <category> 数学 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 矩阵分解 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[矩阵LU分解及其实现]]></title>
      <url>/2017/03/29/%E6%95%B0%E5%AD%A6-%E7%9F%A9%E9%98%B5LU%E5%88%86%E8%A7%A3/</url>
      <content type="html"><![CDATA[<p>LU分解:可以将一个矩阵分解为一个<strong>单位下三角矩阵</strong>和一个<strong>上三角矩阵</strong>的<strong>乘积</strong>（有时是它们和一个置换矩阵的乘积）。LU分解主要应用在数值分析中，用来解线性方程、求反矩阵或计算行列式。</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-29-19-31-33.png" alt=""> </p>
<h1 id="LU分解条件">1. LU分解条件</h1><p>如果n阶方阵A的各阶顺序主子式<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-29-19-34-31.png" alt=""> ，即A的各阶顺序主子矩阵Ak都可逆，则存在唯一的单位下三角矩阵L与唯一的非奇异上三角矩阵U，使得A=LU</p>
<p>其中k阶顺序主子式指<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-29-19-36-08.png" alt=""> </p>
<h1 id="LU分解方法">2. LU分解方法</h1><p>由于L存在可逆矩阵L’，即LL’=E<br>则L’A=LL’U=U<br>因此得出一般的分解方法：<br>通过对(A,E)做初等行变换得到(U,L’),再由L’得到L.</p>
<p>其中：</p>
<ol>
<li>L是单位下三角矩阵（对角线上的系数都为1的下三角矩阵）；L’也是单位上三角矩阵；</li>
<li>U是非奇异上三角矩阵；</li>
</ol>
<h1 id="直接消去法的矩阵解释">3. 直接消去法的矩阵解释</h1><p>计算过程如图所示：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-29-20-13-15.png" alt=""> </p>
<p><strong>目的</strong>：将[A|E]–&gt;[U|L]形式，其中U是上三角矩阵</p>
<p><strong>过程</strong>：每轮将一列的下三角消为0，就相当于给A左乘一个下三角单位矩阵Lk（对角线为1，保证变换后对角线元素不变）。</p>
<p><strong>第一轮消元</strong>：将第一列的下三角消为0，相当于对A1左乘矩阵L1，即：<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-29-20-54-39.png" alt=""><br>其中，<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-29-20-55-24.png" alt=""><br>我们注意到li1恰好使得第i行的第一列元素变为零，即ai1-li1*a11=0。</p>
<p><strong>第二轮消元</strong>：将第二列的下三角消为0，对应于<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-29-20-57-24.png" alt=""> </p>
<p><strong>第k轮消元</strong>:<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-29-20-57-48.png" alt=""><br>其中，<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-29-20-58-09.png" alt=""> </p>
<p>把k轮消元相乘，即：<br><strong>整个消元过程为</strong>：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-29-20-59-09.png" alt=""> </p>
<p><strong>总结</strong><br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-29-21-05-36.png" alt=""><br>初始（第一步）：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-29-21-00-46.png" alt=""> </p>
<p>迭代第r步：<br>即<br>ur=f(u1,u2,…,u(r-1),l1,l2,…,l(r-1)),第r项由前r-1项计算得到<br>lr=g(u1,u2,…,u(r-1),l1,l2,…,l(r-1))<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-29-21-02-44.png" alt=""> </p>
<p>计算顺序：</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-30-10-36-28.png" alt=""> </p>
<p>需要注意的是，我们在计算时需要判断本阶的顺序主子式是否为零。</p>
<p><strong>代码实现</strong><br>备注：其中的piovt暂时没有卵用。</p>
<p>输入矩阵：<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-30-14-16-46.png" alt=""> </p>
<pre><code>bool lu(double *a,int *pivot,int n){//矩阵是n*n的
double test = det(a,r,n);//检验本阶顺序主子式是否为0
 if(test==0){
    return true;
 }
//数组a在内存中按行优先次序存放
//pivot:输出参数
//pivot[0,n)中存放主元的位置排列
//成功时返回false，否则返回ture
//int len = sizeof(a)/sizeof(a[0]);
double *U,*L;
U = new double[n*n];
L = new double[n*n];
set0(U,n);
set0(L,n);
//先算urj(固定r，计算完所有的urj)，再算ljr(固定i，计算完所有的ljr)
for(int r=0;r&lt;n;r++){
    //计算urj(固定r，计算完所有的urj)
    //计算ljr(固定i，计算完所有的ljr)
    for(int j=r;j&lt;n;j++){
        double sum_lu1=0;
        double sum_lu2=0;
        for(int k=0;k&lt;r;k++){
            sum_lu1 = sum_lu1+L[r*n+k]*U[k*n+j];
            sum_lu2 = sum_lu2+L[j*n+k]*U[k*n+r];
        }
        U[r*n+j]=a[r*n+j]-sum_lu1;
        if(j==r){
            L[j*n+r]=1;
        }else{
            L[j*n+r]=a[j*n+r]-sum_lu2;
            L[j*n+r]=L[j*n+r]/U[r*n+r];
        }
    }
}
return false;
}
</code></pre><p>结果：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-30-14-22-05.png" alt=""> </p>
<p>不知道为什么，我的答案与网上的之前学长做过的这道题的答案统统不一样。仔细检查后还是查不出来。又用Matlab验证了一下LU分解，MATLAB跑的结果为：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-30-14-39-25.png" alt=""><br>与我自己的L矩阵一致。决定还是相信自己。</p>
<h1 id="列主元高斯消去法">4. 列主元高斯消去法</h1><p>主要思想是在每次计算第r行时，选取当前第r列下的最大的a[i,r]的所在的第i行作为主元，即将第i行与第r行交换，再进行计算。</p>
<p>主要理论见参考文献-北邮理学院数值分析课件chapter5.</p>
<p>代码：</p>
<pre><code>#include &lt;iostream&gt;
#include&lt;cstdio&gt;
#include&lt;cstdlib&gt;
#include&lt;iomanip&gt;
#define LIM -100000000
using namespace std;
double *luReult;
void printmat(double *mat,int n,string s){
    std::cout&lt;&lt;endl&lt;&lt;endl&lt;&lt;s&lt;&lt;endl;
    for(int i=0;i&lt;n;i++){
        for(int j=0;j&lt;n;j++){
            printf(&quot;%.5f\t&quot;,mat[i*n+j]);
        }
        std::cout&lt;&lt;endl;
    }
}
void printarr(int *mat,int n,string s){
    std::cout&lt;&lt;endl&lt;&lt;endl&lt;&lt;s&lt;&lt;endl;
    for(int i=0;i&lt;n;i++){
        std::cout&lt;&lt;mat[i]&lt;&lt;&quot;\t&quot;;
        //printf(&quot;%s\t&quot;,mat[i]);
    }
}
int findMainNumber(double *a,int n,int r){
    float maxa=-99999;
    int maxaIdx=-1;
    //printmat(a,n,&quot;a is now :&quot;);
    for(int i=r;i&lt;n;i++){
        if(a[i*n+r]&gt;maxa){
            maxa=a[i*n+r];
            maxaIdx=i;
        }
    }
    return maxaIdx;
}
void exchange(double *a,int n,int e,int r){
    float temp=0;
    for(int i=0;i&lt;n;i++){
        temp = a[r*n+i];
        a[r*n+i]=a[e*n+i];
        a[e*n+i]=temp;
    }
}
bool lu(double* a, int* pivot, int n)//矩阵LU分解
{
      for(int k=0;k&lt;n;k++){
        //寻找第k列的主元
        int p = findMainNumber(a,n,k);
        exchange(a,n,p,k);//交换k行和p行
        pivot[k]=p;//记录置换矩阵p
        if(a[k*n+k]!=0){
                for(int i=k+1;i&lt;n;i++){//部分下三角L
                    a[i*n+k]=a[i*n+k]/a[k*n+k];
                }
                for(int i=k+1;i&lt;n;i++){//计算上三角U
                    for(int j=k+1;j&lt;n;j++){
                        a[i*n+j]=a[i*n+j]-a[i*n+k]*a[k*n+j];
                    }
                }
        }else{
            return true;//矩阵奇异
        }
      }
      /*
      //计算下三角L
      double temp=0;
       for(int i=0; i&lt;n-2; i++)//i行k列
            for(int k=i+1; k&lt;n-1;k++)
            {
                    temp=a[n*pivot[k] + i];
                    a[n*pivot[k] + i]=a[k*n + i];
                    a[k*n + i]=temp;
            }
        */
      luReult=a;
      printmat(a,n,&quot;lu&quot;);
      return false ;
}
double radio(int a,int b){
    return (double)(a)/(double)(b);
}
void buildHilbert(double *a,double *b,int n){
    for(int r=0;r&lt;n;r++){
        for(int j=0;j&lt;n;j++){
            a[r*n+j]=radio(1,j+r+1);
            b[r]=b[r]+a[r*n+j];
        }
    }
}
void exchangeb(double *b,int n,int r,int e){
    double temp=0;
    temp=b[e];
    b[e]=b[r];
    b[r]=temp;
    /*r(int i=0;i&lt;n;i++){
        temp=b[r*n+i];
        b[r*n+i]=b[e*n+i];
        b[e*n+i]=temp;
    }*/
}

int main()
{
    int n=6;//矩阵是n*n的
    double *b=new double[n];
    double *a=new double[n*n];
    /*double input[n*n]={0.001,1.00,1.00,2.00};
    a=input;
    double inputb[n]={1.00,3.00};
    b=inputb;*/
    buildHilbert(a,b,n);
    printmat(a,n,&quot;a:&quot;);
    int *pivot=new int[n*n];
    luReult=new double[n*n];
    lu(a,pivot,n);
    printarr(pivot,n,&quot;p:&quot;);
    //cout &lt;&lt; &quot;Hello world!&quot; &lt;&lt; endl;
    return 0;
}
</code></pre><p>输出：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-31-11-02-01.png" alt=""> </p>
<h1 id="参考文献">5. 参考文献</h1><ol>
<li><a href="https://ccjou.wordpress.com/2010/09/01/lu-%E5%88%86%E8%A7%A3/" target="_blank" rel="external">LU 分解</a></li>
<li><a href="http://blog.csdn.net/u010945683/article/details/45803141" target="_blank" rel="external">矩阵分析——LU分解</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 数学 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 矩阵分解 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[最大流]]></title>
      <url>/2017/03/28/%E7%AE%97%E6%B3%95-%E6%9C%80%E5%A4%A7%E6%B5%81/</url>
      <content type="html"><![CDATA[<p>最大流问题：给定流网络、源节点、汇点，找到值最大的一个流。</p>
<h1 id="Ford-Fullkerson方法">1. Ford-Fullkerson方法</h1><p><strong>主要思想</strong>：循环增加流的值。</p>
<h2 id="几个概念">1.1. 几个概念</h2><h3 id="残存网络-G-f">1.1.1. 残存网络$G_f$</h3><p>残存网络简单定义：</p>
<pre><code>残存网络=网络容量Capacity-流量网络flow
</code></pre><p>残存网络形式化定义：</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-28-19-36-03.png" alt=""> </p>
<p>说明：<br>第一项很好理解，就是=网络容量Capacity-流量网络flow</p>
]]></content>
      
        <categories>
            
            <category> 算法 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[ACM-poj1789-TruckHistory]]></title>
      <url>/2017/03/27/ACM-poj1789-TruckHistory/</url>
      <content type="html"><![CDATA[<h1 id="Description">1. Description</h1><p>Advanced Cargo Movement, Ltd. uses trucks of different types. Some trucks are used for vegetable delivery, other for furniture, or for bricks. The company has its own code describing each type of a truck. The code is simply a string of exactly seven lowercase letters (each letter on each position has a very special meaning but that is unimportant for this task). At the beginning of company’s history, just a single truck type was used but later other types were derived from it, then from the new types another types were derived, and so on. </p>
<p>Movement:运动<br>trucks：卡车<br>exactly seven lowercase letters ：正好七个小写字母<br>derived：派生</p>
<p>Today, ACM is rich enough to pay historians to study its history. One thing historians tried to find out is so called derivation plan – i.e. how the truck types were derived. They defined the distance of truck types as the number of positions with different letters in truck type codes. They also assumed that each truck type was derived from exactly one other truck type (except for the first truck type which was not derived from any other type). The quality of a derivation plan was then defined as<br><code>1/Σ(to,td)d(to,td)</code></p>
<p>quality：质量</p>
<p>where the sum goes over all pairs of types in the derivation plan such that to is the original type and td the type derived from it and d(to,td) is the distance of the types.<br>Since historians failed, you are to write a program to help them. Given the codes of truck types, your program should find the highest possible quality of a derivation plan. </p>
<h1 id="Input">2. Input</h1><p>The input consists of several test cases. Each test case begins with a line containing the number of truck types, N, 2 &lt;= N &lt;= 2 000. Each of the following N lines of input contains one truck type code (a string of seven lowercase letters). You may assume that the codes uniquely describe the trucks, i.e., no two of these N lines are the same. The input is terminated with zero at the place of number of truck types.</p>
<h1 id="Output">3. Output</h1><p>For each test case, your program should output the text “The highest possible quality is 1/Q.”, where 1/Q is the quality of the best derivation plan.<br>Sample Input</p>
<p>4<br>aaaaaaa<br>baaaaaa<br>abaaaaa<br>aabaaaa<br>0</p>
<h1 id="Sample-Output">4. Sample Output</h1><p>The highest possible quality is 1/3.</p>
<h1 id="解决方案">5. 解决方案</h1><p>t:表示卡车的七个字母的字符串<br>d(t0,td)=t0和td两卡车的字符串不相同的个数</p>
<p>每个卡车都是由另一个卡车派生而来。<br>现在给出n种不同型号的truck，问怎样使quality的值最小————即找到一条连接所有truck的最短路径</p>
]]></content>
      
        <categories>
            
            <category> ACM </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[最小生成树算法]]></title>
      <url>/2017/03/26/%E7%AE%97%E6%B3%95-%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%E7%AE%97%E6%B3%95/</url>
      <content type="html"><![CDATA[<p>带权图分为有向和无向，无向图的最短路径又叫做最小生成树，有prime算法和kruskal算法；有向图的最短路径算法有dijkstra算法和floyd算法。</p>
<p>最小生成树问题：给定一个连通无向图，寻找一颗无环树，使得树上所有边权值之和最小。</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-26-20-15-02.png" alt=""> </p>
<h1 id="最小生成树的贪心策略的通用方法">1. 最小生成树的贪心策略的通用方法</h1><h2 id="问题描述">1.1. 问题描述</h2><p><strong>已知</strong>：连通无向图$G=(V,E)$，权重函数$w:E \rightarrow R$<br><strong>循环不变式</strong>：在每边循环之前，A是某颗最小生成树的一个子集。<br><strong>伪代码</strong></p>
<pre><code>GENERIC-MST(G,w)
A={}
while A does not form a spanning tree // 当A不是一个生成树时
    find an edge(u,v) that is safe for A // 找到一条A的安全边
    A = A ∪ {(u,v)}
return A
</code></pre><p>注：安全边是指加入A后，不会使得A违反循环不变式。即 A ∪ {(u,v)}也是某颗最小生成树的一个子集</p>
<p><strong>问题</strong>：如何寻找安全边</p>
<h2 id="求安全边">1.2. 求安全边</h2><p><strong>定理</strong>：设A是图G的某最小生成树的一个子集。设（S,V-S）是图G中尊重集合A的任意一个切割，又设(u,v)是横跨切割(S,V-S)的一条轻量级边，则边(u,v)对于集合A是安全的。</p>
<p><strong>切割</strong>：图中的线<br><strong>切割尊重集合A</strong>：集合A中不存在横跨切割的边（如图a中的灰粗线构成的集合）<br><strong>轻量级边</strong>：横跨一个切割的所有边中权重最小的边（不唯一）。</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-26-21-11-54.png" alt=""> </p>
<h1 id="Kruskal和Prim关系">2. Kruskal和Prim关系</h1><table>
<thead>
<tr>
<th>term</th>
<th style="text-align:right">集合A</th>
<th style="text-align:center">说明</th>
<th style="text-align:center">共性</th>
</tr>
</thead>
<tbody>
<tr>
<td>Kruskal</td>
<td style="text-align:right">森林</td>
<td style="text-align:center">结点是原图结点，安全边是权重最小的连接两个不同分量的边</td>
<td style="text-align:center">都是用具体的规则来确定安全边的方法</td>
</tr>
<tr>
<td>Prim</td>
<td style="text-align:right">树</td>
<td style="text-align:center">安全边是连接A和A之外某个节点的边中权重最小的边</td>
</tr>
</tbody>
</table>
<h1 id="Kruskal算法">3. Kruskal算法</h1><p><strong>寻找安全边</strong>:在所有连接两个不同树的边里，找到权重最小的边(u,v)</p>
<h2 id="伪代码">3.1. 伪代码</h2><pre><code>MST-KRUSKAL(G,w)
A={}//A是森林
for each vertex v∈G.V
    MAKE-SET(v)//将集合A初始化为空集，并创建M颗子树，每棵树各含一个结点
sort the edges of G.E into nondecreasing order by weight w //对边按照权重排序
for each edge(u,v)∈G.E,taken in nondecreasing order by weight//按权重顺序遍历边
    if FIND-SET(v)!=FIND-SET(u)//(u,v)不在一棵树
        A= A ∪ {(u,v)}
        UNION(u,v)
return A
</code></pre><h2 id="时间复杂度">3.2. 时间复杂度</h2><p>$O(ElgV)$</p>
<h2 id="特点">3.3. 特点</h2><p>图的存贮结构采用边集数组,且权值相等的边在数组中排列次序可以是任意的.该方法对于边相对比较多的不是很实用,浪费时间.</p>
<p>c++实现（写的很好，一定要看）:<a href="http://blog.csdn.net/niushuai666/article/details/6689285" target="_blank" rel="external">Kruskal算法</a></p>
<h1 id="Prim算法">4. Prim算法</h1><p><strong>寻找安全边</strong>:A总是一颗树。从单一顶点开始，逐步扩大树中所含顶点的数目，直到遍及连通图的所有顶点。</p>
<p>为了快速选择新边， 在算法执行的过程中，所有不在树A中的结点都存放在一个基于key属性的<code>最小优先队列Q</code>中。</p>
<p><code>u.key</code> : 连接结点u和<strong>树</strong>中结点的所有边中最小边的权重。<br><code>u.π</code>：u在<strong>树</strong>中的父节点</p>
<h2 id="描述">4.1. 描述</h2><p><strong>输入</strong>:连通图G,边权w,最小生成树的根节点r</p>
<p><strong>初始化</strong>：Vnew = {x}，其中x为集合V中的任一节点（起始点），Enew = {}</p>
<p><strong>循环</strong>：重复以下操作，直到$V_{new}=V$：</p>
<ol>
<li>在集合E中选取权值最小的边（u,v），其中u是集合Vnew中的元素，而v则是V中没有加入Vnew的顶点；</li>
<li>将v加入Vnew中，将(u,v)加入Enew中；</li>
</ol>
<p><strong>输出</strong>：使用集合Vnew和Enew来描述所得到的最小生成树。</p>
<p>图例：</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-27-15-47-24.png" alt=""> </p>
<h2 id="伪代码-1">4.2. 伪代码</h2><pre><code>MST-PRIM(G,w,r)//r是最小生成树的根节点
for each u∈G.V
    u.key=∞ 
    u.π=NIL //u在树中的父节点
r.key=0
Q=G.V
while Q!={}
    u=EXTRACT-MIN(Q)//某条横跨切割(V-Q,Q)的一个轻量级边的端点
    for each v∈G.Adj[u]//遍历u的邻接表
    if v∈Q and w(u,v)&lt;v.key
        v.π=u
        v.key=w(u,v)
</code></pre><h2 id="时间复杂度-1">4.3. 时间复杂度</h2><p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-27-15-51-25.png" alt=""> </p>
<p>通过邻接矩阵图表示的简易实现中，找到所有最小权边共需O（V2）的运行时间。使用简单的二叉堆与邻接表来表示的话，普里姆算法的运行时间则可缩减为O(E log V)，其中E为连通图的边数，V为顶点数。如果使用较为复杂的斐波那契堆，则可将运行时间进一步缩短为O(E + V log V)，这在连通图足够密集时（当E满足Ω（V log V）条件时），可较显著地提高运行速度</p>
<h1 id="参考文献">5. 参考文献</h1><ol>
<li><a href="https://zh.wikipedia.org/wiki/%E6%99%AE%E6%9E%97%E5%A7%86%E7%AE%97%E6%B3%95" target="_blank" rel="external">维基百科</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 算法 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[ACM-poj1860-CurrencyExchange]]></title>
      <url>/2017/03/23/ACM-poj1860-CurrencyExchange/</url>
      <content type="html"><![CDATA[<h1 id="Description">1. Description</h1><p>Several currency exchange points are working in our city. Let us suppose that each point specializes in two particular currencies and performs exchange operations only with these currencies. There can be several points specializing in the same pair of currencies. Each point has its own exchange rates, exchange rate of A to B is the quantity of B you get for 1A. Also each exchange point has some commission, the sum you have to pay for your exchange operation. Commission is always collected in source currency.<br>For example, if you want to exchange 100 US Dollars into Russian Rubles at the exchange point, where the exchange rate is 29.75, and the commission is 0.39 you will get (100 - 0.39) * 29.75 = 2963.3975RUR.<br>You surely know that there are N different currencies you can deal with in our city. Let us assign unique integer number from 1 to N to each currency. Then each exchange point can be described with 6 numbers: integer A and B - numbers of currencies it exchanges, and real RAB, CAB, RBA and CBA - exchange rates and commissions when exchanging A to B and B to A respectively.<br>Nick has some money in currency S and wonders if he can somehow, after some exchange operations, increase his capital. Of course, he wants to have his money in currency S in the end. Help him to answer this difficult question. Nick must always have non-negative sum of money while making his operations. </p>
<p> currency exchange points：货币兑换点<br> commission：佣金<br> assign ：分配</p>
<p>每个货币兑换点只能互换两种货币。兑换点可重复。每个点都有自己的兑换率，A to B 的兑换率是指1个A能兑换的B的数量。</p>
<p>兑换时收取一定的佣金，佣金是以来源货币来collect的。例如，如果你想将100dolars兑换成Russian Bules,  兑换点的兑换率是29.75，费用是0.39，，那么你会得到的钱是 (100 - 0.39) * 29.75 = 2963.3975RUR. </p>
<p>假设每种兑换的点数量是1-N，那么每个兑换点可以由6个num来描述：</p>
<p>interger A and B  兑换货币的序号<br>RAB A to B兑换率<br>CAB A to B 的佣金<br>RBA B to A 兑换率<br>CBA B to A 的佣金</p>
<p>Nick有些S货币，他很好奇他能否通过货币兑换的方式对他的资金进行增值。最终他希望他拿到还是S货币。帮他解决这个问题。Nick在这个过程中不能借钱。</p>
<h1 id="Input">2. Input</h1><p>The first line of the input contains four numbers: N - the number of currencies, M - the number of exchange points, S - the number of currency Nick has and V - the quantity of currency units he has. </p>
<p>The following M lines contain 6 numbers each - the description of the corresponding exchange point - in specified above order. Numbers are separated by one or more spaces. </p>
<p>1&lt;=S&lt;=N&lt;=100, 1&lt;=M&lt;=100, V is real number, 0&lt;=V&lt;=103. </p>
<p>For each point exchange rates and commissions are real, given with at most two digits after the decimal point, 10-2&lt;=rate&lt;=102, 0&lt;=commission&lt;=102. </p>
<p>Let us call some sequence of the exchange operations simple if no exchange point is used more than once in this sequence. You may assume that ratio of the numeric values of the sums at the end and at the beginning of any simple sequence of the exchange operations will be less than 104. </p>
<p>corresponding：相应的</p>
<p>第一行包含四个数字：<br>N 货币的种类<br>M 兑换点的数量<br>S Nick的货币的序号<br>V Nick拥有的钱</p>
<p>接下来的M行，每行包含六个数字，描述相应的兑换点的属性。<br>数字由一个或多个空格隔开</p>
<p>1&lt;=S&lt;=N&lt;=100, 1&lt;=M&lt;=100, V is real number, 0&lt;=V&lt;=103. </p>
<p>每个兑换点的兑换率和手续费都是实数，至多精确到两位小数。</p>
<p> 10-2&lt;=rate&lt;=102, 0&lt;=commission&lt;=102</p>
<p>如果在操作序列中不适用多个兑换点，我们可以发起一些简单的兑换操作。你可以假设：（最后的总和/）</p>
<h1 id="输出数据">3. 输出数据</h1><p>如果nick能够实现他的愿望，则输出YES，否则输出NO。</p>
<h1 id="样例输入">4. 样例输入</h1><p>3 2 1 20.0<br>1 2 1.00 1.00 1.00 1.00<br>2 3 1.10 1.00 1.10 1.00</p>
<h1 id="思路">5. 思路</h1><p>将货币看做点，每种兑换规则为边，两点的路径长度为兑换后的钱数。建图之后可以看出题意为求图中是否存在正环，用Bellman-Ford求最长路径，如果存在正环输出YES，不存在输出NO。</p>
]]></content>
      
        <categories>
            
            <category> ACM </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[单源最短路径问题]]></title>
      <url>/2017/03/23/%E7%AE%97%E6%B3%95-%E5%8D%95%E6%BA%90%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98/</url>
      <content type="html"><![CDATA[<p>单源最短路径问题：给定一个图 $G=(V,E)$ ，我们希望找到从给定源节点$s\in V$到每个节点$v \in V$的最短路径。</p>
<p>先总结：</p>
<p>Bellman-Ford算法：采用动态规划进行设计。<strong>待总结</strong>。简单，还能侦探含源节点的负权重回路。<br>Dijkstra算法：采用贪心算法范式进行设计。复杂度低，但要求权重非负。</p>
<h1 id="最短路径树">1. 最短路径树</h1><p>一颗根节点为s的最短路径树是一个有向子图$G’=(V’,E’)$，这里$V’\in V$,$E’\in E$,满足：</p>
<ol>
<li>$V’$是图G中从源节点s可以到达的所有结点的集合；</li>
<li>$G’$形成一颗根节点为s的树；</li>
<li>对于所有结点$v\in V’$,图$G’$中从结点s到结点v的唯一简单路径是图G中从结点s到结点v的一条最短路径。</li>
</ol>
<h1 id="松弛操作">2. 松弛操作</h1><p>对每个节点v，我们维持一个属性v.d，记录s→v的最短路径估计</p>
<p>松弛操作：比较s→u→v与s→v的d,然后进行更新。</p>
<pre><code>RELEAX(u,v,w)
    if v.d&gt;u.d+w(u,v)
        v.d=u.d+w(u,v)
        v.π=u
</code></pre><h1 id="Bellman-Ford算法">3. Bellman-Ford算法</h1><p><strong>目标</strong>：解决单源最短路径问题<br><strong>条件</strong>：边权重可负<br><strong>输入</strong>：带权有向图$G=(V,E)$和权重函数$w:E→R$<br><strong>输出</strong>：布尔值，是否存在一个从源节点可以到达的负权重回路。若存在，则算法无解。</p>
<p><strong>思路</strong>：Bellman-Ford通过对边进行松弛操作来渐进地降低从源节点s到每个节点v的最短路径估计值v.d，直到该估计值与实际的最短路径权重$δ(s,v)$相同为止。</p>
<p>初始函数：</p>
<pre><code>INITIALIZE-SINGLE-SOURCE(G,s)
    for eahc vertex v∈G.V
        v.d=∞
        v.π=null
    s.d=0
</code></pre><p><strong>算法</strong>：</p>
<pre><code>BELLMAN-FORD(G,w,s)
    INITIALIZE-SINGLE-SOURCE(G,s)//对每个点v.d和v.π初始化
    for i=1 to |G.V|-1 //对每个边处理V-1次
        for each edge(u,v)∈G.E //遍历所有的边
            RELAX(u,v,w)
    for each edge(u,v)∈G.E
        if v.d&gt;u.d+w(u,v)
            return False
        else
            return True
</code></pre><p><strong>复杂度</strong>：$O(VE)$</p>
<p><strong>对每个边处理V-1的原因</strong>：设p是从s到v的最短路径，则p最多包含V-1条边。</p>
<p>如下图所示的极限条件，v0-v5路径应该为<code>&lt;v0,v1,v2,v3,v4,v5&gt;</code></p>
<p>原本v0-v5的路径是灰色的。<br>第一轮松弛后，v0-v5路径变为<code>&lt;v0,v1,v5&gt;</code>，即黑色的<br>同理，第二轮松弛后，v0-v5路径变为<code>&lt;v0,v1,v2,v5&gt;</code><br>因此要松弛V-1次才可以<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-23-17-07-49.png" alt=""> </p>
<h1 id="Dijkstra算法">4. Dijkstra算法</h1><p><strong>条件</strong>：所有边的权重非负<br><strong>思想</strong>：由上述性质可知，如果存在一条从i到j的最短路径(Vi…..Vk,Vj)，Vk是Vj前面的一顶点。那么(Vi…Vk)也必定是从i到k的最短路径。为了求出最短路径，Dijkstra就提出了以最短路径长度递增，逐次生成最短路径的算法。即：每次找到离源点最近的一个顶点，然后以该顶点为中心进行扩展，最终得到源点到其余所有点的最短路径。</p>
<p><strong>Dijkstra算法的关键</strong>：维持一组节点集合S，从s到该集合中的每个节点的最短路径已经被找到。算法重复从V-S中选择最短路径估计最小的节点u，将u加入结合S，然后对所有从u出发的边进行松弛。</p>
<pre><code>DIJKSTRA(G,w,s)
    INITIALIZE-SINGLE-SOURCE(G,s)//对v.d和v.π初始化
    S={}
    Q=G.V
    while Q.length != 0
        u = UXTRACT-MIN(Q)//从V-S中选出最短路径估计最小的节点u
        S=S∪{u}
        for each vertex v∈G.Adj[u]
            RELAX(u,v,w)
</code></pre><p><strong>算法解释</strong><br>二维数组 e 来存储顶点之间边的关系，初始值如下：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-23-22-23-08.png" alt=""> </p>
<p>我们还需要用一个一维数组 dis 来存储 1 号顶点到其余各个顶点的初始路程，如下。<br>我们将此时 dis 数组中的值称为最短路的“估计值”<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-23-22-23-38.png" alt=""> </p>
<p>图的关系如图所示，1是源点<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-23-22-22-41.png" alt=""> </p>
<p>既然是求 1 号顶点到其余各个顶点的最短路程，那就先找一个离 1 号顶点最近的顶点。通过数组 dis 可知当前离 1 号顶点最近是 2 号顶点。当选择了 2 号顶点后，dis[2]的值就已经从“估计值”变为了“确定值”，即 1 号顶点到 2 号顶点的最短路程就是当前 dis[2]值。<br>原因：目前离 1 号顶点最近的是 2 号顶点，并且这个图所有的边都是正数，那么肯定不可能通过第三个顶点中转，使得 1 号顶点到 2 号顶点的路程进一步缩短了。因为 1 号顶点到其它顶点的路程肯定没有 1 号到 2 号顶点短，</p>
<p>既然选了 2 号顶点，接下来再来看 2 号顶点有哪些出边呢。有 2-&gt;3 和 2-&gt;4 这两条边。先讨论通过 2-&gt;3 这条边能否让 1 号顶点到 3 号顶点的路程变短。也就是说现在来比较 dis[3]和 dis[2]+e[2][3]的大小。其中 dis[3]表示 1 号顶点到 3 号顶点的路程。dis[2]+e[2][3]中 dis[2]表示 1 号顶点到 2 号顶点的路程，e[2][3]表示 2-&gt;3 这条边。所以 dis[2]+e[2][3]就表示从 1 号顶点先到 2 号顶点，再通过 2-&gt;3 这条边，到达 3 号顶点的路程。</p>
<p>我们发现 dis[3]=12，dis[2]+e[2][3]=1+9=10，dis[3]&gt;dis[2]+e[2][3]，因此 dis[3]要更新为 10。这个过程有个专业术语叫做“松弛”。即 1 号顶点到 3 号顶点的路程即 dis[3]，通过 2-&gt;3 这条边松弛成功。这便是 Dijkstra 算法的主要思想：通过“边”来松弛 1 号顶点到其余各个顶点的路程。</p>
<p>同理通过 2-&gt;4（e[2][4]），可以将 dis[4]的值从 ∞ 松弛为 4（dis[4]初始为 ∞，dis[2]+e[2][4]=1+3=4，dis[4]&gt;dis[2]+e[2][4]，因此 dis[4]要更新为 4）。</p>
<p>刚才我们对 2 号顶点所有的出边进行了松弛。松弛完毕之后 dis 数组为：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-23-22-31-33.png" alt=""> </p>
<p>以此类推，此处不再多加阐述。</p>
<p>参考文献<a href="http://wiki.jikexueyuan.com/project/easy-learn-algorithm/dijkstra.html" target="_blank" rel="external">算法 7：Dijkstra 最短路算法</a></p>
<h1 id="有向无环图的单源最短路径问题">5. 有向无环图的单源最短路径问题</h1><p>来日再填坑。</p>
]]></content>
      
        <categories>
            
            <category> 算法 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[ACM--Radar Installation]]></title>
      <url>/2017/03/22/ACM-Radar-Installation/</url>
      <content type="html"><![CDATA[<h1 id="题目描述">1. 题目描述</h1><p>Assume the coasting is an infinite straight line. Land is in one side of coasting, sea in the other. Each small island is a point locating in the sea side. And any radar installation, locating on the coasting, can only cover d distance, so an island in the sea can be covered by a radius installation, if the distance between them is at most d. </p>
<p>We use Cartesian coordinate system, defining the coasting is the x-axis. The sea side is above x-axis, and the land side below. Given the position of each island in the sea, and given the distance of the coverage of the radar installation, your task is to write a program to find the minimal number of radar installations to cover all the islands. Note that the position of an island is represented by its x-y coordinates. </p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-22-19-32-14.png" alt=""> </p>
<p>coasting：滑行<br>infinite：无穷的<br>Cartesian coordinate system：笛卡尔坐标系</p>
<p>已知：海岸线是x轴，以上是海，以下是陆地。雷达安装在海岸线上，覆盖半径是d。<br>目标：求能够覆盖所有岛屿的雷达安装数目。<br>需需要注意的是，海岛坐标在x-y坐标系中。</p>
<h1 id="Input">2. Input</h1><p>The input consists of several test cases. The first line of each case contains two integers n (1&lt;=n&lt;=1000) and d, where n is the number of islands in the sea and d is the distance of coverage of the radar installation. This is followed by n lines each containing two integers representing the coordinate of the position of each island. Then a blank line follows to separate the cases. </p>
<p>The input is terminated by a line containing pair of zeros </p>
<p>输入一般包含好几组case测试数据。</p>
<p>每个case的第一行是(n,d)<br>然后是n行岛屿坐标</p>
<p>最后以（0,0）结尾</p>
<h1 id="Output">3. Output</h1><p>For each test case output one line consisting of the test case number followed by the minimal number of radar installations needed. “-1” installation means no solution for that case.</p>
<h1 id="思路">4. 思路</h1><p>这道题问的是怎样放雷达使其放的雷达数目最少而能够探测到所有的岛屿，这里需要转换为求每个岛屿的能放雷达的区间的问题:</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-22-21-06-38.png" alt=""> </p>
<p>抽象问题:每个小岛都对应一个区域,这个区域内的雷达都能探测到这个小岛,把这N个区域求出来,问题现在就变成了,最少放置几个点,能使得每个区域内都至少有一个点.</p>
<p>这道题目的关键之处就是把面的问题转换成线的问题，每一个座海岛在x轴上有一个区间，在这个区间里面的雷达都可以侦测到海岛，区间的范围即是[x-sqrt(dd – yy), x+sqrt(dd+yy)]，然后先以右端点为基进行从小到大排序，然后把第一个雷达默认放在最左端的xmax，接下来的点只要是xmin小于当前xmax就可以不用增加雷达，如果xmax == xmin的话也不用增加雷达。然后如果xmax &lt; xmin的话就加一个雷达，然后以xmin所属区间的xmax为基进行比较。</p>
<h1 id="代码">5. 代码</h1><pre><code>import java.io.PrintWriter;

import java.util.Arrays;
import java.util.Scanner;
public class Main {
    static class Range implements Comparable&lt;Range&gt;{
        double left,right;
        public Range(double left,double right){
            this.left = left;

            this.right = right;
        }
        @Override

        public int compareTo(Range range) {
            if(range.left == left){
                return ((Double)right).compareTo((Double)(range.right));
            }else{
                return ((Double)left).compareTo((Double)(range.left));
            }
        }

        @Override
        public String toString() {
            return &quot;(&quot; + left + &quot;,&quot; + right + &quot;)&quot;;
        }

    }


    public static void main(String[] args) {
        Scanner scn = new Scanner(System.in);

        PrintWriter out = new PrintWriter(System.out);
        int n ,d,x,y,num;
        double dx;
        Range[] ranges;
        int index = 0;
        while(true){
            num = 0;
            n = scn.nextInt();
            d = scn.nextInt();
            if(n == 0){
                break;
            }
            ranges = new Range[n];
            for(int i = 0; i &lt; n; i++){
                x = scn.nextInt();
                y = scn.nextInt();
                if(y &gt; d){
                    num = -1;
                }
                dx = Math.sqrt(d*d - y*y);
                ranges[i] = new Range(x - dx, x + dx);
            }
            Arrays.sort(ranges);//���
            if(num != -1){
                num = calute(ranges);
            }
            out.format(&quot;Case %d: %d\n&quot;,++index,num);
        }
        out.flush();

    }

    private static int calute(Range[] ranges) {
        int num = 1;
        int n = ranges.length;
        Range preRange = ranges[0],range;
        for(int i = 1; i &lt; n; i++){
            range = ranges[i];
            if(range.left &gt;= preRange.left &amp;&amp; range.left &lt;= preRange.right){
                preRange.left = range.left;
                if(range.right &lt; preRange.right){
                    preRange.right = range.right;
                }
            }else{
                num++;
                preRange = range;
            }
        }
        return num;
    }
}
</code></pre>]]></content>
      
        <categories>
            
            <category> ACM </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[numpy笔记]]></title>
      <url>/2017/03/21/Python-numpy%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<h1 id="numpy结构数组">1. numpy结构数组</h1><p>在c语言中，我们可以使用关键字struct定义结构类型。和c语言一样，numpy也可以创建结构定义，这样可以很方便的读取二进制的C语言结构数组，将其转换为numpy数组对象，假设我们定义的结构数组如下(C语言描述)：</p>
<pre><code>struct Person{
     char name[30];
     int    age;
     float weight; 
};
</code></pre><p>我们在python中可以自定义类型如下：</p>
<pre><code>persontype = np.dtype({
&apos;names&apos;:[&apos;name&apos;,&apos;age&apos;,&apos;weight&apos;],
&apos;formats&apos;:[&apos;S30&apos;,&apos;i&apos;,&apos;f&apos;]},align = True)
</code></pre><p>参考文献<a href="http://www.cnblogs.com/td15980891505/p/6083083.html" target="_blank" rel="external">numpy中结构数组</a></p>
]]></content>
      
        <categories>
            
            <category> Python </category>
            
        </categories>
        
        
        <tags>
            
            <tag> numpy </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[java学习笔记2-继承]]></title>
      <url>/2017/03/16/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-2-%E7%BB%A7%E6%89%BF/</url>
      <content type="html"><![CDATA[<h1 id="super关键字">1. super关键字</h1><h2 id="子类override-覆盖-父类的函数">1.1. 子类override(覆盖)父类的函数</h2><p>override时，使用<code>super</code>调用父类的方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//超类，员工</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Employee</span></span>&#123;</div><div class="line">    <span class="keyword">private</span> String name;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">double</span> salary;<span class="comment">//薪水</span></div><div class="line">    <span class="keyword">private</span> Date hireDay;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getSalary</span><span class="params">()</span></span>&#123;</div><div class="line">        <span class="keyword">return</span> salary;</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">//经理</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Manage</span> <span class="keyword">extends</span> <span class="title">Employee</span></span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">double</span> bonus;<span class="comment">//奖金</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getSalary</span><span class="params">()</span></span>&#123;<span class="comment">//对原来的getSalary进行override</span></div><div class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.bonus + <span class="keyword">super</span>.getSalary();<span class="comment">//super调用父类的getSalary()方法</span></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="super在构造器中的应用">1.2. super在构造器中的应用</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">Manager</span><span class="params">(String n, <span class="keyword">double</span> s, <span class="keyword">int</span> year, <span class="keyword">int</span> mouth, <span class="keyword">int</span> day)</span></span>&#123;</div><div class="line">    <span class="keyword">super</span>(n,s,year,mouth,day);<span class="comment">//调用超类Employee中对应参数的构造器</span></div><div class="line">    bonus = <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="多态">2. 多态</h1><p>一个对象变量可以指示多种实际类型的现象————多态（polymorphism）<br>在运行时自动选择调用那个方法的现象————动态绑定（dynamic binding）</p>
<p>例如：</p>
<pre><code>Employee e = new Employee();
e = new Manage(); // is ok
</code></pre><p>此时，对象变量<code>e</code>也可以引用<code>Manager</code>的对象。</p>
<pre><code>Manage boss = new Manage(...);
Employee[] staff = new Employee();
</code></pre><h1 id="调用对象方法的执行过程">3. 调用对象方法的执行过程</h1><ol>
<li>编译器查看对象的声明类型和方法名。假设调用<code>x.f(param)</code>，且隐式参数x声明为C类的对象。编译器一一列举所有C类中名为f的方法和其超类中访问属性为public且名为f的方法。</li>
<li>编译器查看调用方法时提供的参数类型。这个过程叫做<strong>重载解析</strong>（overloading resolution）</li>
<li>如果是private方法、static方法、final方法或者构造器，那么编译器会准确地知道应该调用哪个方法（编译器可以在编译阶段就完成绑定），这种调用方式叫<strong>静态绑定</strong>(static binding)。与此对应的是，调用的方法依赖于隐式参数的实际类型（编译器在编译阶段不知道要调用哪个方法，直到运行时才能确定），并在运行时实现<strong>动态绑定</strong>。有一个很好的例子解释这两个概念——<a href="http://blog.csdn.net/lingzhm/article/details/44116091" target="_blank" rel="external">lingzhm-动态绑定</a></li>
<li>程序运行时，若是动态绑定调用方法，那就先从本类中寻找，否则从超类中寻找。（每个类都有一个方法表method table）</li>
</ol>
<h1 id="阻止继承：final类和方法">4. 阻止继承：final类和方法</h1><p>不允许扩展（被继承）的类被称为final类。</p>
<p>例如下例子中的Executive类就不能有子类。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Executive</span> <span class="keyword">extends</span> <span class="title">Manager</span></span>&#123;</div><div class="line">    ...</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>类中的方法也可以final,那么子类就不能覆盖这个方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Employee</span></span>&#123;</div><div class="line">    ...</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> String <span class="title">getName</span><span class="params">()</span></span>&#123;</div><div class="line">        <span class="keyword">return</span> name;</div><div class="line">    &#125;</div><div class="line">    ...</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="抽象类，abstract">5. 抽象类，abstract</h1><p>用于表示某种很抽象的、上层的、更通用的类。例如图中的<code>Person</code>类。<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-04-13-10-25-16.png" alt=""> </p>
<ul>
<li>一般来说，包含一个或多个抽象方法的类本身必须被声明为抽象的。</li>
<li>抽象类<strong>不能</strong>被实例化！</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">class</span> <span class="title">Person</span></span>&#123;</div><div class="line">    ...</div><div class="line">    <span class="keyword">private</span> String name;<span class="comment">//人类共有的属性,是具体的属性</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String n)</span></span>&#123;<span class="comment">//具体的方法</span></div><div class="line">        name=n;</div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> String <span class="title">getDescription</span><span class="params">()</span></span>;<span class="comment">//抽象方法</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li><p>可以定义抽象类的对象变量，但只能引用非抽象子类的对象：</p>
<p>  Person p = new Student(“Vince Vu”,”Economics”);</p>
</li>
</ul>
<p>照着书上写了abstract的<a href="https://github.com/jiayi797/Java/tree/master/abstactClasses" target="_blank" rel="external">demo</a></p>
<p>输出为：</p>
<pre><code>Harry Hacker,an employee with a salary of 50000.00
Maria Morris,a student majoring in computer science
</code></pre><h1 id="受保护访问，Protected">6. 受保护访问，Protected</h1><p>若超类的某个域被声明为protected,那么子类就可以直接访问这个protected域。</p>
<ul>
<li>private-仅本类可见</li>
<li>public-所有类可见</li>
<li>protected-对本包和所有子类可见</li>
<li>默认-对本包可见</li>
</ul>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[GBDT]]></title>
      <url>/2017/03/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-GBDT/</url>
      <content type="html"><![CDATA[<p>之前的AdaBoostDTree的误差函数是指数型的。GBDT的误差函数是任意指定的。<br>GBDT的核心就在于，每一棵树学的是之前所有树结论和的残差，这个残差就是一个加预测值后能得真实值的累加量。</p>
<h1 id="GBDT的误差函数">1. GBDT的误差函数</h1><p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-15-13-49-01.png" alt=""> </p>
<h1 id="目标">2. 目标</h1><ol>
<li>求函数h(x)的形式</li>
<li>求h(x)的步长η</li>
</ol>
<h1 id="回归问题求解目标">3. 回归问题求解目标</h1><p>对于回归（regression）问题，误差函数一般采用平方误差。即：</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-15-13-55-15.png" alt=""> </p>
<p>为了进一步求解，我们对上式进行taylor展开，即：</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-15-13-58-42.png" alt=""> </p>
<p>其中：</p>
<ul>
<li>左边一项$err(S_n,y_n)$是常量（因为$S_n$、$y_n$都已知）</li>
<li>右边一项应该对s求导，并在sn这点取导数值（$error=(s-y)^2$求导之后得到$2(s-y)$）</li>
</ul>
<p>那么，上式等于：</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-15-14-04-27.png" alt=""> </p>
<h2 id="求h-x">3.1. 求h(x)</h2><p>为了让上式最小化，那么貌似$|h(x)|$无穷大即可实现，这不科学！于是我们要对$h(x)$的大小进行限制（类似归一化）————加入惩罚项$(h(x_n))^2$，即将上式变为：</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-15-14-19-46.png" alt=""> </p>
<p>而上式可变为：</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-15-14-20-27.png" alt=""> </p>
<p>其中的$(s_n-y_n)^2$是常数，记为constant</p>
<p>那么新的目标就变为：用$x_n$和$y_n-s_n$做一个regression即可。即：</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-15-14-27-31.png" alt=""> </p>
<p>经过penalize一番折腾之后，h终于有个像模像样的形式了：即regression with residuals（残差）。</p>
<h2 id="求步长η">3.2. 求步长η</h2><p>需要求得一个η，使得下式最小化：</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-15-15-21-27.png" alt=""> </p>
<p>为了方便计算，我们将平方内的项取负：</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-15-15-22-55.png" alt=""> </p>
<p>上式的$y_n-s_n$即residuals（残差）.这是一个单变量的线性回归问题，其中输入是用gt转换后的数据，输出是残差(residual)。</p>
<h1 id="GBDT算法">4. GBDT算法</h1><p>输出：$\sum_t^T\alpha_t g_t(x)$，即一堆权重$\alpha_t$和一堆决策树$g_t(x)$<br>步骤：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-15-15-32-42.png" alt=""> </p>
<p>1）利用C&amp;RT去学{x, yn-sn}，保留这一轮学出来的树gt(x)</p>
<p>2）再求{gt(x), residual}线性回归，最小化目标函数求出来ita</p>
<p>3）更新sn</p>
<p>学习足够多次数后，返回组合的GBDT。</p>
]]></content>
      
        <categories>
            
            <category> 机器学习算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 树模型 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[jacman/hexo目录改成浮动]]></title>
      <url>/2017/03/14/blog-jacman-hexo%E7%9B%AE%E5%BD%95%E6%94%B9%E6%88%90%E6%B5%AE%E5%8A%A8/</url>
      <content type="html"><![CDATA[<h1 id="添加样式支持">1. 添加样式支持</h1><p>为了不吧原先的像是文件搞得太乱，这里，添加子集的样式文件。<br>首先，在样式文件的<code>source</code>文件夹下找到<code>css</code>文件夹，打开<code>style.styl</code>文件，在最后添加：</p>
<p><code>@import &quot;_my/mycss&quot;;</code> </p>
<h1 id="新建自定义样式">2. 新建自定义样式</h1><p>找到样式文件夹<code>css</code> 新建<code>_my</code>文件夹，在其中新建<code>mycss.sty</code>l文件，之后就可以按照<code>stylus</code>的格式自定义样式了。</p>
<h1 id="设置toc浮动">3. 设置toc浮动</h1><p>给mycss.sty添加：</p>
<pre><code>#toc
 line-height 1.2em
 font-size 0.8em
 backgroud-color #fff
 float right
 position fixed
 right 30em
 top 20em
</code></pre><h1 id="存在的问题">4. 存在的问题</h1><p>暂不支持自相应。</p>
<h1 id="参考文献">5. 参考文献</h1><ol>
<li><a href="https://segmentfault.com/a/1190000003846777" target="_blank" rel="external">Hexo博客主题NexT使用自定义的CSS样式</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 瞎折腾 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Java学习笔记1-类与对象]]></title>
      <url>/2017/03/14/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1-%E7%B1%BB%E4%B8%8E%E5%AF%B9%E8%B1%A1/</url>
      <content type="html"><![CDATA[<p>本文主要总结了一些自己不太熟悉的概念。</p>
<h1 id="对象与对象变量">1. 对象与对象变量</h1><pre><code>Date birthday = new Date();
</code></pre><p>对象变量：birthday<br>对象：右边的部分</p>
<p>一个对象变量并没有实际包含一个对象，仅仅是引用一个对象。</p>
<p>可以显示地将对象变量设置为<code>null</code>，表明这个对象变量目前没有引用任何对象：</p>
<pre><code>birthday = null;
</code></pre><h1 id="隐式参数与显式参数">2. 隐式参数与显式参数</h1><p>例，methodName()是类class1的方法，</p>
<pre><code>calss class1{
int a;
    public void methodName(int b){
    this.a = b ;
}
</code></pre><ul>
<li>显式参数(explicit)：括号里面的，例如double pName</li>
<li>隐式参数(implicit)：出现在方法名前的class1类对象<br>– 关键词<code>this</code>表示隐式参数。例如<code>this.a</code></li>
</ul>
<h1 id="封装">3. 封装</h1><p>不能编写返回<code>引用可变对象</code>的访问器方法！例如：</p>
<pre><code>class class1{
    private Date a;
    public Date get(){
        return Date a; //会破坏封装性！
    }
}
</code></pre><p>以上操作破坏了<code>a</code>的私有性。</p>
<p>改正方法：克隆（clone）</p>
<pre><code>class class1{
    private Date a;
    public Date get(){
        return Date a.clone(); //使用clone()
    }
}
</code></pre><h1 id="final实例域">4. final实例域</h1><pre><code>class class1{
    private final String name;
}
</code></pre><p>final域的特征：</p>
<ol>
<li>构造对象时，必须初始化final</li>
<li>后面操作中，不能再改动</li>
<li>但并不等于常量！</li>
<li>属于对象，并不是类！</li>
</ol>
<h1 id="static静态">5. static静态</h1><h2 id="static域">5.1. static域</h2><ol>
<li>每个类只能有一个static域</li>
<li>同一类的所有对象共享一个static域</li>
<li>即使没有对象，static域也存在。它属于类，不属于任何一个对象</li>
</ol>
<pre><code>class Employee{
    private static int nextId = 1;
    private int id;
}
</code></pre><h2 id="static常量">5.2. static常量</h2><ol>
<li>如下例，在程序中，可以使用<code>Math.PI</code>来获取这个常量。</li>
</ol>
<pre><code>public class Math{
    public static final double PI = 3.14;
}
</code></pre><h2 id="static方法">5.3. static方法</h2><pre><code>Math.pow(x,a)
</code></pre><ol>
<li>不使用任何对象；</li>
<li>不能操作实例域（即类内的非static方法和变量），因为它不能操作对象；</li>
<li>可以访问自身类的static域；</li>
<li>对象也可以调用static方法。</li>
</ol>
<p>在下面两种情况使用静态方法：</p>
<ol>
<li>一个方法不需要访问对象；</li>
<li>一个方法只需要访问类的static域。</li>
</ol>
<h2 id="工厂方法">5.4. 工厂方法</h2><p>工厂方法是静态方法的一种常见用途。<br>例如，<code>NumberFormat</code>使用工厂方法(而不是构造器)产生<strong>不同风格</strong>的格式对象。</p>
<pre><code>NumberFormat a = NumberFormat.getSytleA();
NumberFormat b = NumberFormat.getStyleB();
</code></pre><h2 id="main方法">5.5. main方法</h2><pre><code>public class Application{
    public static void main(String[] args){
        // construct objects here
    }
}
</code></pre><ol>
<li>每一个类可以有一个main方法，用来单元测试；</li>
<li>多个类被调用时，只会执行一个main方法；</li>
</ol>
<h1 id="初始化块">6. 初始化块</h1><p>构造对象时，先运行初始化块，才运行构造器主体部分。</p>
<pre><code>class Employee{
    private static int nextId;
    private int id;
    //初始化块
    {
        id=nextId;
    }
}
</code></pre><p>如果对类的静态域进行初始化的代码比较复杂，就可以使用静态的初始化块：</p>
<pre><code>static{
    Random generator = new Random();
    nextId = generator.nextId(10000);
}
</code></pre><p>类（！！！不是对象）第一次加载时，将会进行static域的初始化。</p>
<h1 id="初始化数据域的三种方法">7. 初始化数据域的三种方法</h1><ol>
<li>在构造器中设置值</li>
<li>在声明中赋值</li>
<li>在初始化块中赋值</li>
</ol>
<h1 id="类的初始化顺序">8. 类的初始化顺序</h1><p>对于静态变量、静态初始化块、变量、初始化块、构造器，它们的初始化顺序依次是（静态变量、静态初始化块）&gt;（变量、初始化块）&gt;构造器。</p>
<p>例如，</p>
<pre><code>public class InitialOrderTest {   
    // 静态变量   
    public static String staticField = &quot;静态变量&quot;;   
    // 变量   
    public String field = &quot;变量&quot;;   
    // 静态初始化块   
    static {   
        System.out.println(staticField);   
        System.out.println(&quot;静态初始化块&quot;);   
    }   
    // 初始化块   
    {   
        System.out.println(field);   
        System.out.println(&quot;初始化块&quot;);   
    }   
    // 构造器   
    public InitialOrderTest() {   
        System.out.println(&quot;构造器&quot;);   
    }   
    public static void main(String[] args) {   
        new InitialOrderTest();   
    }   
}  
</code></pre><p>运行以上代码，我们会得到如下的输出结果： </p>
<pre><code>静态变量
静态初始化块
变量
初始化块
构造器
</code></pre><p>对于继承的情况：</p>
<pre><code>class Parent {   
    // 静态变量   
    public static String p_StaticField = &quot;父类--静态变量&quot;;   
    // 变量   
    public String p_Field = &quot;父类--变量&quot;;   

    // 静态初始化块   
    static {   
        System.out.println(p_StaticField);   
        System.out.println(&quot;父类--静态初始化块&quot;);   
    }   

    // 初始化块   
    {   
        System.out.println(p_Field);   
        System.out.println(&quot;父类--初始化块&quot;);   
    }   

    // 构造器   
    public Parent() {   
        System.out.println(&quot;父类--构造器&quot;);   
    }   
}   

public class SubClass extends Parent {   
    // 静态变量   
    public static String s_StaticField = &quot;子类--静态变量&quot;;   
    // 变量   
    public String s_Field = &quot;子类--变量&quot;;   
    // 静态初始化块   
    static {   
        System.out.println(s_StaticField);   
        System.out.println(&quot;子类--静态初始化块&quot;);   
    }   
    // 初始化块   
    {   
        System.out.println(s_Field);   
        System.out.println(&quot;子类--初始化块&quot;);   
    }   

    // 构造器   
    public SubClass() {   
        System.out.println(&quot;子类--构造器&quot;);   
    }   

    // 程序入口   
    public static void main(String[] args) {   
        new SubClass();   
    }   
}  
</code></pre><p>运行一下上面的代码，结果马上呈现在我们的眼前： </p>
<pre><code>父类--静态变量
父类--静态初始化块
子类--静态变量
子类--静态初始化块
父类--变量
父类--初始化块
父类--构造器
子类--变量
子类--初始化块
子类--构造器
</code></pre><p>总得来说，是先静态后变量，先父类后子类</p>
<h1 id="其他重点">9. 其他重点</h1><ol>
<li>基于类的访问权限：一个方法可以访问所属类的所有私有数据。</li>
<li>java的值引用（基本数据类型、对象引用）</li>
<li>如果类中提供了至少一个有参构造器，而没有无参构造器，则在构造无参对象时会出错。</li>
</ol>
<h1 id="Java类库中的GregorianCalendar类-（删除本节）">10. Java类库中的GregorianCalendar类 （删除本节）</h1><h2 id="纪元">10.1. 纪元</h2><p>时间是用距离一个固定时间点的毫秒数表示的，这个点就是纪元(epoch)。</p>
<h2 id="时间与日历">10.2. 时间与日历</h2><p>为了将<strong>时间</strong>与<strong>日历</strong>分开，标准Java类库分别包含两个类：</p>
<ul>
<li>Date类：用来表示时间点的类；</li>
<li>GregorianCalendar类：用来表示公历法的类；（通过它还有一个扩展类——Calendar类，描述了日历的一般属性）</li>
</ul>
<h3 id="Date类">10.2.1. Date类</h3><p>用来表示时间的类；</p>
<p>只有少量的方法，例如比较两个时间点before(),after()：</p>
<pre><code>doday.before(birthday)
</code></pre><h3 id="GregorianCalendar类">10.2.2. GregorianCalendar类</h3><p>常见方法：</p>
<p><code>new GregorianCalendar()</code>，构造新的对象，用于表示对象构造时的日期和时间；</p>
<p>例如:</p>
<pre><code>GregorianCalendar g1 = new GregorianCalendar();
</code></pre><p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-14-10-47-16.png" alt=""> </p>
<p><code>new GregorianCalendar(1999,11,31)</code>，提供年月日构造一个表示特定日期午夜的日历对象。（月份从0开始计数，11表示12月）</p>
<p><code>new GregorianCalendar(1991,Calendar.DECEMBER,31)</code>,与上等价</p>
<p><code>new GregorianCalendar(1991,Calendar.DECEMBER,31,23,59,59)</code>,设置时间</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[O2O优惠券预测——对第一名的思路源码分析（二）]]></title>
      <url>/2017/03/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5-O2O%E4%BC%98%E6%83%A0%E5%88%B8%E9%A2%84%E6%B5%8B-%E5%AF%B9%E7%AC%AC%E4%B8%80%E5%90%8D%E7%9A%84%E6%80%9D%E8%B7%AF%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
      <content type="html"><![CDATA[<p>本文主要针对天池大数据竞赛之“O2O优惠券使用预测”的冠军队伍的思路和源码分析。在此感谢无私的前辈(诗人都藏在水底)[<a href="https://github.com/wepe/O2O-Coupon-Usage-Forecast]。" target="_blank" rel="external">https://github.com/wepe/O2O-Coupon-Usage-Forecast]。</a></p>
<p>本文主要对模型训练<code>xgb.py</code> 做一些详细的分析。</p>
<p>文件：O2O-Coupon-Usage-Forecast/code/wepon/season one </p>
<p><code>xgb.py</code> 训练xgboost模型，生成特征重要性文件，生成预测结果。单模型第一赛季A榜AUC得分0.798.</p>
<h1 id="import包">1. import包</h1><p>首先作者import xgboost,因此我们需要安装一下它。</p>
<p>XGBoost是数据挖掘中用到一个新型的数据分析包，相对其它Boosting模型更加高效。</p>
<p>安装教程<a href="http://www.jianshu.com/p/11f9229b0ecd" target="_blank" rel="external">xgboost install on windows</a></p>
<h1 id="导入数据">2. 导入数据</h1><pre><code>#将数据集导入
dataset1 = pd.read_csv(&apos;data/dataset1.csv&apos;)
dataset2 = pd.read_csv(&apos;data/dataset2.csv&apos;)
dataset3 = pd.read_csv(&apos;data/dataset3.csv&apos;)
</code></pre><p><code>dataset1、dataset2</code>有56个特征，图是前十个。</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-12-22-11-30.png" alt=""> </p>
<p><code>dataset3</code>有57个特征</p>
<pre><code>#将dataset1的label列的-1都换成0
dataset1.label.replace(-1,0,inplace=True)
dataset2.label.replace(-1,0,inplace=True)

#删除重复项
dataset1.drop_duplicates(inplace=True)
dataset2.drop_duplicates(inplace=True)
dataset3.drop_duplicates(inplace=True)
</code></pre><p>将dataset1和dataset2连起来</p>
<pre><code>dataset12 = pd.concat([dataset1,dataset2],axis=0)
</code></pre><p>dataset1_y赋值为dataset1的label列</p>
<pre><code>dataset1_y = dataset1.label
</code></pre><p>删除dataset1的’user_id’,’label’,’day_gap_before’,’day_gap_after’字段，赋值给dataset1_x</p>
<pre><code>dataset1_x = dataset1.drop([&apos;user_id&apos;,&apos;label&apos;,&apos;day_gap_before&apos;,&apos;day_gap_after&apos;],axis=1)  # &apos;day_gap_before&apos;,&apos;day_gap_after&apos; cause overfitting, 0.77


dataset2_y = dataset2.label
dataset2_x = dataset2.drop([&apos;user_id&apos;,&apos;label&apos;,&apos;day_gap_before&apos;,&apos;day_gap_after&apos;],axis=1)
dataset12_y = dataset12.label
dataset12_x = dataset12.drop([&apos;user_id&apos;,&apos;label&apos;,&apos;day_gap_before&apos;,&apos;day_gap_after&apos;],axis=1)
dataset3_preds = dataset3[[&apos;user_id&apos;,&apos;coupon_id&apos;,&apos;date_received&apos;]]
dataset3_x = dataset3.drop([&apos;user_id&apos;,&apos;coupon_id&apos;,&apos;date_received&apos;,&apos;day_gap_before&apos;,&apos;day_gap_after&apos;],axis=1)
</code></pre><p>用shape属性来显示数据的格式</p>
<pre><code>print dataset1_x.shape,dataset2_x.shape,dataset3_x.shape
</code></pre><p>若输出：(8618,36) 表示这个表格有8618行和36列的数据，其中dimensions[0]为8618，dimensions[1]为36</p>
<h1 id="加载数据到xgboost">3. 加载数据到xgboost</h1><p>dataset1、dateset2、dateset3 为xgb的DMatrix</p>
<pre><code>dataset1 = xgb.DMatrix(dataset1_x,label=dataset1_y)
dataset2 = xgb.DMatrix(dataset2_x,label=dataset2_y)
dataset12 = xgb.DMatrix(dataset12_x,label=dataset12_y)
dataset3 = xgb.DMatrix(dataset3_x)
</code></pre><p>参考文献<a href="http://blog.csdn.net/sb19931201/article/details/52557382" target="_blank" rel="external">xgboost入门与实战（原理篇）</a></p>
<h1 id="设置参数">4. 设置参数</h1><pre><code>params={&apos;booster&apos;:&apos;gbtree&apos;,
        &apos;objective&apos;: &apos;rank:pairwise&apos;,
        &apos;eval_metric&apos;:&apos;auc&apos;,
        &apos;gamma&apos;:0.1,
        &apos;min_child_weight&apos;:1.1,
        &apos;max_depth&apos;:5,
        &apos;lambda&apos;:10,
        &apos;subsample&apos;:0.7,
        &apos;colsample_bytree&apos;:0.7,
        &apos;colsample_bylevel&apos;:0.7,
        &apos;eta&apos;: 0.01,
        &apos;tree_method&apos;:&apos;exact&apos;,
        &apos;seed&apos;:0,
        &apos;nthread&apos;:12
        }
</code></pre><h1 id="训练模型">5. 训练模型</h1><pre><code>model = xgb.train(params,dataset12,num_boost_round=3500,evals=watchlist)    
</code></pre><h1 id="预测测试集">6. 预测测试集</h1><pre><code>dataset3_preds[&apos;label&apos;] = model.predict(dataset3)
dataset3_preds.label = MinMaxScaler().fit_transform(dataset3_preds.label)
dataset3_preds.sort_values(by=[&apos;coupon_id&apos;,&apos;label&apos;],inplace=True)
dataset3_preds.to_csv(&quot;xgb_preds.csv&quot;,index=None,header=None)
print dataset3_preds.describe()
</code></pre><h1 id="保存特征评分">7. 保存特征评分</h1><pre><code>feature_score = model.get_fscore()
feature_score = sorted(feature_score.items(), key=lambda x:x[1],reverse=True)
fs = []
for (key,value) in feature_score:
    fs.append(&quot;{0},{1}\n&quot;.format(key,value))

with open(&apos;xgb_feature_score.csv&apos;,&apos;w&apos;) as f:
    f.writelines(&quot;feature,score\n&quot;)
    f.writelines(fs)
</code></pre><h1 id="总结">8. 总结</h1><p>这次算是对自己之前的各种理论知识进行了一次梳理，感觉平时过于注重算法的研究，并没有注意到宏观上的操作。以后要多加注意</p>
]]></content>
      
        <categories>
            
            <category> o2o优惠券使用预测 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[O2O优惠券预测——对第一名的思路源码分析（一）]]></title>
      <url>/2017/03/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5-O2O%E4%BC%98%E6%83%A0%E5%88%B8%E9%A2%84%E6%B5%8B-%E5%AF%B9%E7%AC%AC%E4%B8%80%E5%90%8D%E7%9A%84%E6%80%9D%E8%B7%AF%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%80%EF%BC%89/</url>
      <content type="html"><![CDATA[<p>感觉自己还是太渣，看了些许算法，并不知道有什么卵用。决定好好分析分析别人的思路，也许能够对我带来些许启发。</p>
<p>本文主要针对天池大数据竞赛之“O2O优惠券使用预测”的冠军队伍的思路和源码分析。在此感谢无私的前辈(诗人都藏在水底)[<a href="https://github.com/wepe/O2O-Coupon-Usage-Forecast]。" target="_blank" rel="external">https://github.com/wepe/O2O-Coupon-Usage-Forecast]。</a></p>
<p>本文主要对数据的抽取<code>extract_feature.py</code>做一些详细的分析。</p>
<h1 id="解决方案概述">1. 解决方案概述</h1><p>本赛题提供了用户线下消费和优惠券领取核销行为的纪录表，用户线上点击/消费和优惠券领取核销行为的纪录表，记录的时间区间是2016.01.01至2016.06.30,需要预测的是2016年7月份用户领取优惠劵后是否核销。根据这两份数据表，我们首先对数据集进行划分，然后提取了用户相关的特征、商家相关的特征，优惠劵相关的特征，用户与商家之间的交互特征，以及利用本赛题的leakage得到的其它特征（这部分特征在实际业务中是不可能获取到的）。最后训练了XGBoost，GBDT，RandomForest进行模型融合。</p>
<p><strong>源码分析</strong></p>
<p>第二赛季暂时没有平台，所以本文只对第一赛季的源码进行分析。</p>
<p>文件：O2O-Coupon-Usage-Forecast/code/wepon/season one </p>
<p>这个文件夹存放第一赛季的代码</p>
<ul>
<li><code>extract_feature.py</code>划分数据集，提取特征，生成训练集（dataset1和dataset2）和预测集（dataset3）。</li>
<li><code>xgb.py</code> 训练xgboost模型，生成特征重要性文件，生成预测结果。单模型第一赛季A榜AUC得分0.798.</li>
</ul>
<h1 id="import概述">2. import概述</h1><p>分析对象：extract_feature.py</p>
<h2 id="import包概述">2.1. import包概述</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> date</div></pre></td></tr></table></figure>
<h2 id="pandas">2.2. pandas</h2><p>Pandas 是基于 NumPy (因此还要<code>import numpy</code>) 的一个非常好用的库，正如名字一样，人见人爱。之所以如此，就在于不论是读取、处理数据，用它都非常简单。Pandas提供了很多处理大数据的方法。我想是因为此，原作者才采用了它。</p>
<p>Pandas 有两种自己独有的基本数据结构。<code>Series</code> 和 <code>DataFrame</code>，它们让数据操作更简单了。</p>
<p>两种结构的属性和方法不再多阐述。见两份很好的参考文档：</p>
<ol>
<li><a href="http://wiki.jikexueyuan.com/project/start-learning-python/311.html" target="_blank" rel="external">Pandas 使用</a></li>
<li><a href="http://www.cnblogs.com/chaosimple/p/4153083.html" target="_blank" rel="external">十分钟搞定pandas</a></li>
<li><a href="http://dataunion.org/14261.html" target="_blank" rel="external">在Python中利用Pandas库处理大数据的简单介绍</a></li>
<li><a href="http://pandas.pydata.org/pandas-docs/stable/cookbook.html" target="_blank" rel="external">pandas官方文档</a></li>
<li><a href="http://www.cnblogs.com/pengsixiong/p/5050833.html" target="_blank" rel="external">pandas常见方法，中文</a></li>
</ol>
<p>大概知道了import包的内容后，我们正式开始看源码。</p>
<h2 id="注意">2.3. 注意</h2><ol>
<li>读取之前，请先把数据的表头项删除（也就是第一行的string）</li>
</ol>
<h1 id="读取数据集">3. 读取数据集</h1><p>总结：</p>
<table>
<thead>
<tr>
<th></th>
<th style="text-align:right">name</th>
<th style="text-align:right">content</th>
<th style="text-align:center">varName</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td style="text-align:right">ccf_offline_stage1_train</td>
<td style="text-align:right">用户线下消费和优惠券领取行为</td>
<td style="text-align:center">off_train</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:right">ccf_online_stage1_train</td>
<td style="text-align:right">用户线上点击/消费和优惠券领取行为</td>
<td style="text-align:center">on_train</td>
</tr>
<tr>
<td>3</td>
<td style="text-align:right">offline_stage1_test_revised</td>
<td style="text-align:right">用户O2O线下优惠券使用预测样本</td>
<td style="text-align:center">off_test</td>
</tr>
</tbody>
</table>
<h2 id="源码分析">3.1. 源码分析</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#1754884 record,1053282 with coupon_id,9738 coupon. date_received:20160101~20160615,date:20160101~20160630, 539438 users, 8415 merchants</span></div><div class="line"></div><div class="line">off_train = pd.read_csv(<span class="string">'data/ccf_offline_stage1_train.csv'</span>,header=<span class="keyword">None</span>)</div><div class="line">off_train.columns = [<span class="string">'user_id'</span>,<span class="string">'merchant_id'</span>,<span class="string">'coupon_id'</span>,<span class="string">'discount_rate'</span>,<span class="string">'distance'</span>,<span class="string">'date_received'</span>,<span class="string">'date'</span>]</div><div class="line"></div><div class="line"><span class="comment">#2050 coupon_id. date_received:20160701~20160731, 76309 users(76307 in trainset, 35965 in online_trainset), 1559 merchants(1558 in trainset)</span></div><div class="line"></div><div class="line">off_test = pd.read_csv(<span class="string">'data/ccf_offline_stage1_test_revised.csv'</span>,header=<span class="keyword">None</span>,nrows=<span class="number">3000</span>)</div><div class="line">off_test.columns = [<span class="string">'user_id'</span>,<span class="string">'merchant_id'</span>,<span class="string">'coupon_id'</span>,<span class="string">'discount_rate'</span>,<span class="string">'distance'</span>,<span class="string">'date_received'</span>]</div><div class="line"></div><div class="line"><span class="comment">#11429826 record(872357 with coupon_id),762858 user(267448 in off_train)</span></div><div class="line"></div><div class="line">on_train = pd.read_csv(<span class="string">'data/ccf_online_stage1_train.csv'</span>,header=<span class="keyword">None</span>,nrows=<span class="number">47000</span>)</div><div class="line">on_train.columns = [<span class="string">'user_id'</span>,<span class="string">'merchant_id'</span>,<span class="string">'action'</span>,<span class="string">'coupon_id'</span>,<span class="string">'discount_rate'</span>,<span class="string">'date_received'</span>,<span class="string">'date'</span>]</div></pre></td></tr></table></figure>
<p>读数据主要用了pandas的read_cvs方法. 为了快捷分析，我们限定只读取数据集的前7w、3k、47w行</p>
<h1 id="采集特征">4. 采集特征</h1><h2 id="主要特征">4.1. 主要特征</h2><p>总结：</p>
<table>
<thead>
<tr>
<th>term</th>
<th style="text-align:right">来源</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td>dataset3</td>
<td style="text-align:right">table3,off_test</td>
<td style="text-align:center">off_test数据</td>
</tr>
<tr>
<td>dataset2</td>
<td style="text-align:right">table2,off_train</td>
<td style="text-align:center">领券时期在20160515-20160615之间的</td>
</tr>
<tr>
<td>dataset1</td>
<td style="text-align:right">table2,off_train</td>
<td style="text-align:center">领券日期在20160414-20160514的</td>
</tr>
<tr>
<td>feature3</td>
<td style="text-align:right">table2,off_train</td>
<td style="text-align:center">消费data在20160315-20160630的，或领券日期在20160315-20160630但没有消费的</td>
</tr>
<tr>
<td>feature2</td>
<td style="text-align:right">table2,off_train</td>
<td style="text-align:center">消费日期在20160201-20160514的，或领券日期在20160201-20160514但没有消费的</td>
</tr>
<tr>
<td>feature1</td>
<td style="text-align:right">table2,off_train</td>
<td style="text-align:center">消费日期在20160101-20160413的，或领券日期在20160101-20160413但没有消费的</td>
</tr>
</tbody>
</table>
<p>这是滑窗的方法得到多份训练数据集，特征区间越小，得到的训练数据集越多。划分方式：</p>
<table>
<thead>
<tr>
<th>项目</th>
<th>预测区间（提取label）</th>
<th style="text-align:center">特征区间（提取feature）</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>领券了的</td>
<td style="text-align:center">消费了的+领券了没消费的</td>
</tr>
<tr>
<td>测试集</td>
<td>dataset3</td>
<td style="text-align:center">feature3</td>
</tr>
<tr>
<td>训练集1</td>
<td>dataset2</td>
<td style="text-align:center">feature2</td>
</tr>
<tr>
<td>训练集2</td>
<td>dataset1</td>
<td style="text-align:center">feature1</td>
</tr>
</tbody>
</table>
<p>上面这个表格很清晰地说明了原作者划分数据的方法.</p>
<h3 id="源码分析-1">4.1.1. 源码分析</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#dataset3存放table3 的数据</span></div><div class="line">dataset3 = off_test </div><div class="line"></div><div class="line"><span class="comment">#feature3存放：筛出off_train中，以下四种情况：</span></div><div class="line"><span class="comment">#消费日期data在20160315-20160630的，</span></div><div class="line"><span class="comment">#或消费日期为空且领券日期在20160315-20160630的，</span></div><div class="line">feature3 = off_train[</div><div class="line">((off_train.date&gt;=<span class="string">'20160315'</span>)&amp;(off_train.date&lt;=<span class="string">'20160630'</span>))</div><div class="line">|((off_train.date==<span class="string">'null'</span>)&amp;(off_train.date_received&gt;=<span class="string">'20160315'</span>)&amp;(off_train.date_received&lt;=<span class="string">'20160630'</span>))]</div><div class="line"></div><div class="line"><span class="comment">#dataset2存放：从off_train筛出：领券时期在20160515-20160615之间的</span></div><div class="line">dataset2 = off_train[</div><div class="line">(off_train.date_received&gt;=<span class="string">'20160515'</span>)&amp;off_train.date_received&lt;=<span class="string">'20160615'</span>)]</div><div class="line"></div><div class="line"><span class="comment">#feature2存放：从off_train筛出：</span></div><div class="line"><span class="comment">#消费日期在20160201-20160514的，</span></div><div class="line"><span class="comment">#或领券日期在20160201-20160514但没有消费的</span></div><div class="line">feature2 = off_train[(off_train.date&gt;=<span class="string">'20160201'</span>)&amp;(off_train.date&lt;=<span class="string">'20160514'</span>)|((off_train.date==<span class="string">'null'</span>)&amp;(off_train.date_received&gt;=<span class="string">'20160201'</span>)&amp;(off_train.date_received&lt;=<span class="string">'20160514'</span>))]</div><div class="line"></div><div class="line"><span class="comment">#dataset1存放：从off_train筛出： 领券日期在20160414-20160514的</span></div><div class="line">dataset1 = off_train[(off_train.date_received&gt;=<span class="string">'20160414'</span>)&amp;(off_train.date_received&lt;=<span class="string">'20160514'</span>)]</div><div class="line"></div><div class="line"><span class="comment">#feature1存放：从off_train筛出：</span></div><div class="line"><span class="comment">#消费日期在20160101-20160413的，或</span></div><div class="line"><span class="comment">#领券日期在20160101-20160413但没有消费的</span></div><div class="line">feature1 = off_train[(off_train.date&gt;=<span class="string">'20160101'</span>)&amp;(off_train.date&lt;=<span class="string">'20160413'</span>)|((off_train.date==<span class="string">'null'</span>)&amp;(off_train.date_received&gt;=<span class="string">'20160101'</span>)&amp;(off_train.date_received&lt;=<span class="string">'20160413'</span>))]</div></pre></td></tr></table></figure>
<h2 id="其他特征">4.2. 其他特征</h2><h3 id="other-feature3">4.2.1. other_feature3</h3><table>
<thead>
<tr>
<th></th>
<th style="text-align:right">内容（都是来自测试集dataset3的数据）</th>
</tr>
</thead>
<tbody>
<tr>
<td>t</td>
<td style="text-align:right">每个用户使用优惠券的总次数</td>
</tr>
<tr>
<td>t1</td>
<td style="text-align:right">每个用户使用不同优惠券的次数</td>
</tr>
<tr>
<td>t2</td>
<td style="text-align:right">每个用户使用某张优惠券（使用次数大于1次）的首次和末次使用时间</td>
</tr>
<tr>
<td>t3</td>
<td style="text-align:right">每个用户用优惠券date；本优惠券首、末次间隔；本优惠券首/末次使用date</td>
</tr>
<tr>
<td>t4</td>
<td style="text-align:right">每个用户每天使用优惠券的次数</td>
</tr>
<tr>
<td>t5</td>
<td style="text-align:right">每个用户每天使用每张优惠券的次数</td>
</tr>
<tr>
<td>t6</td>
<td style="text-align:right">用户使用每张优惠券的date，不同date用冒号分隔</td>
</tr>
<tr>
<td>t7</td>
<td style="text-align:right">用户使用每张券的时间，以及和前、后一张券的时间间隔</td>
</tr>
</tbody>
</table>
<p>文件名：data/other_feature3.csv</p>
<p>格式：user_id,coupon_id,this_month_user_receive_same_coupon_count,this_month_user_receive_all_coupon_count,date_received,this_month_user_receive_same_coupon_lastone,this_month_user_receive_same_coupon_firstone,this_day_user_receive_all_coupon_count,this_day_user_receive_same_coupon_count,day_gap_before,day_gap_after</p>
<p>解释：用户id,优惠券id,本月用户使用本券次数，本月用户使用所有券次数，使用时间，本月用户使用本券末次时间、首次时间，本日用户用券总数，本日用户用本券总数，上次用本券间隔，下次用本券间隔</p>
<h4 id="源码分析-2">4.2.1.1. 源码分析</h4><p>t:计算每个用户使用优惠券的总次数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#将测试集dataset3的userid存在t中</span></div><div class="line">t = dataset3[[<span class="string">'user_id'</span>]]</div><div class="line"><span class="comment">#给t添加一个列，列名是this_month_user_receive_all_coupon_count，值都是1</span></div><div class="line">t[<span class="string">'this_month_user_receive_all_coupon_count'</span>] = <span class="number">1</span></div><div class="line"><span class="comment">#按照user_id分组，将user_id重复的项目的this_month_user_receive_all_coupon_count相加，然后进行reset_index</span></div><div class="line"><span class="comment">#其实就是算出每个用户使用优惠券的总次数</span></div><div class="line">t = t.groupby(<span class="string">'user_id'</span>).agg(<span class="string">'sum'</span>).reset_index()</div></pre></td></tr></table></figure>
<p>t1:统计每个用户，使用不同优惠券的次数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">t1 = dataset3[[<span class="string">'user_id'</span>,<span class="string">'coupon_id'</span>]]</div><div class="line">t1[<span class="string">'this_month_user_receive_same_coupon_count'</span>] = <span class="number">1</span></div><div class="line"><span class="comment">#按照user_id和coupon_id进行分组</span></div><div class="line"><span class="comment">#统计每个用户，使用不同优惠券的次数</span></div><div class="line">t1 = t1.groupby([<span class="string">'user_id'</span>,<span class="string">'coupon_id'</span>]).agg(<span class="string">'sum'</span>).reset_index()</div></pre></td></tr></table></figure>
<p>t2:找出每个人，消费每个券的时间，并用冒号分隔例如：<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-09-20-10-27.png" alt=""> </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">t2 = dataset3[[<span class="string">'user_id'</span>,<span class="string">'coupon_id'</span>,<span class="string">'date_received'</span>]]</div><div class="line">t2.date_received = t2.date_received.astype(<span class="string">'str'</span>)</div><div class="line"><span class="comment"># 按照user_id','coupon_id排序后，提出来date_received，进行agg运算</span></div><div class="line"><span class="comment"># agg运算：用冒号连接起来</span></div><div class="line">t2 = t2.groupby([<span class="string">'user_id'</span>,<span class="string">'coupon_id'</span>])[<span class="string">'date_received'</span>].agg(<span class="keyword">lambda</span> x:<span class="string">':'</span>.join(x)).reset_index()</div></pre></td></tr></table></figure>
<p>t2:每个用户使用某张优惠券（使用次数大于1次）的首次和末次使用时间</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#apply会返回每个优惠券的使用次数</span></div><div class="line">t2[<span class="string">'receive_number'</span>] = t2.date_received.apply(<span class="keyword">lambda</span> s:len(s.split(<span class="string">':'</span>)))</div><div class="line"><span class="comment">#筛出使用次数大于1次的数据</span></div><div class="line">t2 = t2[t2.receive_number&gt;<span class="number">1</span>]</div><div class="line"><span class="comment">#对max_date_received赋值为最近一次的使用时间</span></div><div class="line">t2[<span class="string">'max_date_received'</span>] = t2.date_received.apply(<span class="keyword">lambda</span> s:max([int(d) <span class="keyword">for</span> d <span class="keyword">in</span> s.split(<span class="string">':'</span>)]))</div><div class="line"><span class="comment">#对min_date_received赋值为最早一次的使用时间</span></div><div class="line">t2[<span class="string">'min_date_received'</span>] = t2.date_received.apply(<span class="keyword">lambda</span> s:min([int(d) <span class="keyword">for</span> d <span class="keyword">in</span> s.split(<span class="string">':'</span>)]))</div><div class="line"><span class="comment"># 重新定义t2为以下项目</span></div><div class="line">t2 = t2[[<span class="string">'user_id'</span>,<span class="string">'coupon_id'</span>,<span class="string">'max_date_received'</span>,<span class="string">'min_date_received'</span>]]</div></pre></td></tr></table></figure>
<p>t3:每个用户使用优惠券的时间、本次优惠券与首次使用的间隔、末次使用的间隔</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">t3 = dataset3[[<span class="string">'user_id'</span>,<span class="string">'coupon_id'</span>,<span class="string">'date_received'</span>]]</div><div class="line"><span class="comment">#merge，将两个数据集合并</span></div><div class="line"><span class="comment">#将t2和t3在['user_id','coupon_id']上进行左帧合并，即根据t3合并t2的user_id','coupon_id</span></div><div class="line"><span class="comment">#t2[['user_id','coupon_id','max_date_received','min_date_received']]</span></div><div class="line"><span class="comment">#t3[['user_id','coupon_id','date_received']]</span></div><div class="line"><span class="comment">#因此合并方式为：找到每个用户每张优惠券的消费时间和对应券的max_date_received与min_date_received</span></div><div class="line">t3 = pd.merge(t3,t2,on=[<span class="string">'user_id'</span>,<span class="string">'coupon_id'</span>],how=<span class="string">'left'</span>)</div><div class="line"><span class="comment">#t3的this_month_user_receive_same_coupon_lastone项目设置为:此用户消费本张优惠券与最近一次消费本张优惠券的间隔</span></div><div class="line"></div><div class="line">t3 = t3.apply(pd.to_numeric, args=(<span class="string">'coerce'</span>,))</div><div class="line">t3[<span class="string">'this_month_user_receive_same_coupon_lastone'</span>] = t3.max_date_received - t3.date_received</div><div class="line"><span class="comment">#此用户消费本张优惠券与第一次消费本张优惠券的间隔</span></div><div class="line">t3[<span class="string">'this_month_user_receive_same_coupon_firstone'</span>] = t3.date_received - t3.min_date_received</div></pre></td></tr></table></figure>
<p>上面跑到<code>t3[&#39;this_month_user_receive_same_coupon_lastone&#39;] = t3.max_date_received - t3.date_received</code>的时候会出现<code>TypeError: unsupported operand type(s) for -: &#39;float&#39; and &#39;str&#39;</code>.</p>
<p>在执行这句话之前，我们看到<code>t3.date_received</code>的类型为<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-09-22-39-21.png" alt=""> </p>
<p>因此我们需要将数据类型先转换为float。在网上查到本方法对本代码有效（暂不知原因）。<a href="http://stackoverflow.com/questions/14450020/unsupported-operand-in-pandas-dataframe-operation" target="_blank" rel="external">参考文献</a></p>
<p><code>t3 = t3.apply(pd.anumeric, args=(&#39;coerce&#39;,))</code></p>
<p>把这句话加上后，我们看到<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-09-22-43-02.png" alt=""> </p>
<p>定义函数is_firstlastone判断优惠券是否是末次使用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_firstlastone</span><span class="params">(x)</span>:</span></div><div class="line">    <span class="keyword">if</span> x==<span class="number">0</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">1</span></div><div class="line">    <span class="keyword">elif</span> x&gt;<span class="number">0</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">0</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">-1</span> <span class="comment">#those only receive once</span></div></pre></td></tr></table></figure>
<p>t3:加上两个数据，…</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">t3.this_month_user_receive_same_coupon_lastone = t3.this_month_user_receive_same_coupon_lastone.apply(is_firstlastone)</div><div class="line">t3.this_month_user_receive_same_coupon_firstone = t3.this_month_user_receive_same_coupon_firstone.apply(is_firstlastone)</div><div class="line">t3 = t3[[<span class="string">'user_id'</span>,<span class="string">'coupon_id'</span>,<span class="string">'date_received'</span>,<span class="string">'this_month_user_receive_same_coupon_lastone'</span>,<span class="string">'this_month_user_receive_same_coupon_firstone'</span>]]</div></pre></td></tr></table></figure>
<p>后面套路差不多，此处不再继续分析。主要结论已经总结在上表中。</p>
<h1 id="合并特征">5. 合并特征</h1><h2 id="生成训练集">5.1. 生成训练集</h2><pre><code>coupon2 = pd.read_csv(&apos;data/coupon2_feature.csv&apos;)
merchant2 = pd.read_csv(&apos;data/merchant2_feature.csv&apos;)
user2 = pd.read_csv(&apos;data/user2_feature.csv&apos;)
user_merchant2 = pd.read_csv(&apos;data/user_merchant2.csv&apos;)
other_feature2 = pd.read_csv(&apos;data/other_feature2.csv&apos;)
#dataset2是根据 优惠券特征 合并商户、用户、用户-商户、其他特征
dataset2 = pd.merge(coupon2,merchant2,on=&apos;merchant_id&apos;,how=&apos;left&apos;)
dataset2 = pd.merge(dataset2,user2,on=&apos;user_id&apos;,how=&apos;left&apos;)
dataset2 = pd.merge(dataset2,user_merchant2,on=[&apos;user_id&apos;,&apos;merchant_id&apos;],how=&apos;left&apos;)
dataset2 = pd.merge(dataset2,other_feature2,on=[&apos;user_id&apos;,&apos;coupon_id&apos;,&apos;date_received&apos;],how=&apos;left&apos;)
dataset2.drop_duplicates(inplace=True)
print dataset2.shape
dataset2.user_merchant_buy_total = dataset2.user_merchant_buy_total.replace(np.nan,0)
dataset2.user_merchant_any = dataset2.user_merchant_any.replace(np.nan,0)
dataset2.user_merchant_received = dataset2.user_merchant_received.replace(np.nan,0)
dataset2[&apos;is_weekend&apos;] = dataset2.day_of_week.apply(lambda x:1 if x in (6,7) else 0)
weekday_dummies = pd.get_dummies(dataset2.day_of_week)
weekday_dummies.columns = [&apos;weekday&apos;+str(i+1) for i in range(weekday_dummies.shape[1])]
dataset2 = pd.concat([dataset2,weekday_dummies],axis=1)
dataset2[&apos;label&apos;] = dataset2.date.astype(&apos;str&apos;) + &apos;:&apos; +  dataset2.date_received.astype(&apos;str&apos;)
dataset2.label = dataset2.label.apply(get_label)
dataset2.drop([&apos;merchant_id&apos;,&apos;day_of_week&apos;,&apos;date&apos;,&apos;date_received&apos;,&apos;coupon_id&apos;,&apos;coupon_count&apos;],axis=1,inplace=True)
dataset2 = dataset2.replace(&apos;null&apos;,np.nan)
dataset2.to_csv(&apos;data/dataset2.csv&apos;,index=None)


coupon1 = pd.read_csv(&apos;data/coupon1_feature.csv&apos;)
merchant1 = pd.read_csv(&apos;data/merchant1_feature.csv&apos;)
user1 = pd.read_csv(&apos;data/user1_feature.csv&apos;)
user_merchant1 = pd.read_csv(&apos;data/user_merchant1.csv&apos;)
other_feature1 = pd.read_csv(&apos;data/other_feature1.csv&apos;)
dataset1 = pd.merge(coupon1,merchant1,on=&apos;merchant_id&apos;,how=&apos;left&apos;)
dataset1 = pd.merge(dataset1,user1,on=&apos;user_id&apos;,how=&apos;left&apos;)
dataset1 = pd.merge(dataset1,user_merchant1,on=[&apos;user_id&apos;,&apos;merchant_id&apos;],how=&apos;left&apos;)
dataset1 = pd.merge(dataset1,other_feature1,on=[&apos;user_id&apos;,&apos;coupon_id&apos;,&apos;date_received&apos;],how=&apos;left&apos;)
dataset1.drop_duplicates(inplace=True)
print dataset1.shape

dataset1.user_merchant_buy_total = dataset1.user_merchant_buy_total.replace(np.nan,0)
dataset1.user_merchant_any = dataset1.user_merchant_any.replace(np.nan,0)
dataset1.user_merchant_received = dataset1.user_merchant_received.replace(np.nan,0)
dataset1[&apos;is_weekend&apos;] = dataset1.day_of_week.apply(lambda x:1 if x in (6,7) else 0)
weekday_dummies = pd.get_dummies(dataset1.day_of_week)
weekday_dummies.columns = [&apos;weekday&apos;+str(i+1) for i in range(weekday_dummies.shape[1])]
dataset1 = pd.concat([dataset1,weekday_dummies],axis=1)
dataset1[&apos;label&apos;] = dataset1.date.astype(&apos;str&apos;) + &apos;:&apos; +  dataset1.date_received.astype(&apos;str&apos;)
dataset1.label = dataset1.label.apply(get_label)
dataset1.drop([&apos;merchant_id&apos;,&apos;day_of_week&apos;,&apos;date&apos;,&apos;date_received&apos;,&apos;coupon_id&apos;,&apos;coupon_count&apos;],axis=1,inplace=True)
dataset1 = dataset1.replace(&apos;null&apos;,np.nan)
dataset1.to_csv(&apos;data/dataset1.csv&apos;,index=None)
</code></pre><h2 id="生成预测集">5.2. 生成预测集</h2><pre><code>coupon3 = pd.read_csv(&apos;data/coupon3_feature.csv&apos;)
merchant3 = pd.read_csv(&apos;data/merchant3_feature.csv&apos;)
user3 = pd.read_csv(&apos;data/user3_feature.csv&apos;)
user_merchant3 = pd.read_csv(&apos;data/user_merchant3.csv&apos;)
other_feature3 = pd.read_csv(&apos;data/other_feature3.csv&apos;)
dataset3 = pd.merge(coupon3,merchant3,on=&apos;merchant_id&apos;,how=&apos;left&apos;)
dataset3 = pd.merge(dataset3,user3,on=&apos;user_id&apos;,how=&apos;left&apos;)
dataset3 = pd.merge(dataset3,user_merchant3,on=[&apos;user_id&apos;,&apos;merchant_id&apos;],how=&apos;left&apos;)
dataset3 = pd.merge(dataset3,other_feature3,on=[&apos;user_id&apos;,&apos;coupon_id&apos;,&apos;date_received&apos;],how=&apos;left&apos;)
dataset3.drop_duplicates(inplace=True)
print dataset3.shape

dataset3.user_merchant_buy_total = dataset3.user_merchant_buy_total.replace(np.nan,0)
dataset3.user_merchant_any = dataset3.user_merchant_any.replace(np.nan,0)
dataset3.user_merchant_received = dataset3.user_merchant_received.replace(np.nan,0)
dataset3[&apos;is_weekend&apos;] = dataset3.day_of_week.apply(lambda x:1 if x in (6,7) else 0)
weekday_dummies = pd.get_dummies(dataset3.day_of_week)
weekday_dummies.columns = [&apos;weekday&apos;+str(i+1) for i in range(weekday_dummies.shape[1])]
dataset3 = pd.concat([dataset3,weekday_dummies],axis=1)
dataset3.drop([&apos;merchant_id&apos;,&apos;day_of_week&apos;,&apos;coupon_count&apos;],axis=1,inplace=True)
dataset3 = dataset3.replace(&apos;null&apos;,np.nan)
dataset3.to_csv(&apos;data/dataset3.csv&apos;,index=None)
</code></pre><h1 id="附录">6. 附录</h1><h2 id="查看dataFrame类型的内容">6.1. 查看dataFrame类型的内容</h2><p>见pandas 文档之 10 minutes to pandas — viewing data</p>
<p>用t.values,t.columns</p>
<h2 id="lambda-functions">6.2. lambda functions</h2><p>源代码中有一行<code>t2.groupby([&#39;user_id&#39;,&#39;coupon_id&#39;])[&#39;date_received&#39;].agg(lambda x:&#39;:&#39;.join(x)).reset_index()</code></p>
<p><a href="http://www.diveintopython.net/power_of_introspection/lambda_functions.html" target="_blank" rel="external">官方文档</a></p>
<p><code>lambda functions</code>是python的一个function.<br>用例：</p>
<pre><code>#函数f(x)
&gt;&gt;&gt; def f(x):
...     return x*2
...
&gt;&gt;&gt; f(3) #输入x=3     
6 #输出6

#f(x)等价于：
&gt;&gt;&gt; g = lambda x: x*2  1
&gt;&gt;&gt; g(3)
6
#f(x)还等价于：
&gt;&gt;&gt; (lambda x: x*2)(3) 2
6
</code></pre><p>作者代码中，有一行<br><code>lambda x:&#39;:&#39;.join(x)</code>即将前后叠加,用<code>:</code>连接<br><code>t2.groupby([&#39;user_id&#39;,&#39;coupon_id&#39;])[&#39;date_received&#39;].agg(lambda x:&#39;:&#39;.join(x)).reset_index()</code>意思是将数据集先按照user_id’,’coupon_id排序，然后对date_received进行用:连接一起来</p>
<p>例如，输入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">df = pd.DataFrame(&#123;<span class="string">'A'</span> : [<span class="string">'foo'</span>, <span class="string">'bar'</span>, <span class="string">'foo'</span>, <span class="string">'bar'</span>,</div><div class="line">                            <span class="string">'foo'</span>, <span class="string">'bar'</span>, <span class="string">'foo'</span>, <span class="string">'foo'</span>],</div><div class="line">                            <span class="string">'B'</span> : [<span class="string">'one'</span>, <span class="string">'one'</span>, <span class="string">'two'</span>, <span class="string">'three'</span>,</div><div class="line">                             <span class="string">'two'</span>, <span class="string">'two'</span>, <span class="string">'one'</span>, <span class="string">'three'</span>],</div><div class="line">                            <span class="string">'C'</span> : np.random.randn(<span class="number">8</span>),</div><div class="line">                            <span class="string">'D'</span> : np.random.randn(<span class="number">8</span>)&#125;)</div></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>i</th>
<th style="text-align:right">A</th>
<th style="text-align:right">B</th>
<th style="text-align:right">C</th>
<th style="text-align:right">D</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td style="text-align:right">foo</td>
<td style="text-align:right">one</td>
<td style="text-align:right">0.754147</td>
<td style="text-align:right">0.912176</td>
</tr>
<tr>
<td>1</td>
<td style="text-align:right">bar</td>
<td style="text-align:right">one</td>
<td style="text-align:right">1.414635</td>
<td style="text-align:right">-0.760638</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:right">foo</td>
<td style="text-align:right">two</td>
<td style="text-align:right">-0.142930</td>
<td style="text-align:right">-1.290766</td>
</tr>
<tr>
<td>3</td>
<td style="text-align:right">bar</td>
<td style="text-align:right">three</td>
<td style="text-align:right">1.196999</td>
<td style="text-align:right">1.647513</td>
</tr>
<tr>
<td>4</td>
<td style="text-align:right">foo</td>
<td style="text-align:right">two</td>
<td style="text-align:right">-0.261663</td>
<td style="text-align:right">1.284779</td>
</tr>
<tr>
<td>5</td>
<td style="text-align:right">bar</td>
<td style="text-align:right">two</td>
<td style="text-align:right">1.622070</td>
<td style="text-align:right">1.685648</td>
</tr>
<tr>
<td>6</td>
<td style="text-align:right">foo</td>
<td style="text-align:right">one</td>
<td style="text-align:right">1.478855</td>
<td style="text-align:right">-0.229636</td>
</tr>
</tbody>
</table>
<pre><code>df3 = df.groupby([&apos;A&apos;])[&apos;B&apos;].agg(lambda x:&apos;:&apos;.join(x)).reset_index()
</code></pre><p>输出：</p>
<table>
<thead>
<tr>
<th>i</th>
<th style="text-align:right">A</th>
<th style="text-align:right">B</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td style="text-align:right">bar</td>
<td style="text-align:right"><code>one:three:two</code></td>
</tr>
<tr>
<td>1</td>
<td style="text-align:right">foo</td>
<td style="text-align:right"><code>one:two:two:one:three</code></td>
</tr>
</tbody>
</table>
<h2 id="pandas的merge的how参数">6.3. pandas的merge的how参数</h2><p>原代码出现了<code>t3 = pd.merge(t3,t2,on=[&#39;user_id&#39;,&#39;coupon_id&#39;],how=&#39;left&#39;)</code></p>
<p>how参数主要决定了哪一个keys会被包含在结果表中。它的值有四种可能性：<code>left,right,outer,inner</code>。我们主要看<code>left和right</code></p>
<p>how=’left’:遍历left表，找与right一样的，依次放入行。 如果没有，则设为NAN</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-09-20-34-44.png" alt=""> </p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-09-20-33-13.png" alt=""> </p>
<p>因此<code>t3 = pd.merge(t3,t2,on=[&#39;user_id&#39;,&#39;coupon_id&#39;],how=&#39;left&#39;)</code>的意思是：</p>
<p>根据t3合并t2的user_id’,’coupon_id</p>
]]></content>
      
        <categories>
            
            <category> o2o优惠券使用预测 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[梯度提升决策树 AdaBoost DecisonTree]]></title>
      <url>/2017/03/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E5%86%B3%E7%AD%96%E6%A0%91%20AdaBoost%20DecisonTree/</url>
      <content type="html"><![CDATA[<p>上一节中介绍了《随机森林算法》，该算法使用bagging的方式作出一些决策树来，同时在决策树的学习过程中加入了更多的随机因素。该模型可以自动做到验证过程同时还可以进行特征选择。 </p>
<p>本节，我们结合<code>AdaBoost+决策树</code>算法。</p>
<h1 id="AdaBoost决策树算法引入">1. AdaBoost决策树算法引入</h1><p>在AdaBoost中每一轮迭代，都会给数据更新一个权重，利用这个权重，我们学习得到一个g，在这里我们得到一个决策树，最终利用线性组合的方式得到多个决策树组成的G。</p>
<p>=======================================<br><strong>AdaBoost-DTree(DD)</strong><br>对于t=1,2,…,T，循环执行：</p>
<ul>
<li>更新数据的权重$u(t)$；</li>
<li>通过决策树算法$DTree(D,u(t))$得到$g_t$；</li>
<li>计算$g_t$的投票权重$α_t$。</li>
</ul>
<p>返回$G=LinearHypo({(g_t,α_t)})$。</p>
<p>========================================</p>
<p><strong>问题</strong>：如何要在决策树中，加入权重<code>ut</code></p>
<p><strong>解决方案</strong>有两种：</p>
<ul>
<li>一种是通过算法加权，在计算Ein的地方嵌入权重计算，比如AdaBoost采用的最小化加权误差；</li>
<li>另一种方法是将算法当成黑盒不变更，通过数据集加权，根据权重在bootstrap时“复制”数据，也就是加权的重采样。</li>
</ul>
<p>AdaBoost决策树通常用后一种，即：$AdaBoost+sampling∝u^{(t)}+DTree(D_t) $</p>
<h1 id="加权的决策树算法-Weighted-Decision-Tree-Algorithm">2. 加权的决策树算法(Weighted Decision Tree Algorithm)</h1><p> 之前含有权重的算法中，我们在误差估计中加入了权重<code>u</code>：</p>
<p> <img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-09-46-47.png" alt=""> </p>
<p>为了对决策树中加入权重，且不改变原算法的健壮性，我们设法对输入的<code>数据</code>进行<code>权重加成</code>。而权重等效于数据的重复次数。根据这种方式得到一组新的数据，那么这组新的数据中的比例大概就是和权重的比例呈正比的，也就是说它能够表达权重对于数据的意义。</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-09-54-14.png" alt=""> </p>
<p>在AdaBoost-DTree中，为了简单起见，我们不去改变AdaBoost的框架，也不去修改决策树的内部细节，而只是通过基于权重的训练数据的采样来实现。</p>
<p>即如下图所示的：AdaBoost提升决策树=AdaBoost提升+关于权重u的数据抽样+决策树</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-09-54-50.png" alt=""> </p>
<h2 id="弱决策树算法">2.1. 弱决策树算法</h2><p>在AdaBoost算法中，我们<strong>通过错误率<code>εt</code>来计算单个的g的权重αt</strong>，那么如果我们使用决策树作为g的时候，g是一个完全长成的树，该树对整个数据集进行细致的切分导致Ein=0，那么这使得εt=0，但计算得到的权重αt会变成无限大。</p>
<p>其意义是，如果使用一个能力很强的树作为g的话，那么该算法会赋予该树无限大的权重或票数，最终得到了一棵“独裁”的树（因为AdaBoost的哲学意义是庶民政治，就是集中多方的意见，及时有的意见可能是错误的），违背了AdaBoost的宗旨。</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-09-59-58.png" alt=""> </p>
<p>上面的问题出在使用了所有的数据和让树完全长成这两方面。针对这两个问题，我们要通过<code>剪枝</code>和<code>部分训练数据</code>得到一个弱一点的树。<br>所以实际上，AdaBoost-DTree是通过sampling的方式得到部分训练数据，通过剪枝的方式限制树的高度，得到弱一点的决策树。</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-10-19-02.png" alt=""> </p>
<p>下面介绍最弱的决策树。</p>
<h2 id="决策桩，AdaBoost-Stump">2.2. 决策桩，AdaBoost-Stump</h2><p>什么样是树才是弱决策树呢？<br>我们这里限制这棵树只有一层（即它仅基于单个特征来做决策），即决策桩(Decision Stump)。这样我们需要让CART树的不纯度(impurity)尽可能低，学习一个决策桩。</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-10-21-14.png" alt=""> </p>
<p>所以，使用决策桩作为弱分类器的AdaBoost称为AdaBoost-Stump，它是一种特殊的AdaBoost-DTree。</p>
<h2 id="决策桩的实现">2.3. 决策桩的实现</h2><p>本节主要参考《机器学习实战》p120</p>
<h3 id="实验数据adaboost-py">2.3.1. 实验数据adaboost.py</h3><pre><code>from numpy import *
def loadSimpData():
    dataMat = matrix([[1.,2.1],[2.,1.1],[1.3,1.],[1.,1.],[2.,1.]])
    classLabels = [1.0,1.0,-1.0,-1.0,1.0]
    return dataMat,classLabels
</code></pre><h3 id="二分类的决策桩实现stump-py">2.3.2. 二分类的决策桩实现stump.py</h3><p>先导入数据</p>
<pre><code>import adaboost
dataMat,classLabels = adaboost.loadSimpData()
</code></pre><p>建立一个<code>buidStump()</code>函数，根据数据集，建立最佳单层决策树（只需要选择一个最好的特征即可）</p>
<pre><code>def buildStump(dataArr,classLabels,D):
    dataMatrix = mat(dataArr)
    labelMat = mat(classLabels).T # T是做转置
</code></pre><p><code>dataMatrix</code>形式为<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-16-16-29-28.png" alt=""><br><code>labelMat</code>形式为<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-16-16-29-39.png" alt=""> </p>
<p>先令一些变量，之后解释。</p>
<pre><code>m,n = shape(dataMatrix)
numSteps = 10.0#步长
bestStup = {}#最佳桩
bestClasEst = mat(zeros((m,1)))#最佳分类est
minError = inf
</code></pre><p>接下来需要对每个特征计算出一个阈值<code>threshVal</code>，根据阈值二分类。</p>
<pre><code>for i in range(n): # 遍历特征个数
    #为了确定threshVal，我们从本特征下的最小值到最大值分10 step进行依次测试
    rangeMin = dataMatrix[:,i].min();rangeMax = dataMatrix[:,i].max();
    stepSize = (rangeMax - rangeMin)/numSteps
    #下面对每个threshVal可能的值进行依次测试
    for j in range(-1,int(numSteps)+1):
        #然后应该开始比较大于阈值和小于阈值怎么怎么滴，为了增加代码的复用性，此处用一个循环来在大于和小于之间切换不等式
        for inequal in [&apos;lt&apos;,&apos;gt&apos;]:#lt=小于等于，gt=大于
            threshVal = (rangeMin + float(j)*stepSize)
            # 开始测试这个特征下这个阈值的二分类器好不好用
            predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)
            #计算本次分类的err
            errArr = mat(ones((m,1)))
            errArr[predictedVals==labelMat]=0
            #基于权重向量D计算权重
            weightedError = D.T*errArr
            if weightedError &lt; minError :
                minError = weightedError
                bestClasEst = predictedVals.copy()
                bestStump[&apos;dim&apos;] = i
                bestStump[&apos;thresh&apos;] = threshVal
                bestStump[&apos;ineq&apos;] = inequal
</code></pre><p>最后，返回最佳的决策桩，和误差</p>
<pre><code>return bestStump,minError,bestClasEst
</code></pre><h1 id="求解AdaBoost决策树">3. 求解AdaBoost决策树</h1><h2 id="AdaBoost的权重与投票分数的关系">3.1. AdaBoost的权重与投票分数的关系</h2><p>回顾AdaBoost算法：</p>
<p>从权重<code>ut</code>，通过<code>◆t</code>对<code>u(t+1)</code>进行修正，而两个公式可以合成为：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-14-35-34.png" alt=""> </p>
<p>如下图，接着我们将<code>u(t+1)</code>展开(表达为<code>u(1)乘以一坨</code>)，最终可以变成连加；<br>我们发现图中橘色部分<code>∑αt·gt(xn)</code>是G(x)的分数！它现在出现在Adaboost的权重表达式中；<br>我们称橘色<code>∑αt·gt(xn)</code>为<strong>投票分数(voting score)</strong>：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-14-38-40.png" alt=""> </p>
<p><strong>结论</strong>：AdaBoost里面每一个数据的权重，和<code>exp(-yn( 投票分数 on xn))</code>呈正比。即：<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-14-41-04.png" alt=""> </p>
<h2 id="投票分数-Voting-Score-和间隔-Margin-的关系">3.2. 投票分数(Voting Score)和间隔(Margin)的关系</h2><p>线性混合(linear blending)等价于将假设看做是特征转换的线性模型：</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-19-13-20.png" alt=""> </p>
<p>其中<code>αt·gt(xn)</code>如果换作是<code>wT·φ(xn)</code>可能就更清楚了，这与下面给出的在SVM中的margin表达式对比，我们可以明白投票分数<code>∑αt·gt(xn)</code>的物理意义，即可以看做是没有正规化的边界(margin)。</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-19-20-39.png" alt=""> </p>
<p>所以，<code>yn·(voting score)</code>是有符号的、没有正规化的边界距离，从这个角度来说，我们希望<code>yn·(voting score)</code>越大越好，因为这样的泛化能力越强。于是，<code>exp(-yn·(voting score))</code>越小越好，那么<code>un(T+1)</code>越小越好。</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-19-21-01.png" alt=""> </p>
<p><strong>结论</strong>：AdaBoost在迭代过程中，是让<code>∑un(t)</code>越来越小的过程，在这个过程中，逐渐达到SVM中最大分类间隔的效果。</p>
<h2 id="AdaBoost误差函数">3.3. AdaBoost误差函数</h2><p>上面解释到了，AdaBoost在迭代学习的过程，就是希望让<code>∑un(t)</code>越来越小的过程，那么我们<strong>新的目标</strong>就是最佳化权重和<code>∑un(T+1)</code>：</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-19-58-44.png" alt=""> </p>
<p>我们可以画出<code>0/1错误</code>和<code>AdaBoost误差函数err(s,y) = exp(-ys)</code>的函数曲线，我们发现AdaBoost的误差函数（称为exponential error measure）实际上也是0/1错误函数的上限函数，于是，<strong>我们可以通过最小化该函数来起到最佳化的效果</strong>。</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-19-59-15.png" alt=""> </p>
<h2 id="AdaBoost误差函数的梯度下降求解">3.4. AdaBoost误差函数的梯度下降求解</h2><p>本节目的————最小化AdaBoost的误差函数<code>Ein</code>：</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-19-58-44.png" alt=""> </p>
<p>这个任务比较麻烦，因为是Σ套着exp再套着Σ，因此需要一些前人的智慧了。</p>
<p>我们可以将<code>Ein</code>函数在所在点的附近做泰勒展开，我们就可以发现在该点的附近可以被梯度所描述，我们希望求一个最好的方向（最大梯度相反的方向），然后在该方向上走一小步，这样我们就可以做到比现在的函数效果好一点点，依次进行梯度下降，最终达到最小化误差函数的效果。</p>
<p>原始的梯度下降法：</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-20-02-45.png" alt=""> </p>
<p>为了模仿梯度下降的方法，假设前面已经AdaBoost完t-1轮了，现在要求的是一个函数gt(x)（或者称为h(x)）。</p>
<p>在第t轮，我们沿着函数h(x)的方向走$η$的步长，可以使得目标函数迅速往min的方向走。如下：现在我们把<code>函数gt</code>当做向量，希望去找到这个<code>gt</code>（这里函数方向gt和上面介绍的最大梯度的方向向量没有什么差别，只是表示方式有所不同而已）。</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-20-03-24.png" alt=""> </p>
<p>我们解释一下上面的公式：</p>
<ul>
<li>(1、2行)由于前面已经执行完了<code>t-1</code>轮，因此可以把式子化简一下，把一些项目合并成<code>ut</code>的函数形式</li>
<li>(3行左) 将<code>exp(-y·η·h(xn))</code>在原点xn=0点的泰勒展开，进一步化简得到得到<code>(1-yn·η·h(xn))</code>；（这里为什么要用0这个位置的taylor展开呢，可以理解成h(x)只是沿着原来的Σ1,t-1(alphat*g’(xn)这个函数，挪动的了一小步；这一小步，就意味着变化很小，变化很小甚至接近0，因此就可以在0点taylor展开。不晓得这种理解是否正确，意会吧）</li>
<li>(3行右) 然后拆成两部分<code>∑un(t)</code>和<code>η·∑un(t)·yn·h(xn)</code>，第一部分是Ein，第二部分就是要最小化的目标。<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-20-04-07.png" alt=""> </li>
</ul>
<p>到此，我们利用前人的智慧已经把目标函数给大大简化了，下面需要要求的东西有俩：</p>
<p>1）<code>h(x)</code>是啥？</p>
<p>2）<code>$η$</code>是啥？</p>
<h3 id="求h-x">3.4.1. 求h(x)</h3><p>我们对<code>∑un(t)·yn·h(xn)</code>整理一下，对于二元分类情形，我们把<code>yn</code>和<code>h(xn)</code>是否同号进行分别讨论：</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-20-04-29.png" alt=""> </p>
<p>上面的公式中，我们特意将<code>∑un(t)·yn·h(xn)</code>拆成<code>-∑un(t)</code>和<code>Ein(h)</code>的形式，这里最小化<code>Ein</code>对应于AdaBoost中的A（弱学习算法），好的弱学习算法就是对应于梯度下降的函数方向。</p>
<p><strong>结论</strong>：在AdaBoost的过程中，算法A就是good gt了！</p>
<h3 id="求最佳化步长-η">3.4.2. 求最佳化步长$η$</h3><p>我们要最小化Eada，需要找到好的函数方向gt，但是得打这个gt的代价有些大，梯度下降的过程中，每走一小步，就需要计算得到一个gt。如果转换一下思路，我们现在已经确定了好的gt，我们希望快速找到梯度下降的最低点，那么我们需要找到一个合适的最大步长η。<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-20-05-39.png" alt=""> </p>
<p>我们这里使用贪心算法来得到最大步长η，称为steepest decent for optimization。</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-20-05-54.png" alt=""> </p>
<p>让Eada对η求偏微分，得到最陡时候的ηt，我们发现这时ηt等于AdaBoost的αt。所以在AdaBoost中αt是在偷偷地做最佳化的工作。</p>
<p>核心在于EADA是怎么变成可对$η$求导的形式的：</p>
<p>EADA = u1t<em>exp(-$η$) + u2t</em>exp($η$)…</p>
<p>EADA1 = u1t<em>exp(-$η$) + ut2t</em>0 … （EADA1只考虑exp(-$η$)的项，其余的补上0）</p>
<p>EADA2 = u1t<em>0 + u2t </em> exp($η$) …（EADA2只考虑exp(+$η$)的项，其余的补上0）</p>
<p>则，EADA = EADA1 + EADA1 = (Σunt) <em> ( (1-epson)exp(-$η$) + epson</em>exp($η$) )</p>
<p>随后的求导步骤就是很自然的了，因此就验证了之前的结论，$η$t = sqrt( (1-epsont)/epsont) )就是最优的。前一次课直接给出了这个结论，并没有说为什么，这次算是给出了一个相对理论些的推导。</p>
<p><strong>结论</strong>：通过求解<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-15-13-25-13.png" alt=""><br>，我们得到最佳的<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-15-13-25-32.png" alt=""> </p>
<h3 id="小结">3.4.3. 小结</h3><p>在第二小节中，我们从另外一个角度介绍了AdaBoost算法，它其实是steepest gradient decent。</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-07-20-06-19.png" alt=""> </p>
<p>上面的式子很清楚了，我们将AdaBoost的误差函数看做是指数误差函数，AdaBoost就是在这个函数上一步一步做最佳化，每一步求得一个h，并将该h当做是gt，决定这个gt上面要走多长的距离ηt，最终得到这个gt的票数αt。</p>
<h1 id="AdaBoost决策树总结">4. AdaBoost决策树总结</h1><ol>
<li>AdaBoost本次的u(t+1)与<code>exp(-yn( 投票分数 on xn))</code>成正比</li>
<li>AdaBoost在迭代过程中，是让<code>∑un(t)</code>越来越小的过程，在这个过程中，逐渐达到SVM中最大分类间隔的效果</li>
<li>上目标与最小化误差函数<code>err(s,y) = exp(-ys)</code>等价</li>
<li>要使得<code>err(s,y)</code>最小，就需要求得<code>h(x)</code>和<code>η</code></li>
</ol>
<h1 id="参考文献">5. 参考文献</h1><ol>
<li><a href="http://qianjiye.de/2015/01/gradient-boosted-decision-tree" target="_blank" rel="external">梯度提升决策树</a></li>
<li><a href="http://www.cnblogs.com/xbf9xbf/p/4706150.html" target="_blank" rel="external">【Gradient Boosted Decision Tree】林轩田机器学习技术</a></li>
<li>《机器学习实战》</li>
</ol>
]]></content>
      
        <categories>
            
            <category> 机器学习算法 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[提升方法 AdaBoost]]></title>
      <url>/2017/03/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%20AdaBoost/</url>
      <content type="html"><![CDATA[<h1 id="Boosting">1. Boosting</h1><p>提升（boosting）：从弱学习算法（正确率低）出发，反复学习，得到一系列弱分类器（基本分类器），然后组合这些弱分类器，构成一个强分类器。（三个臭皮匠顶个诸葛亮）</p>
<p>提升（boosting）方法需要解决的问题：</p>
<ul>
<li>如何获得更多的弱分类器————如何改变训练数据的权值或概率分布————提高被前一轮错误分类样本的权值，降低被正确分类样本的权值。</li>
<li>如何将弱分类器合成一个强分类器————加权多数表决：加大误差小的分类器的权值，减小误差大的分类器的权值。</li>
</ul>
<p>提升方法有很多，最具代表性的就是AdaBoost算法。</p>
<h1 id="AdaBoost算法">2. AdaBoost算法</h1><p>假设给定一个二分类训练数据集$T=\{(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\}$</p>
<p>其中，每个样本点由<code>实例+标记</code>组成</p>
<p>实例：$x_i\in X \subseteq R^n $</p>
<p>标记：$y_i \in Y={-1,+1}$</p>
<p><code>AdaBoost</code>利用以下算法，从训练数据中学习一系列弱分类器或基本分类器，并将这些弱分类器线性组合成一个强分类器</p>
<p><strong>输入</strong>:</p>
<ul>
<li>数据集$T=\{(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\}$</li>
<li>弱学习算法</li>
</ul>
<p><strong>输出</strong>：最终分类器$G(x)$</p>
<p><strong>步骤</strong>：</p>
<ol>
<li>初始化训练数据的权值(每个都设为1/N)：</li>
</ol>
<p>$$D_1=(w_{11},w_{1i},…,w_{1N}),w_{1i}=\frac{1}{N},i=1,2,…,N$$</p>
<ol>
<li>对$m=1,2,…,M$:</li>
</ol>
<ul>
<li>使用带权值$D_m$的训练集学习，得到基本分类器$G_m(x):X\rightarrow \{-1,+1\}$</li>
<li>计算$G_m(x)$在训练集上的分类误差率：$$e_m=P(G_m(x_i)\neq y_i)=\sum_{n=1}^N w_{mi}I(G_m(x_i)\neq y_i)$$</li>
</ul>
<ol>
<li>计算$G_m(x)$的系数：$$\alpha_m=\frac{1}{2}log\frac{1-e_m}{e_m}$$</li>
<li>更新训练集权值：</li>
</ol>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-06-22-49-14.png" alt=""> </p>
<ol>
<li>构建基本分类器的线性组合：</li>
</ol>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-06-22-49-54.png" alt=""> </p>
<h1 id="AdaBoost算法推导">3. AdaBoost算法推导</h1><h2 id="Boot-strapping">3.1. Boot strapping</h2><p>Boot strapping，拔靴法：利用有限的样本资料经由<strong>多次重复抽样</strong>，重新建立起足以代表母体样本分布之新样本。</p>
<p>多次之后，得到一个非线性的结果（黑色线）<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-17-37-57.png" alt=""> </p>
<h2 id="基本算法引入权重">3.2. 基本算法引入权重</h2><p>已知：一笔数据$D=\{(x_1,y_1),(x_2,y_2),(x_3,y_3),(x_4,y_4)\}$<br>根据<code>D</code>算出来的输入误差Ein为：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-19-29-41.png" alt=""> </p>
<p>通过Boot strapping，得到新的一笔数据$D_t=\{(x_1,y_1),(x_1,y_1),(x_2,y_2),(x_4,y_4)\}$<br>对应地，根据<code>Dt</code>算出来的Ein为：<br>（增加一个权重u即可）<br><code>u1=2,u2=1,u3=0,u4=1</code><br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-19-31-04.png" alt=""> </p>
<p><strong>结论：每一个bootstrapping得到了一个权重<code>u</code></strong></p>
<h2 id="优化权重u">3.3. 优化权重u</h2><h3 id="优化原理">3.3.1. 优化原理</h3><ul>
<li>每一个bootstrapping得到了一个权重`u。</li>
<li>为了综合得到更好的g,则需要抽取的数据集得到的g尽量地不同。</li>
<li>改变<code>u</code>，使得<code>g</code>差异更大，才会更好地改进最终结果</li>
</ul>
<p>得到g差异很大的方法：</p>
<ul>
<li>第一轮$u_n^t$时，得到$g_t$<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-19-39-48.png" alt=""> </li>
<li>第二轮，选择一个 在$g_t$ 表现不好的 $u_n^{t+1}$  ，得到 $g_{t+1}$ <img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-19-41-02.png" alt=""><br>– 表现不好的定义：<br>— 将$u_n^{t+1}$作用在$g_t$上，得到一个归一化的错误率<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-19-45-01.png" alt=""><br>— 为了简便，定义橙色方块为所有犯错误的$u_n^{t+1}$的累加，绿色圆形为所有正确的$u_n^{t+1}$累加<br>— 即：<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-19-47-12.png" alt=""><br>– 表现不好的选择方法：<br>— 将本次正确的$u_n^t$，除以一个错误的比例（缩小正确），赋给$u_n^{t+1}$<br>— 将本次错误的$u_n^t$，乘以一个正确的比例（放大错误），赋给$u_n^{t+1}$<br>— 这样得到的$u_n^{t+1}$的比率就会为2/1<br>— 即：<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-19-51-21.png" alt=""> </li>
</ul>
<h3 id="优化权重u的方法————放缩因子">3.3.2. 优化权重u的方法————放缩因子</h3><p>放缩因子-Adaptive Boosting Algorithm<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-20-02-12.png" alt=""> </p>
<ul>
<li>◆t有更清晰的物理意义，通常情况下εt &lt; 1/2（因为是学习之后的结果，错误率应该小于0.5），</li>
<li>◆t将大于1；</li>
<li>那么，犯错的数据将乘上大于1的数，正确数据将除以大于1的数</li>
<li>使得提升了犯错数据的权重(scale up incorrect)，</li>
<li>降低做对数据的权重(scale down correct)</li>
<li>这样使得更加专注在犯了错的地方，来得到不一样的假设(diverse hypotheses)。</li>
</ul>
<h2 id="Linear-Aggregation（聚集）-合成最终的g">3.4. Linear Aggregation（聚集） - 合成最终的g</h2><p>目标：合成最终的的$G(x)=sign(\sum_{t=1}^T\alpha_t g_t(x)$</p>
<ul>
<li>其中 $\alpha_t$是系数</li>
<li>要求好的$g_t$（错误率低），$\alpha_t$应该大一些</li>
<li>坏的$g_t$（错误率高），$\alpha_t$应该小一些</li>
<li>而◆t与错误率成反比</li>
<li>则可令$\alpha_t=ln(\text{◆t})$</li>
</ul>
<p>算法流程：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-20-21-25.png" alt=""> </p>
<p>这里之所以认为αt = ln(◆t)，处于下面的考虑：<br>如果εt = 1/2， 那么◆t = 1，则αt = 0，意思是随机乱猜的情况下（二元分类错误率为0.5），认为是坏的g，则一票不给个，不使用该g<br>如果εt = 0， 那么◆t = ∞，则αt = ∞，意思是正确率为0的情况，给它无限多票数</p>
<h1 id="AdaBoost-自适应优化算法总结">4. AdaBoost 自适应优化算法总结</h1><p>自适应优化算法 = 简单的学习A + 放缩权重 + 合成得到g<br>即：<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-20-25-49.png" alt=""> </p>
<p>AdaBoost算法完整流程<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-20-26-16.png" alt=""> </p>
<h1 id="AdaBoost理论特性">5. AdaBoost理论特性</h1><p>通过之前的VC Bound，来约束测试误差，其中蓝色的部分是模型的复杂度，O(dvc(H))为g的模型复杂度，而O(dvc(H))·T·logT是模型G的复杂度。原作者证明说，可以用O(logN)次迭代可以将Ein(G)做到很小，并且当数据量N足够多的情况下，又可以使得模型复杂度变得很小，从而使得模型复杂度得到控制。最终预测效果Eout也会很好。<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-20-27-24.png" alt=""><br>AdaBoost的保证是让一个很弱的算法不断变强，最终得到一个很强是算法（Ein=0，Eout is small）。<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-20-27-48.png" alt=""> </p>
<h1 id="Adaptive-Boosting的实际应用表现">6. Adaptive Boosting的实际应用表现</h1><p>上面的AdaBoost只需要一个很弱的算法就可以使用。<br>一般情况下，可以使用决策桩(Decision Stump)，该模型相当于在某一个维度上的Perceptron模型。<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-20-28-27.png" alt=""> </p>
<h1 id="聚合（aggregation）模型总结">7. 聚合（aggregation）模型总结</h1><p>aggregation 模型主要应用在将得到的多个预测函数$g_t$聚合在一起，得到更好的$g_t$（即更好的分类器）的方式</p>
<p>聚合方式主要面向两种情况：</p>
<ul>
<li>blending:已经有了一堆$g_t$在手上（可能是已知的，可能是求得的）。</li>
<li>learning：不已知$g_t$，需要通过一定方式求得很多$g_t$</li>
</ul>
<p>learning的分为三种情况</p>
<ul>
<li>把g看做是同等地位，通过投票或者平均的方式将它们合起来，称为Bagging</li>
<li>g是不平等的，有好有坏，一个可行的做法是把g当成是特征的转换，然后丢进线性模型训练就可以了，这称为AdaBoost</li>
<li>如果是不同的条件下，使用不同的g，那么我们仍然可以将g当做是特征转换，接下来使用一个非线性模型来得到最终的模型参数，这就是下文要介绍的决策树算法</li>
</ul>
<table>
<thead>
<tr>
<th>$g_t$类型</th>
<th style="text-align:right">blending</th>
<th style="text-align:center">learning</th>
</tr>
</thead>
<tbody>
<tr>
<td>各$g_t$等权重型（uniform）</td>
<td style="text-align:right">投票方式/平均方式</td>
<td style="text-align:center">Bagging</td>
</tr>
<tr>
<td>$g_t$权重不等型（non-uniform）</td>
<td style="text-align:right">线性聚合</td>
<td style="text-align:center">AdaBoost</td>
</tr>
<tr>
<td>不同情形用不同$g_t$（conditional）</td>
<td style="text-align:right">stacking</td>
<td style="text-align:center">决策树</td>
</tr>
</tbody>
</table>
<h1 id="AdaBoost思路总结">8. AdaBoost思路总结</h1><ul>
<li>一般，数据量过少时，我们无法得到更好的g.</li>
<li>因此我们采取BootStrapping方法，生成多个数据集，得到多个g</li>
<li>最后合成最好的g</li>
</ul>
<h1 id="AdaBoost伪代码">9. AdaBoost伪代码</h1><pre><code>对每次迭代：
    用buildStump()函数找到最佳单层决策树
    将最佳单层决策树加入到单层决策树数组
    计算alpha
    计算新的权重向量D
    更新累积类别估计值
    如果错误率等于0，则退出循环
</code></pre><p>参考文献</p>
<ol>
<li>《机器学习技法》，林轩田</li>
<li><a href="http://blog.csdn.net/JasonDing1354/article/details/46462711" target="_blank" rel="external">Jason Ding，【机器学习基础】自适应提升</a></li>
<li><a href="http://blog.jasonding.top/2015/07/22/Machine%20Learning/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E3%80%91%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95/" target="_blank" rel="external">Jason Ding，【机器学习基础】决策树算法</a></li>
</ol>
<p>备注：本节是《机器学习技法》第8章+《统计学习方法》第8章笔记</p>
]]></content>
      
        <categories>
            
            <category> 机器学习算法 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[随机森林算法]]></title>
      <url>/2017/03/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E7%AE%97%E6%B3%95/</url>
      <content type="html"><![CDATA[<p><strong>引言</strong></p>
<p>回顾之前学习过的两个算法：</p>
<ul>
<li>Bagging<br>– 简要：通过bootstrapping得到不一样的数据，得到不同的g，对g取平均得到G<br>– 特点：通过投票和平均的方式来降低对不同数据的敏感性（variance的效果）</li>
<li>决策树<br>– 简要：通过递归方式建立子树，最终得到完整的树<br>– 特点：对不同数据较敏感（算法的variance很大）</li>
<li>随机森林<br>– 两者的结合</li>
</ul>
<h1 id="随机森林算法">1. 随机森林算法</h1><p>概述：利用随机的方式将许多决策树组合成一个森林,每个决策树$g_t(t)$在分类的时候投票决定测试样本的最终类别。在得到森林之后，当有一个新的输入样本进入的时候，就让森林中的每一棵决策树分别进行一下判断，看看这个样本应该属于哪一类（对于分类算法），然后看看哪一类被选择最多，就预测这个样本为那一类。</p>
<p>详细算法：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-05-17-09-01.png" alt=""> </p>
<ul>
<li>左边的总算法是Bagging思想–体现随机性</li>
<li><p>其中为每个$g_t(t)$建树时，是决策树的思想–体现森林</p>
</li>
<li><p>并行计算的可能性：随机森林算法从Bagging过程中可以分配到不同的计算机中进行计算，每台计算机可以独立学习一棵树，不同的树之间没有任何依赖关系。这使得Bagging过程很容易实现并行化。</p>
</li>
</ul>
<h1 id="特征投影（Feature-Project">2. 特征投影（Feature Project)</h1><ul>
<li>原来在Bagging中，我们对数据进行抽取，得到不同的数据集，从而产生不同的$g_t$</li>
<li>在随机森林算法中，除了对数据抽取，也可以在<strong>特征</strong>这一角度抽取</li>
<li>例，如果事先我们有100个特征，现在我们可以抽取10个特征<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-05-20-34-44.png" alt=""> </li>
</ul>
<ul>
<li>得到数据集<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-05-20-34-07.png" alt=""> </li>
<li><p>来训练一棵树，这样的方式我们也可以得到很不一样的树，其对于分类的标准显然也很不一样</p>
</li>
<li><p>这等效于一个特征转换，这个过程中，从100维度到10个维度的转换中，相当于作了低维度的投影(Projection)</p>
</li>
<li><p>一般来说，<img src="http://om1bxijvl.bkt.clouddn.com/2017-03-05-20-34-18.png" alt=""> </p>
</li>
</ul>
<ul>
<li>得到的特征实际上是原始特征的随机子集，这使得生成模型过程中的效率也大大提高了</li>
</ul>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-05-17-17-10.png" alt=""> </p>
<h1 id="特征扩展（feature-Expansion）">3. 特征扩展（feature Expansion）</h1><p>每次随机抽取子空间 <code>等效于</code> 对原来的特征向量左乘一个<strong>投影矩阵</strong>$P$,使得$\Phi(X)=P\cdot x$</p>
<p>更加有能力的特征投影就是不再单一选取单一维度的特征，而是将多个维度的特征进行组合(随机的方向)，得到新的一维的特征，这称为<strong>特征扩展</strong>。</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-05-18-43-19.png" alt=""> </p>
<ul>
<li>将多个方向的特征随机合起来(combination)，即对于投影矩阵$P$的每一个方向$p_i$，不再固定方向（row）。即变为$\Phi_i(X)=P_i^T\cdot x$<br>– 一般情况下，会考虑<code>low-dimensional</code>，即投影过去时，一般每次选取少量维度进行投影。即只有$d’’$的<code>非零项</code>被投影过去</li>
<li>这样的方式，包含了随机抽取（random subspace）的思想</li>
<li>一般来说，每次投影都采用新的不一样的投影</li>
</ul>
<h1 id="随机森林的采样过程">4. 随机森林的采样过程</h1><p>在建立森林的每颗决策树$g_t$的过程中，首先需要随机采样数据点。</p>
<p>不是所有数据点都能被采到。以下介绍OOB点</p>
<h2 id="Out-of-bag（OOB）点">4.1. Out-of-bag（OOB）点</h2><p>OOB点：在bootstrapping过程中，有些数据可能没有被选择，这些数据被称为OOB点。例如下表，对于训练每一个决策树$g_t$，其中用*号标注的就是$g_t$的OOB<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-05-19-18-06.png" alt=""> </p>
<h3 id="OOB点个数">4.1.1. OOB点个数</h3><p>假设bootstrapping抽了$N’$次数据，探讨会有多少数据不会被抽到：</p>
<ul>
<li>若$N’=N$，某个数据$(x_n,y_n)$从未被抽到的概率是$(1-\frac{1}{N})^N$<br>$$(1-\frac{1}{N})^N=\frac{1}{\frac{N}{N-1}^N}\approx \frac{1}{e}$$</li>
<li>那么每个决策树$g_t$OOB集合的大小就约为$\frac{1}{e}N\approx 0.3N$</li>
</ul>
<h3 id="OOB用途-验证随机森林的G">4.1.2. OOB用途-验证随机森林的G</h3><p>可以用来做测试集-问题在于————验证<code>g</code>还是<code>G</code>？<br>以数据集$(x_N,y_N)为例$</p>
<ul>
<li>验证$g$的必要性不大</li>
<li>验证$G$不方便</li>
<li>可以用来验证<code>除了g1之外的G</code> = $G_N^-(x)=average(g_2,g_3,g_T)$</li>
<li>总之，用来验证$G$表现是否好的方式：<br>$$E_{oob}(G)=\frac{1}{N}\sum_1^N error(y_n,G_n^-(x_n))$$</li>
</ul>
<h1 id="特征选择（feature-selection）">5. 特征选择（feature selection）</h1><p>目的：自动选择需要的特征，去除冗余、不相关的特征<br>优点：降维，减少复杂度；减少噪声，提高模型泛化能力；物理意义；<br>缺点：计算量大；可能导致过拟合；</p>
<p>下面介绍特征选择的方法。</p>
<h2 id="根据重要性选择（线性的）">5.1. 根据重要性选择（线性的）</h2><ul>
<li>给每个特征算一个权重（分数）</li>
<li>问题：特征选择是线性的，不符合随机森林的非线性特点</li>
</ul>
<h2 id="置换检验（非线性的，Permutation-Test）">5.2. 置换检验（非线性的，Permutation Test）</h2><p>问题：每个特征是有噪音的，由于噪音的存在，导致某些原本很优秀的特征的分数被降低</p>
<p>解决方法：将第i个维度特征的所有数据重新的随机调整位置，然后比较一下原始数据和调整之后的数据表现的差距，来评价这个维度的特征是有多么重要。</p>
<ul>
<li>调整方法1：高斯什么的，但会改变数据原始分布</li>
<li>调整方法2：随机重排，即置换检验。将某一维度的数据随机重排，可以看出来这个维度有多重要。</li>
</ul>
<h2 id="在Out-Of-Bag-Estimate过程中做Permutation-Test">5.3. 在Out-Of-Bag Estimate过程中做Permutation Test</h2><p>在随机森林中可以用OOB代替验证的过程，为了简化Permutation Test带来的重新进行训练的代价，我们在使用OOB Example（bootstrap过程中没有选取的数据）进行验证的过程中做一些修改，即在验证的时候去进行Permutation Test，而非训练时进行。<br>在求Eoob(G)时，我们通过G-(xn)来计算，我们在这里将x(n)修改成x(n,i)，就可以不用对G进行修改了。<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-05-20-17-46.png" alt=""><br>在实际应用中，面对非线性的问题时，可以通过随机森林的方法来进行初步的特征选择。</p>
<p> <img src="http://om1bxijvl.bkt.clouddn.com/2017-03-05-20-16-21.png" alt=""> </p>
<p>参考资料：</p>
<ol>
<li><a href="http://database.51cto.com/art/201407/444788.htm" target="_blank" rel="external">机器学习的算法(1):决策树之随机森林</a></li>
<li>机器学习技法</li>
</ol>
]]></content>
      
        <categories>
            
            <category> 机器学习算法 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[决策树和CART]]></title>
      <url>/2017/03/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E5%86%B3%E7%AD%96%E6%A0%91%E5%92%8CCART/</url>
      <content type="html"><![CDATA[<h1 id="决策树简介">1. 决策树简介</h1><p>模仿人类决策的过程</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-05-12-43-33.png" alt=""> </p>
<ul>
<li>优点：好理解；简单</li>
<li>缺点：缺少很强的理论支持；树结构不唯一；</li>
</ul>
<h2 id="决策树的表达方式">1.1. 决策树的表达方式</h2><p>如上图所示的决策树，我们用$G(x)$来表达决策树：</p>
<p>$$G(x)=\sum_{t=1}^T q_t(x)\cdot g_t(x) $$</p>
<p>tips:</p>
<ul>
<li>$g(x)$是最终的决策（<code>Y or N</code>），叶子节点</li>
<li>$q_t(x)$是条件，<code>condition</code>。就是橘色箭头的判断过程</li>
<li>内部的决策过程，例如<code>deadline?</code>，内部节点</li>
</ul>
<p>那么决策树的表达就有两种方式：</p>
<ul>
<li><p>路径角度。将每个从根到叶子的路径作为一个假设g，通过不同的条件组合得到最后的G(X)。<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-05-12-53-15.png" alt=""> </p>
</li>
<li><p>递归角度。父树是由子树递归定义的<code>tree=(root,sub-trees)</code><br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-05-12-53-25.png" alt=""> </p>
</li>
</ul>
<h2 id="基本流程">1.2. 基本流程</h2><ol>
<li>如何分支（branching criteria），即如何得到$b(x)$</li>
<li>根据分支，数据如何分块</li>
<li>根据数据，如何学习子树</li>
<li>得到最终的决策树</li>
</ol>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-05-15-33-51.png" alt=""> </p>
<h1 id="CART算法">2. CART算法</h1><ul>
<li>Classification And Regression Tree，分类回归树</li>
<li>二叉树（只有是、否）</li>
<li>输入：随机变量$X$</li>
<li>输出：随机变量$Y$的条件概率分布</li>
<li>$g_t(x)$返回一个常数（根据不同的条件，对数据进行切分，到达叶子节点时，根据剩下的数据进行预测，输出一个常数）</li>
</ul>
<h2 id="纯度">2.1. 纯度</h2><h3 id="纯度的定义">2.1.1. 纯度的定义</h3><ul>
<li>CART算法中每个节点（看做是一个决策桩decision stump）对数据进行切分，如果分出来的数据的y都很接近（回归问题）或者都一样（分类问题），那么我们说这样的数据是“纯的”，这样用标量对数据进行预测可以得到比较小的误差。</li>
</ul>
<p>CART分支$b(x)$为：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-05-16-03-33.png" alt=""> </p>
<ul>
<li>我们通过上面的公式，来计算对于每一个节点的决策桩来说，分出来的两份数据的纯度是怎样的。</li>
<li>该公式通过计算数据集<code>Di（i=1 or 2）</code>的纯度并根据数据集的数量对其进行加权</li>
<li>其加权的意义是如果数据集的数量比较大的话，那个纯度对其比较重要</li>
<li>反之，就不那么重要。</li>
<li>CART通过分出的两部分数据综合起来的纯度对决策桩进行选择，选择“最纯”的分割方式作为当前的分支。</li>
</ul>
<h3 id="纯度的计算函数">2.1.2. 纯度的计算函数</h3><p>我们可以将分割出来的数据和回传的常数的误差作为评价纯度的方法，利用数据的y和回传的y_ba的均方误差来评价回归问题的纯度；利用0/1误差函数来评价分类问题的纯度。</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-05-16-11-16.png" alt=""> </p>
<p>如果是分类问题，我们还可以使用一个别的方法。通过基尼不纯度来度量分类问题的纯度问题。</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-05-16-11-41.png" alt=""> </p>
<h2 id="终止条件">2.2. 终止条件</h2><p>CART中有两种被迫终止的情况，分别是：</p>
<ul>
<li><code>yn</code>都一样，这时不纯度为0，于是可以得到<code>gt(x)=yn</code>；</li>
<li><code>xn</code>都一样，就没有继续分割的可能了。</li>
<li>CART树长到被迫停下来的情况，称为完全长成的树（fully-grown tree）。</li>
</ul>
<p>下面是CART算法完整流程：</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-05-16-19-09.png" alt=""> </p>
<h2 id="CART剪枝">2.3. CART剪枝</h2><p>预防过拟合</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-05-16-20-48.png" alt=""> </p>
<p>上图告诉我们使用叶子的数目作为正则项（regularizer），最终得到一个正则化的决策树。<br>关于剪枝的具体做法时：</p>
<ul>
<li>首先得到完全长成的树作为<code>G(0)</code>；</li>
<li>然后试图摘掉一片叶子，将所有摘掉一片叶子后的树计算<code>Ein</code>，将最小的那棵摘掉一片叶子的数作为<code>G(1)</code>；</li>
<li>如此这般，得到摘掉两片叶子的最优树<code>G(2)</code>，这样不断剪枝，直到根结点，形成一个子树序列；</li>
<li>最终对这个子树序列使用<code>argmin Ein(G)+λΩ(G)</code>来得到最后的输出。</li>
</ul>
<h1 id="参考资料">3. 参考资料</h1><ol>
<li><a href="http://blog.jasonding.top/2015/07/22/Machine%20Learning/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E3%80%91%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95/" target="_blank" rel="external">Jason Ding，决策树算法</a></li>
<li>机器学习技法课程，林轩田，台湾大学</li>
</ol>
]]></content>
      
        <categories>
            
            <category> 机器学习算法 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[boosting（混合模型）和bagging（装袋）]]></title>
      <url>/2017/03/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-boosting%EF%BC%88%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B%EF%BC%89%E5%92%8Cbagging/</url>
      <content type="html"><![CDATA[<p>这位前辈写的很好。今天也没有时间看视频。看看他的博客也就足够了。<a href="http://blog.jasonding.top/2015/06/10/Machine%20Learning/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E3%80%91%E6%B7%B7%E5%90%88%E5%92%8C%E8%A3%85%E8%A2%8B/" target="_blank" rel="external">混合和装袋</a></p>
<h1 id="bagging">1. bagging</h1><p>bagging——基于数据随机重抽样的分类器构建方法。</p>
<h1 id="boosting">2. boosting</h1><p>新的分类器根据已训练出的分类器的性能来进行训练；<br>分类结果基于所有分类器的加权求和得到。</p>
<h1 id="bagging和boosting区别">3. bagging和boosting区别</h1><p>Bagging 是 Bootstrap Aggregating 的简称，意思就是再取样 (Bootstrap) 然后在每个样本上训练出来的模型取平均，所以是降低模型的 variance. Bagging 比如 Random Forest 这种先天并行的算法都有这个效果。</p>
<p>Boosting 则是迭代算法，每一次迭代都根据上一次迭代的预测结果对样本进行加权，所以随着迭代不断进行，误差会越来越小，所以模型的 bias 会不断降低。这种算法无法并行，例子比如 Adaptive Boosting.</p>
<p>作者：匿名用户<br>链接：<a href="https://www.zhihu.com/question/26760839/answer/33963551" target="_blank" rel="external">https://www.zhihu.com/question/26760839/answer/33963551</a><br>来源：知乎<br>著作权归作者所有，转载请联系作者获得授权。</p>
]]></content>
      
        <categories>
            
            <category> 机器学习算法 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[O2O优惠券预测——思路总结]]></title>
      <url>/2017/03/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5-O2O%E4%BC%98%E6%83%A0%E5%88%B8%E9%A2%84%E6%B5%8B-%E6%80%9D%E8%B7%AF%E6%80%BB%E7%BB%93/</url>
      <content type="html"><![CDATA[<p>最近看各种机器学习算法，感觉没有实战，总是空空的。刚好这个月没什么事情，趁此机会拿<a href="https://tianchi.shuju.aliyun.com/getStart/information.htm?spm=5176.100067.5678.2.SfEzJi&amp;raceId=231593" target="_blank" rel="external">赛题</a>练习一下。</p>
<h1 id="资料整理">1. 资料整理</h1><ol>
<li><a href="https://github.com/wepe/O2O-Coupon-Usage-Forecast" target="_blank" rel="external">阿里天池O2O优惠券消费行为预测竞赛优胜方案</a>。第一名。北大。解题思路。</li>
<li><a href="http://blog.csdn.net/shine19930820/article/details/53995369" target="_blank" rel="external">O2O优惠券使用预测思路总结</a>。16名。解题思路。</li>
<li><a href="http://blog.csdn.net/bryan__/article/details/53907292" target="_blank" rel="external">O2O优惠券使用预测复赛第三名思路</a>。3名。PPT.</li>
<li><a href="https://www.zhihu.com/question/42154455/answer/124080774" target="_blank" rel="external">各竞赛QQ群</a></li>
<li><a href="http://www.datafountain.cn/data/science/player/competition/detail/description/238" target="_blank" rel="external">竞赛官网</a></li>
<li><a href="https://bbs.aliyun.com/thread/254.html?spm=5176.bbsl254.0.0.sBagXf&amp;type=1214&amp;type=1214#tabA" target="_blank" rel="external">论坛专区</a></li>
<li><a href="https://tianchi.shuju.aliyun.com/getStart/introduction.htm?spm=5176.100066.333.1.osUTZq&amp;raceId=231593" target="_blank" rel="external">天池新人实战赛[o2o优惠券使用预测]</a></li>
<li>也可以去天池官网上，点学习入口，下面的视频，这边也有对这次020比赛的一些视频解说 </li>
<li><a href="https://bbs.aliyun.com/read/273638.html" target="_blank" rel="external">数加平台指南＋文档、视频、FAQ及精华帖干货集锦</a></li>
<li><a href="http://www.jianshu.com/p/00dba98eb1d0" target="_blank" rel="external">数据科学完整学习路径</a></li>
</ol>
<h1 id="赛题背景">2. 赛题背景</h1><ul>
<li>O2O（Online to Offline）消费</li>
<li>O2O：是指将线下的商务机会与互联网结合，让互联网成为线下交易的平台</li>
<li>以优惠券盘活老用户或吸引新客户进店消费是O2O的一种重要营销方式</li>
</ul>
<h1 id="赛题目标">3. 赛题目标</h1><ul>
<li>个性化投放优惠券，提高核销率</li>
<li>通过分析建模，精准预测用户是否会在规定时间内使用相应优惠券</li>
<li>已知：用户在2016年1月1日至2016年6月30日之间真实线上线下消费行为</li>
<li>预测：用户在2016年7月领取优惠券后15天以内的使用情况</li>
<li>评价标准：优惠券核销预测的平均AUC（ROC曲线下面积）。即对每个优惠券coupon_id单独计算核销预测的AUC值，再对所有优惠券的AUC值求平均作为最终的评价标准。 关于AUC的含义与具体计算方法，可参考维基百科</li>
</ul>
<h1 id="数据描述及分析">4. 数据描述及分析</h1><h4 id="数据描述">4.0.0.1. 数据描述</h4><ul>
<li>Table 1: 用户线下消费和优惠券领取行为，ccf_offline_stage1_train.csv</li>
<li>Table 2: 用户线上点击/消费和优惠券领取行为，ccf_online_stage1_train</li>
<li>Table 3：用户O2O线下优惠券使用预测样本，ccf_offline_stage1_test_revised.csv</li>
<li>Table 4：选手提交文件字段，其中user_id,coupon_id和date_received均来自Table 3,而Probability为预测值</li>
</ul>
<p><strong> TABLE 1： 用户线下消费和优惠券领取行为 </strong><br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-03-21-57-25.png" alt=""> </p>
<p><strong> Table 2: 用户线上点击/消费和优惠券领取行为</strong><br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-03-21-58-04.png" alt=""> </p>
<p><strong> Table 3：用户O2O线下优惠券使用预测样本</strong><br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-03-21-58-29.png" alt=""> </p>
<p><strong> Table 4选手提交文件字段</strong><br>其中user_id,coupon_id和date_received均来自Table 3,而Probability为预测值<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-03-21-58-40.png" alt=""> </p>
<h4 id="数据分析">4.0.0.2. 数据分析</h4><h3 id="初步分析">4.0.1. 初步分析</h3><p><strong> TABLE 1 分析 </strong></p>
<ul>
<li>特点：<br>– 标题：用户线下消费和优惠券领取行为<br>– 场景：线下<br>– 行为：消费、优惠券领取<br>– 数据：优惠券领取、使用情况，消费情况，用户常活动地点与最近门店距离</li>
<li>分析1：用户行为有三种情况<br>– 领了优惠券 &amp;&amp; 未消费 = 负样本 （Date=null &amp; Coupon_id != null）<br>– 没领优惠券 &amp;&amp; 已消费（Date!=null &amp; Coupon_id = null）<br>– 领了优惠券 &amp;&amp; 已消费（Date!=null &amp; Coupon_id != null）<br>– 总结：本数据作为刻画用户特点的主要依据较为合理</li>
<li>分析2：优惠率<br>– 总结：有可能用户会根据优惠率来决定是否进行消费</li>
<li>分析3：距离<br>– 离用户近的门店可能会总领取优惠券，但不一定会使用。<br>– 离用户远的门店如果有优惠券，则可能会为了很大的优惠率专程去使用。</li>
<li>总结<br>– 本数据集主要刻画线下用户特征。</li>
</ul>
<p><strong> TABLE 2 分析 </strong></p>
<ul>
<li>特点：<br>– 标题：用户线上点击/消费和优惠券领取行为<br>– 场景：线上<br>– 行为：点击、消费、优惠券领取<br>– 数据：用户是否点击。购买。领取优惠券。</li>
<li>分析1：用户行为有三种情况<br>– 领了优惠券 &amp;&amp; 未消费 = 负样本（Date=null &amp; Coupon_id != null）<br>– 没领优惠券 &amp;&amp; 已消费 （Date!=null &amp; Coupon_id = null）<br>– 领了优惠券 &amp;&amp; 已消费 （Date!=null &amp; Coupon_id != null）</li>
<li>分析2：用户点击、消费、优惠券情况<br>– 用户点击了 &amp;&amp; 没领优惠券 &amp;&amp; 未消费 = 负样本<br>– 用户点击了 &amp;&amp; 领了优惠券 &amp;&amp; 未消费<br>– 用户点击了 &amp;&amp; 领了优惠券 &amp;&amp; 已消费<br>– 用户点击了 &amp;&amp; 没领优惠券 &amp;&amp; 已消费<br>– 用户没点击 </li>
<li>总结<br>– 本数据集主要刻画线上用户特征。</li>
</ul>
<p><strong> Table 3：用户O2O线下优惠券使用预测样本 </strong></p>
<ul>
<li>测试集</li>
</ul>
<h3 id="认识数据">4.0.2. 认识数据</h3><p>感谢wepon的<a href="https://tianchi.shuju.aliyun.com/video.htm?spm=5176.100258.100258.3.1O7LLR" target="_blank" rel="external">无私奉献</a></p>
<p>对提供的数据做一些基本的统计，有助于对赛题的理解，可以熟悉业务逻辑，也方便后面的特征工程。</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-12-21-38-50.png" alt=""> </p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-12-21-39-13.png" alt=""> </p>
<h1 id="特征提取">5. 特征提取</h1><ul>
<li>特征提取：将原始特征转换为一组具有明显物理意义（Gabor、几何特征[角点、不变量]、纹理[LBP HOG]）或者统计意义或核的特征</li>
<li>经验上来说，这些特征提取的越多越好，并不用担心特征过多，因为推荐系统的数据量都比较大，并且基于一些规则可以很好的筛选特征。</li>
<li>第一次做特征提取，很多东西想得不够周到。参考了很多第一名的思想。</li>
</ul>
<h4 id="用户特征">5.0.0.1. 用户特征</h4><p>用途：描述用户消费偏好</p>
<p>线下：</p>
<ol>
<li>领取优惠券率（领取次数/总次数）</li>
<li>优惠券核销率（优惠券使用次数/优惠券领取次数）</li>
<li>消费率（消费次数/总次数）</li>
<li>核销时的优惠率</li>
<li>领取、使用优惠券间隔</li>
<li>user经常活动的地点离平均/最大/最小用户-商家的最近门店距离</li>
<li>消费频数</li>
<li>优惠券领取频数</li>
<li>优惠券使用频数</li>
<li>用户满减优惠券核销率（满减优惠券使用次数/优惠券领取次数）</li>
<li>用户满减优惠券核销比重（满减优惠券使用次数/优惠券使用次数）</li>
<li>核销优惠券的平均/最低/最高消费打率</li>
<li>核销过的商户数量，以及不同商家的比重</li>
<li>核销过的不同优惠券数量，以及其与优惠券种类数的比重</li>
<li>平均每个商家核销多少张优惠券</li>
</ol>
<p>线上：</p>
<ol>
<li>优惠券领取率（领取/总）</li>
<li>点击频数</li>
<li>优惠券领取频数</li>
<li>优惠券使用频数</li>
<li>优惠券核销率（使用/领取）</li>
<li>消费频数</li>
<li>消费率（消费次数/总）</li>
<li>核销时的优惠率</li>
<li>领取、使用优惠券间隔</li>
<li>用户线上不消费次数</li>
<li>用户线下不消费次数占线上线下总的不消费次数的比重</li>
<li>用户线下的优惠券核销次数占线上线下总的优惠券核销次数的比重</li>
</ol>
<h4 id="线下消费的优惠券特征">5.0.0.2. 线下消费的优惠券特征</h4><ol>
<li>优惠率</li>
<li>优惠券被领取次数</li>
<li>优惠券核销率</li>
<li>领取、使用优惠券间隔</li>
</ol>
<h4 id="线上商户特征">5.0.0.3. 线上商户特征</h4><ol>
<li>点击频数</li>
<li>购买频数</li>
<li>优惠券被领取频数</li>
<li>优惠券被使用频数</li>
<li>消费率（购买/总）</li>
<li>优惠券领取率（领取/总）</li>
<li>优惠券核销率（使用/领取）</li>
<li>优惠率</li>
<li>领取、使用优惠券间隔</li>
</ol>
<p>现在遇到了一些瓶颈。参考了前人的教程<a href="http://www.jianshu.com/p/00dba98eb1d0" target="_blank" rel="external">数据科学完整学习路径</a>，发现自己基础还是不够扎实。决定先看看机器学习技法教程，再进行下一步。</p>
<p>=======2017.3.1======</p>
<p>看了一下GBDT，发现我的疑问还是不能解决。</p>
<ul>
<li>多类特征，怎么处理？</li>
<li>处理的流程究竟是怎样的？</li>
</ul>
<p>为了解决上述问题，我决定开始深入分析第一名的队伍的<a href="https://github.com/wepe/O2O-Coupon-Usage-Forecast" target="_blank" rel="external">阿里天池O2O优惠券消费行为预测竞赛优胜方案</a>源码。</p>
<p>=======2017.3.8======</p>
<p>算是大致看完了前辈的代码。见本博客文章“O2O优惠券预测——对第一名的思路源码分析”</p>
<p>这其中的奥妙深不可测。</p>
<p>知识累积不是一蹴而就的。加油吧。</p>
<p>=======2017.3.12======</p>
]]></content>
      
        <categories>
            
            <category> o2o优惠券使用预测 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[SVM]]></title>
      <url>/2017/03/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-SVM/</url>
      <content type="html"><![CDATA[<h1 id="SVM简介">1. SVM简介</h1><p>SVM - Support Vector Machines, 支持向量机。是二分类模型。</p>
<h1 id="线性可分SVM">2. 线性可分SVM</h1><h2 id="概念复习">2.1. 概念复习</h2><p><a href="http://blog.csdn.net/kaka19880812/article/details/46419269" target="_blank" rel="external">参考文献</a></p>
<p><em>输入空间</em>：输入所有可能的取值的集合</p>
<p><em>特征向量</em>：每个具体的输入</p>
<p><em>特征空间</em>：所有特征向量存在的空间。特征空间可以是输入空间，也可以由输入空间映射得到。模型定义在特征空间上。</p>
<p><em>输出空间</em>：输出所有可能的取值的集合</p>
<h2 id="线性可分SVM学习目标">2.2. 线性可分SVM学习目标</h2><p>在特征空间找到一个分离超平面 $wx+b=0$，并且间隔最大。</p>
<h2 id="SVM与PLA区别">2.3. SVM与PLA区别</h2><p>PLA:误分类最小策略，求得分离超平面。解不唯一。<br>线性可分SVM:间隔最大化，求得分离超平面。解唯一。</p>
<h2 id="函数间隔和几何间隔">2.4. 函数间隔和几何间隔</h2><p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-03-13-44-02.png" alt=""> </p>
<ul>
<li>一个点距离分离超平面的远近<code>|wx+b|</code> 是 分类预测的<strong>确信程度</strong>。例如将A分为0的确信度很高，而将C分为0的确信度较低</li>
<li><code>wx+b</code>与<code>y</code>的符号一致，则分类正确</li>
<li><strong>函数间隔</strong>：<code>y(wx+b)</code>，表示分类的正确性及确信度</li>
<li><strong>超平面的函数间隔*</strong>：<code>min{y(wx+b)}</code></li>
<li><strong>几何间隔</strong>：规范化<code>||w||=1</code>，即为$y(\frac{w}{||w||}\cdot x + \frac{b}{||w||})$，使得间隔固定。（因为w和b成比例增加时，超平面不会改变，但函数间隔会变大）</li>
</ul>
<h1 id="SVM基本算法">3. SVM基本算法</h1><h2 id="标准问题">3.1. 标准问题</h2><p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-03-14-56-13.png" alt=""> </p>
<h2 id="算法的推导">3.2. 算法的推导</h2><ul>
<li>一开始的目标是：<br>– 目标：求得一个x，使得margin最大<br>– 条件：<br>— 每个点都被正确分类（<code>b</code>被塞入了<code>w</code>矩阵里）<br>— magin是最近的点的距离<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-16-22-00.png" alt=""> </li>
</ul>
<ul>
<li><p>从距离的理解入手，如图所示<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-16-07-16.png" alt=""> </p>
</li>
<li><p><code>w</code>的理解<br>– 灰色是分割平面<br>– $x’$和$x’’$是平面上的两个点，则它俩满足$w^T X’ = -b$，$w^T x’’ = -b$<br>– 两式相减，得到 $w^T(x’’ - x’)=0$<br>– 则<strong><code>w</code>垂直于平面</strong>，即w是平面的法向量<br>– 那么dist是向量$x’ x’’$在<code>w</code>上的投影</p>
</li>
</ul>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-16-15-32.png" alt=""> </p>
<ul>
<li><p>而<code>y(wx+b)&gt;0</code>，则距离可以表示为：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-16-18-42.png" alt=""> </p>
</li>
<li><p>因此，新的算法目标为<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-16-19-57.png" alt=""> </p>
</li>
<li><p>归一化条件：<code>margin=y(wx+b)=1</code>,得到新目标<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-16-29-24.png" alt=""> </p>
</li>
<li><p>对目标进行放缩，方便解<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-16-31-16.png" alt=""> </p>
</li>
<li><p>再将最大化变为最小化，也拿走||w||的根号<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-16-33-31.png" alt=""> </p>
</li>
</ul>
<h3 id="支持向量">3.2.1. 支持向量</h3><ul>
<li>在线性可分的情况下，训练数据集的样本点中与分离超平面距离最近的样本点的实例，叫做<strong>支持向量</strong>（support vector）</li>
<li>支持向量是使得约束条件等号成立的点</li>
<li>决定分离超平面时，只有支持向量起作用，而其他点不起作用</li>
<li>在H1，H2上的点就是支撑向量（很少，但很重要的点）</li>
</ul>
<h3 id="间隔-margin">3.2.2. 间隔 margin</h3><p>H1，H2之间，$margin=\frac{2}{||w||}$</p>
<h3 id="间隔边界">3.2.3. 间隔边界</h3><p>H1，H2<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-03-15-06-02.png" alt=""> </p>
<h3 id="标准问题的求解">3.2.4. 标准问题的求解</h3><ul>
<li>目标是二次的，条件是线性的</li>
<li><p>则这是一个二次规划问题，有固定的解</p>
</li>
<li><p>我们的标准问题：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-16-47-03.png" alt=""> </p>
</li>
<li><p>标准二次规划问题：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-16-47-26.png" alt=""> </p>
</li>
<li><p>系数代入：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-16-47-47.png" alt=""> </p>
</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 机器学习算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 线性模型 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[逻辑回归（Logistic regression）]]></title>
      <url>/2017/03/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%EF%BC%88Logistic-regression%EF%BC%89/</url>
      <content type="html"><![CDATA[<h1 id="逻辑回归模型">1. 逻辑回归模型</h1><h3 id="逻辑回归分布">1.0.1. 逻辑回归分布</h3><p>连续随机变量$X$服从逻辑回归分布，则$X$具有下列++分布函数和密度函数++：</p>
<p>$$<br>F(x)=P(X&lt;=x)=\frac{1}{1+e^{-(x-u)/r}}<br>$$</p>
<p>$$<br>f(x)=F’(x)=\frac{e^{-(x-u)/r}}{r(1+e^{-(x-u)/r})^2}<br>$$</p>
<p>其中</p>
<p>$u$为位置参数</p>
<p>$r&gt;0$为形状参数</p>
<p>其中，密度函数与分布函数的形状如图所示<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-02-20-46-41.png" alt=""> </p>
<h4 id="分布密度函数与分布函数">1.0.1.1. 分布密度函数与分布函数</h4><p>感觉自己宛如一个智障，这些居然忘记了。哎，重新来吧。</p>
<p>概率密度函数$f(x)$：表示瞬时值落在某区间的概率，是幅值的概率。++用来描述连续型随机变量取值的密集程度的。++$f(x)$表示X=x的概率是$\int_0^1f(x)$。</p>
<p>$P(X=x|x \in (0,1))=\int_0^1f(x)$</p>
<p>分布函数$F(x)$：描述随机变量落在任一区间的概率。</p>
<p>$F(x)=P(X&lt;=x)$</p>
<p>关系：</p>
<p>分布函数$F(x)$是概率密度函数$f(x)$从负无穷到正无穷上的积分；</p>
<p>在坐标轴上，概率密度函数的函数值y表示落在x点上的概率为y；分布函数的函数值y则表示x落在区间(-∞上的概率。</p>
<h3 id="二项逻辑回归模型">1.0.2. 二项逻辑回归模型</h3><h4 id="用途：估计某个值的为哪一类的概率">1.0.2.1. 用途：估计某个值的为哪一类的概率</h4><p>logistic回归是分类问题。前面我们讲的分类问题的输出都是 “yes”或者“no”。但是在现实生活中，我们并不是总是希望结果那么肯定，而是概率（发生的可能性）。比如，我们希望知道这个房子在第三个星期被卖出去的概率。那么以前的分类算法就无法使用了，这时logistic 回归就派上了用场。 </p>
<h4 id="定义">1.0.2.2. 定义</h4><p>二项逻辑斯蒂回归模型是如下的条件概率分布：</p>
<p>$$<br>P(Y=1|x)=\frac{exp(wx+b)}{1+exp(wx+b)}<br>$$</p>
<p>$$<br>P(Y=0|x)=\frac{1}{1+exp(wx+b)}<br>$$</p>
<p>其中：<br>$x \in R^n$ ：输入</p>
<p>$Y \in (0,1)$ ：输出</p>
<p>给定$x$，可以求得$P(Y=1|x)$和$P(Y=0|x)$</p>
<h4 id="逻辑斯蒂回归模型的特点">1.0.2.3. 逻辑斯蒂回归模型的特点</h4><p>几率（odds）= 该事件发生的概率/该事件不该发生的概率，则对数几率：</p>
<p>$$<br>log(odds)=log(\frac{p}{1-p})=log(\frac{P(Y=1|x)}{1-P(Y=1|x)})=wx<br>$$</p>
<p>则：输出Y=1的对数几率=输入x的线性函数</p>
<h1 id="模型参数估计">2. 模型参数估计</h1><p>输入： 一堆（x,y）</p>
<p>目标：估计参数w,b</p>
<p>方法：极大似然法</p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-02-21-35-03.png" alt=""> </p>
<h1 id="总结">3. 总结</h1><ol>
<li>逻辑回归是一种预测y的各类别的概率的模型，即计算P(Y=1|x)或者P(Y=0|x)</li>
<li>与机器学习过程类似，即 通过已知的大量（x,y），拟合计算参数w,b；再用y=wx+b来计算新的x下的y；把y输入sigmoid函数中，得到y为1的概率。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> 机器学习算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 回归 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[SQL游标]]></title>
      <url>/2017/03/02/SQL-SQL%E6%B8%B8%E6%A0%87/</url>
      <content type="html"><![CDATA[<h1 id="简介">1. 简介</h1><h3 id="场景">1.0.1. 场景</h3><p>从某一结果集中地逐一读记录</p>
<h3 id="游标本质">1.0.2. 游标本质</h3><p>能从包括多条数据记录的结果集中每次提取一条记录的机制。</p>
<p>我们知道关系数据库管理系统实质是面向集合的，在MS SQL SERVER 中并没有一种描述表中单一记录的表达形式，除非使用where 子句来限制只有一条记录被选中。因此我们必须借助于游标来进行面向单条记录的数据处理。</p>
<h3 id="游标种类">1.0.3. 游标种类</h3><ul>
<li>Transact_SQL 游标</li>
<li>API 游标</li>
<li>客户游标</li>
</ul>
<h1 id="游标操作">2. 游标操作</h1><p>使用游标有四种基本的步骤:声明游标、打开游标、提取数据、关闭游标。</p>
<h3 id="声明游标">2.0.1. 声明游标</h3><p>游标的声明包括两个部分:游标的名称 + 这个游标所用到的SQL语句。</p>
<p>例：要声明一个叫作Cus-tomerCursor的游标用以查询地址在北京的客户的姓名、帐号及其余额: </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">DECLARE CustomerCursor CURSOR FOR </div><div class="line">SELECT acct_no,name,balance </div><div class="line">FROM customer </div><div class="line">WHERE province=&quot;北京&quot;;</div></pre></td></tr></table></figure>
<p>TIPS:</p>
<ul>
<li>声明游标的这一段代码行是不执行的,不能将debug时的断点设在这一代码行上,也不能用IF语句来声明两个同名的游标,如下列的代码就是错误的。 </li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">IF Is_prov=&quot;北京&quot;THEN </div><div class="line">DECLARE CustomerCursor CURSOR FOR </div><div class="line">SELECT acct_no,name,balance </div><div class="line">FROM customer </div><div class="line">WHERE province=&quot;北京&quot;; </div><div class="line">ELSE </div><div class="line">DECLARE CustomerCursor CURSOR FOR </div><div class="line">SELECT acct_no,name,balance </div><div class="line">FROM customer </div><div class="line">WHERE province〈〉&quot;北京&quot;; </div><div class="line">END IF</div></pre></td></tr></table></figure>
<h3 id="打开游标">2.0.2. 打开游标</h3><p>打开游标是执行与其相关的一段SQL语句</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">OPEN CustomerCursor;</div></pre></td></tr></table></figure>
<h3 id="提取数据">2.0.3. 提取数据</h3><p>必须用FETCH语句来取得数据。</p>
<p>一条FETCH语句一次可以将一条记录放入程序员指定的变量中。</p>
<p>事实上,++FETCH语句是游标使用的核心++。</p>
<h4 id="用游标提取一条数据">2.0.3.1. 用游标提取一条数据:</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">FETCH CustmerCur-sor </div><div class="line">INTO:ls_acct_no, </div><div class="line">    :ls_name, </div><div class="line">    :ll_balance;</div></pre></td></tr></table></figure>
<h4 id="用游标遍历很多条数据：">2.0.3.2. 用游标遍历很多条数据：</h4><p>而在多数情况下,我们所想要作的是在数据库中从第一条记录开始提取,一直到结束。所以我们一般要将游标提取数据的语句放在一个循环体内,直至将结果集中的全部数据提取后,跳出循环圈。</p>
<p><strong>通过检测SQLCA.SQL-CODE的值,可以得知最后一条FETCH语句是否成功。</strong></p>
<p>一般,当SQLCODE值为0时表明一切正常,100表示已经取到了结果集的末尾,而其它值均表明操作出了问题,这样我们可以编写以下的代码: </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">lb_continue=True </div><div class="line">ll_total=0 </div><div class="line">DO WHILE lb_continue </div><div class="line">    FETCH CustomerCur-sor </div><div class="line">    INTO:ls_acct_no, </div><div class="line">        :ls_name, </div><div class="line">        :ll_balance; </div><div class="line">    If sqlca.sqlcode=0 Then  #如果SQLCA.SQL-CODE==0，则一切正常</div><div class="line">        ll_total+=ll_balance </div><div class="line">    Else #跳出循环</div><div class="line">        lb_continue=False </div><div class="line">    End If </div><div class="line">LOOP</div></pre></td></tr></table></figure>
<h3 id="关闭游标">2.0.4. 关闭游标</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">CLOSE CustomerCursor;</div></pre></td></tr></table></figure>
<h3 id="使用Where子句子">2.0.5. 使用Where子句子</h3><p>我们可以动态地定义游标中的Where子句的参数,例如在本例中我们是直接定义了查询省份是北京的记录,但也许在应用中我们要使用一个下拉式列表框,由用户来选择要查询的省份,我们该怎样做呢?<br>我们在前面曾经提到过,DECLARE语句的作用只是定义一个游标,在OPEN语句中这个游标才会真正地被执行。了解了这些,我们就可以很方便地实现这样的功能,在DECLARE的Where子句中加入变量作参数,如下所示: </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">DECLARE CustomerCursor CURSOR FOR </div><div class="line">SELCECT acct_no,name,balance </div><div class="line">FROM customer </div><div class="line">WHERE province=:ls_province; </div><div class="line">∥定义ls_province的值 </div><div class="line">OPEN CustomerCursor;</div></pre></td></tr></table></figure>
<h3 id="游标的类型">2.0.6. 游标的类型</h3><p>同其它变量一样,我们也可以定义游标的访问类型:全局、共享、实例或局部,游标变量的命名规范建议也同其它变量一样。 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">--声明游标</div><div class="line">declare my_cursor cursor keyset for select * from info</div><div class="line">--删除游标资源</div><div class="line">deallocate my_cursor</div><div class="line">--打开游标,在游标关闭或删除前都有效</div><div class="line">open my_cursor</div><div class="line">--关闭游标</div><div class="line">close my_cursor</div><div class="line">--声明局部变量</div><div class="line">declare @id int,@name varchar(20),@address varchar(20)</div><div class="line">--定位到指定位置的记录</div><div class="line">fetch absolute 56488 from my_cursor into @id,@name,@address</div><div class="line">select @id as id,@name as name,@address as address</div><div class="line">--定位到当前记录相对位置记录</div><div class="line">fetch relative -88 from my_cursor into @id,@name,@address</div><div class="line">select @id as id,@name as name,@address as address</div><div class="line">--定位到当前记录前一条</div><div class="line">fetch prior from my_cursor into @id,@name,@address</div><div class="line">select @id as id,@name as name,@address as address</div><div class="line">--定位到当前记录后一条</div><div class="line">fetch next from my_cursor into @id,@name,@address</div><div class="line">select @id as id,@name as name,@address as address</div><div class="line">--定位到首记录</div><div class="line">fetch first from my_cursor into @id,@name,@address</div><div class="line">select @id as id,@name as name,@address as address</div><div class="line">--定位到尾记录</div><div class="line">fetch last from my_cursor into @id,@name,@address</div><div class="line">select @id as id,@name as name,@address as address</div></pre></td></tr></table></figure>
<p>实例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">use database1</div><div class="line">declare my_cursor cursor scroll dynamic</div><div class="line"> /**//*scroll表示可随意移动游标指针（否则只能向前），dynamic表示可以读写游标（否则游标只读）*/</div><div class="line">for</div><div class="line">select productname from  product</div><div class="line">open my_cursor</div><div class="line">declare @pname sysname</div><div class="line">fetch next from my_cursor into @pname</div><div class="line">while(@@fetch_status=0)</div><div class="line">  begin</div><div class="line">    print &apos;Product Name: &apos; + @pname</div><div class="line">    fetch next from my_cursor into @pname</div><div class="line">  end</div><div class="line">fetch first from my_cursor into @pname</div><div class="line">print @pname</div><div class="line">/**//*update product set productname=&apos;zzg&apos; where current of my_cursor */</div><div class="line">/**//*delete from product where current of my_cursor */</div><div class="line">close my_cursor</div><div class="line">deallocate my_cursor</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> SQL </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[从出租车行驶数据筛选出OD点数据]]></title>
      <url>/2017/03/02/%E4%BB%8E%E5%87%BA%E7%A7%9F%E8%BD%A6%E8%A1%8C%E9%A9%B6%E6%95%B0%E6%8D%AE%E7%AD%9B%E9%80%89%E5%87%BAOD%E7%82%B9%E6%95%B0%E6%8D%AE/</url>
      <content type="html"><![CDATA[<p>动手前先动脑，这句话献给自己。</p>
<h2 id="目标">0.1. 目标</h2><p>从出租车行驶数据中，筛选出OD点。</p>
<h2 id="数据集">0.2. 数据集</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">名称：2012年11月1日 北京市出租车GPS数据</div><div class="line"></div><div class="line">格式：txt文本文件</div><div class="line"></div><div class="line">数据项及顺序：车辆标识,触发事件,运营状态,GPS时间,GPS经度,GPS纬度,GPS速度,GPS方向,GPS状态</div><div class="line">车辆标识：6个字符</div><div class="line">触发事件：0=变空车，1=变载客，2=设防，3=撤防，4=其它</div><div class="line">运营状态：0=空车，1=载客，2=驻车，3=停运，4=其它</div><div class="line">GPS时间</div><div class="line">GPS经度</div><div class="line">GPS纬度</div><div class="line">GPS速度：取值000-255内整数，以公里/小时为单位</div><div class="line">GPS方位：取值000-360内整数，以度为单位</div><div class="line">GPS状态：0=无效，1=有效</div><div class="line">结束串：回车符+换行符</div><div class="line"></div><div class="line">数据示例:</div><div class="line">123456,0,0,20110414160613,116.4078674,40.2220650,21,274,1</div></pre></td></tr></table></figure>
<h2 id="思路">0.3. 思路</h2><ol>
<li>将数据点按照“车牌号、运营时间、运营状态”依次从小到大排序</li>
<li>筛出同一车牌号的运营状态变化的时刻的数据</li>
</ol>
<h2 id="方法">0.4. 方法</h2><ul>
<li><p>方法一：导入数据库，再写脚本操作数据。可能是我对数据库实在没缘分，这个方法没有成功。</p>
</li>
<li><p>方法二：将车牌号分段后，在每段上进行如上思路所示的操作。</p>
</li>
</ul>
<p>为了更好地分段，我们先对车牌号段进行分析。</p>
<h3 id="车牌号段分析">0.4.1. 车牌号段分析</h3><p>查询车的数目：12409个</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">SELECT COUNT(DISTINCT id) FROM SET1</div></pre></td></tr></table></figure>
<p>脚本名：data1IDcount.py</p>
<p>地址：81服务器上，D:\jiayi\wxt</p>
<p>听说数据集有三千多万，所以我决定每一千个数据取一条进行粗略分析。</p>
<p>车牌号分布：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-01-15-01-24.png" alt=""> </p>
<p>结果：</p>
<ol>
<li>车牌号分布在1-800000之间</li>
<li>100000-200000的车最多</li>
<li>一共有32885600条数据</li>
</ol>
<h3 id="分段">0.4.2. 分段</h3><p>脚本名：data2cut.py</p>
<p>分段法：将车牌号分为10段，其中100000-200000为三段，其余段均分。 <del>简单起见，还是将车牌号均分为十段了(ERROR:Errcode: 28 - No space left on device))</del></p>
<p>还是采用了数据库。是福不是祸，是祸躲不过呀。<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-01-19-49-25.png" alt=""> </p>
<h3 id="伪代码">0.4.3. 伪代码</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">for i = 0:10000:800000</div><div class="line">    # 为本区间数据建立新表，并插入数据</div><div class="line">    CREATE TABLE to this range</div><div class="line">    INSERT data </div><div class="line">    #将本区间数据排序</div><div class="line">    ORDER BY id,timen,opevent</div><div class="line">    #遍历，筛出本段的OD点</div><div class="line">    for line in this range table</div><div class="line">    </div><div class="line">        #如果本条数据是跳跃点，则插入到OD表中</div><div class="line">        #vehicle:上一条数据的车牌号</div><div class="line">        #pre:上一条数据的opevent</div><div class="line">        </div><div class="line">        #第一条数据</div><div class="line">        if vehicle==&quot;&quot;:</div><div class="line">            vehicle = row[0]</div><div class="line">            pre=row[2]</div><div class="line">        else:#从第二条记录开始</div><div class="line">            # 如果与上一条是一个车</div><div class="line">            if vehicle==row[0]:</div><div class="line">                #如果与上一条记录是同一个车，且event有变化</div><div class="line">                if pre!=row[2]:</div><div class="line">                    INSERT to OD_table</div><div class="line">                    pre=row[2]</div><div class="line">                    vehicle=row[0]</div><div class="line">                else:</div><div class="line">                    continue</div><div class="line">            #如果与上一条不是同一个车</div><div class="line">            else:</div><div class="line">                vehicle=row[0]</div><div class="line">                pre=row[2]</div></pre></td></tr></table></figure>
<h3 id="结果">0.4.4. 结果</h3><p>原始数据：data.set1，32885600个</p>
<p>OD点：data.set1_od ,645271个</p>
]]></content>
      
        
        <tags>
            
            <tag> 数据预处理 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[ROC和AUC]]></title>
      <url>/2017/03/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5-O2O%E4%BC%98%E6%83%A0%E5%88%B8%E9%A2%84%E6%B5%8B-ROC%E5%92%8CAUC/</url>
      <content type="html"><![CDATA[<h3 id="AUC定义">0.0.1. AUC定义</h3><p>用途：用来度量分类模型好坏的一个标准<br>背景：</p>
<ul>
<li>有些时候，仅仅依靠正确率是不妥当的。</li>
<li>能客观反映对正样本、负样本综合预测的能力，还要考虑消除样本倾斜的影响。</li>
</ul>
<h3 id="ROC">0.0.2. ROC</h3><ul>
<li>ROC:Receiver Operating Characteristic</li>
<li>ROC曲线：横坐标是false positive rate(FPR)，纵坐标是true positive rate(TPR)。</li>
<li>对某个分类器而言，我们可以根据其在测试样本上的表现得到一个TPR和FPR点对。这样，此分类器就可以映射成ROC平面上的一个点。</li>
<li>调整这个分类器分类时候使用的阈值，我们就可以得到一个经过(0, 0)，(1, 1)的曲线，这就是此分类器的ROC曲线。</li>
</ul>
<p>tip：FPR和TPR<br>先来看一个普遍的二分类问题的结果，预测值和实际值有4种组合情况，看下面的表格：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-03-22-18-05.png" alt=""><br>我们定义<br>$$ TruePositiveRate(TPR) = \frac{TP}{TP+FN=P} = \frac{正确预测1}{正确预测1+错误预测1=1的数量}=实际正样本正确预测的比例$$<br>$$ FalsePositiveRate(FPR) = \frac{FP}{FP+TN=N} = \frac{错误预测0}{错误预测0+正确预测0=0的数量}=实际负样本错误预测的比例$$</p>
<h4 id="如何一个分类器的画ROC曲线">0.0.2.1. 如何一个分类器的画ROC曲线</h4><p>概率输出：即表示分类器认为某个样本具有多大的概率属于正样本（或负样本），来动态调整一个样本是否属于正负样本<br>例：</p>
<ul>
<li>图中共有20个测试样本</li>
<li>“Class”一栏表示每个测试样本真正的标签（p表示正样本，n表示负样本）</li>
<li>“Score”表示每个测试样本属于正样本的概率。<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-03-22-38-47.png" alt=""><br>步骤：</li>
<li>从高到低，依次将“Score”值作为阈值，当测试样本属于正样本的概率大于或等于这个阈值时，我们认为它为正样本，否则为负样本。</li>
<li>举例来说，对于图中的第4个样本，其“Score”值为0.6，那么样本1，2，3，4都被认为是正样本，因为它们的“Score”值都大于等于0.6，而其他样本则都认为是负样本。</li>
<li>每次选取一个不同的阈值，我们就可以得到一组FPR和TPR，即ROC曲线上的一点。这样一来，我们一共得到了20组FPR和TPR的值，将它们画在ROC曲线的结果如下图：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-03-22-39-56.png" alt=""> </li>
<li>当我们将阈值设置为1和0时，分别可以得到ROC曲线上的(0,0)和(1,1)两个点。将这些(FPR,TPR)对连接起来，就得到了ROC曲线。</li>
<li>当阈值取值越多，ROC曲线越平滑。</li>
</ul>
<h3 id="AUC">0.0.3. AUC</h3><ul>
<li>AUC的值就是处于ROC curve下方的那部分面积的大小</li>
<li>通常，AUC的值介于0.5到1.0之间</li>
<li>较大的AUC代表了较好的performance</li>
</ul>
<h4 id="计算AUC的方法">0.0.3.1. 计算AUC的方法</h4><ul>
<li>直接计算AUC是很麻烦的，所以就使用了AUC的一个性质（它和Wilcoxon-Mann-Witney Test是等价的）来进行计算。</li>
<li>Wilcoxon-Mann-Witney Test就是测试任意给一个正类样本和一个负类样本，正类样本的score有多大的概率大于负类样本的score。</li>
<li>有了这个定义，我们就得到了另外一中计算AUC的办法：得到这个概率。</li>
</ul>
<h5 id="方法一">0.0.3.1.1. 方法一</h5><p>统计一下所有的 M×N(M为正类样本的数目，N为负类样本的数目)个正负样本对中，有多少个组中的正样本的score大于负样本的score。当二元组中正负样本的 score相等的时候，按照0.5计算。然后除以MN。实现这个方法的复杂度为O(n^2)。n为样本数（即n=M+N）。<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-03-22-43-59.png" alt=""> </p>
<h5 id="方法二">0.0.3.1.2. 方法二</h5><p>第二种方法实际上和上述方法是一样的，但是复杂度减小了。</p>
<ul>
<li>首先对score从大到小排序</li>
<li>然后令最大score对应的sample 的rank为n，第二大score对应sample的rank为n-1，以此类推</li>
<li>然后把所有的正类样本的rank相加，再减去正类样本的score为最小的那M个值的情况。</li>
<li>得到的就是所有的样本中有多少对正类样本的score大于负类样本的score。</li>
<li>然后再除以M×N。即<br><code>AUC=((所有的正例位置相加)-M*(M+1))/(M*N)</code></li>
</ul>
<p>另外，特别需要注意的是，再存在score相等的情况时，对相等score的样本，需要 赋予相同的rank(无论这个相等的score是出现在同类样本还是不同类的样本之间，都需要这样处理)。具体操作就是再把所有这些score相等的样本 的rank取平均。然后再使用上述公式。</p>
<h3 id="参考文献">0.0.4. 参考文献</h3><ol>
<li><a href="https://www.zybuluo.com/frank-shaw/note/152851" target="_blank" rel="external">评价分类器性能指标之AUC、ROC</a></li>
<li><a href="http://www.cnblogs.com/lixiaolun/p/4053499.html" target="_blank" rel="external">AUC(Area Under roc Curve)学习笔记</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> o2o优惠券使用预测 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[PLA-线性感知机]]></title>
      <url>/2017/02/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-PLA-%E7%BA%BF%E6%80%A7%E6%84%9F%E7%9F%A5%E6%9C%BA/</url>
      <content type="html"><![CDATA[<p>感觉自己记性越来越差。寒假前看的东西，回来忘得一干二净。从此认真做笔记，不能再重蹈覆辙。——题记<br>（第一次使用markdown，不太习惯，后面的公式没有继续打。现在去学习一下好用一些的公式编辑方法）</p>
<h1 id="简介">1. 简介</h1><p>定义：感知机是二类分类的线性模型。</p>
<p>输入：实例的特征向量</p>
<p>输出：实例的类别（±1）</p>
<h1 id="感知机模型">2. 感知机模型</h1><p>感知机——由输入空间到输出空间的函数：</p>
<p>$$<br>f(x)=sign(wx+b)<br>$$</p>
<p>###Tips:<br>$ w \in R^n $：权值，weight<br>$ b \in R $：偏值，bias<br>输入空间（特征空间）：$ X \in R^n $<br>输出空间：$ y={+1,-1} $<br>输入：$ x \in X $表示实例的特征向量，对应于输入空间的点<br>输出：$ y \in Y $，表示实例的类别</p>
<h1 id="感知机学习策略">3. 感知机学习策略</h1><ol>
<li>感知机学习目标：求得一个能将训练集正实例点和负实例点完全正确分开的分离超平面 = 确定模型参数w,b。</li>
<li>感知机学习策略：定义（经验）损失函数并将损失函数极小化。</li>
<li>损失函数的选择：</li>
</ol>
<ul>
<li>《统计学习方法》中介绍到的损失函数：所有误分类点到超平面S的总距离：<img src="http://om1bxijvl.bkt.clouddn.com/2017-02-27-22-03-00.png" alt=""><br>一般不考虑w,即损失函数为：<img src="http://om1bxijvl.bkt.clouddn.com/2017-02-27-22-05-23.png" alt=""><br>M:误分类点的个数</li>
<li>《西瓜书》里提到的误差是均方误差：<img src="https://ooo.0o0.ooo/2017/07/11/59648c8143357.png" alt=""><br>然后用最小二乘法求解w,b。</li>
</ul>
<ol>
<li>误分类点越少，损失函数越小。</li>
</ol>
<p><strong>将感知机学习问题转化为求解损失函数最优化问题</strong></p>
<h1 id="感知机学习算法">4. 感知机学习算法</h1><h2 id="感知机学习算法的原始形式">4.1. 感知机学习算法的原始形式</h2><p><img src="http://om1bxijvl.bkt.clouddn.com/2017-02-27-22-06-33.png" alt=""> </p>
<h2 id="算法的收敛性">4.2. 算法的收敛性</h2>]]></content>
      
        <categories>
            
            <category> 机器学习算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 线性模型 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[布置完毕]]></title>
      <url>/2017/02/28/blog-%E5%B8%83%E7%BD%AE%E5%AE%8C%E6%AF%95/</url>
      <content type="html"><![CDATA[<p>可算是把博客布置得差不多了。还有很多功能待完善，先记下来，日后再说。</p>
<p>1.RSS订阅功能</p>
<p>2.新浪微博圈</p>
<p>3.搜索功能</p>
<p>4.评论功能</p>
<p>5.访问量统计</p>
<p>6.数学公式支持。已解决。<a href="https://weylmann.github.io/2017/02/21/%E7%94%A8github-hexo-mathjax-%E9%83%A8%E7%BD%B2%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/" target="_blank" rel="external">参考文献，程数的博客</a></p>
<p>7.图片一键上传到图床，已解决。<a href="https://github.com/kingname/MarkdownPicPicker" target="_blank" rel="external">参考文献MarkdownPicPicker-master</a></p>
<p>8.sublime text<a href="http://jingyan.baidu.com/article/f006222838bac2fbd2f0c87d.html" target="_blank" rel="external">编辑md</a>。<a href="http://www.cnblogs.com/Richard-Core/p/Sublime-MarkDown.html" target="_blank" rel="external">WEB实时刷新</a>。<a href="https://packagecontrol.io/packages/auto-save" target="_blank" rel="external">sublime实时保存</a></p>
<ol>
<li><a href="https://github.com/HarleyWang93/blog/issues/26" target="_blank" rel="external">站长统计</a></li>
<li><a href="https://zetaoyang.github.io/post/2016/07/08/hexo-localsearch.html" target="_blank" rel="external">搜索引擎</a></li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">9.一键发布功能[已解决](http://blog.csdn.net/anonymalias/article/details/50528946)</div><div class="line"></div><div class="line">10.[为Hexo博客标题自动添加序号：hexo-heading-index](http://www.qingpingshan.com/jianzhan/cms/212734.html)</div></pre></td></tr></table></figure>]]></content>
      
        <categories>
            
            <category> 瞎折腾 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[机器学习简介]]></title>
      <url>/2017/02/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/</url>
      <content type="html"><![CDATA[<p>很多东西看了就忘。一定要好好做笔记。</p>
<p>本节主要记录《机器学习基石》的常见符号。</p>
<h1 id="基础符号">1. 基础符号</h1><p>输入： $ x \in X $<br>输出： $y \in Y $<br>目标函数： $f:X\rightarrow Y $ （理想中的，实际得不到）<br>假设函数：$g:X\rightarrow Y $ ，又称为<code>hypothesis</code>（学习到的g，希望跟f越像越好）<br>$g \in H $<br>假设函数集合：$H = \{h_k\} $ <code>hypothesis set</code><br>训练集：$D=\{(x_1,y_1),…,(x_N,y_N)\}$<br>机器学习演算法：$A$</p>
<h1 id="机器学习流程">2. 机器学习流程</h1><ul>
<li>从数据集D出发</li>
<li>通过演算法A，来计算出一个g，使得g很接近f<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-19-09-29.png" alt=""> </li>
</ul>
<h1 id="误差E">3. 误差E</h1><p>不知道为什么公式显示不出来，只好手动展图了<br>输入误差：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-20-44-49.png" alt=""> </p>
<p>$$E_{in}(h)=\frac{1}{N} \sum_{n=1}^N(h(x_n)-y_n)^2$$</p>
<ul>
<li>样本（训练集）中出现的错误率</li>
</ul>
<p>输出误差：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-03-04-20-45-03.png" alt=""> </p>
<p>$$E_{out}(h)=\mathcal{E}_{(x,y)\text~P}(w^Tx-y)^2$$</p>
<ul>
<li>总体（测试集+训练集）中出现的错误率</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 机器学习算法 </category>
            
        </categories>
        
        
    </entry>
    
  
  
</search>
