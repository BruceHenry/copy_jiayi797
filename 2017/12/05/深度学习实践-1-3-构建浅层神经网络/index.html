<!doctype html>




<html class="theme-next pisces" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="true" />







  <meta name="baidu-site-verification" content="q1zwhBKKPA" />







  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="1. 序言本文主要参考自吴恩达Coursera深度学习课程 DeepLearning.ai 编程作业（1-3） 吴恩达Coursera课程 DeepLearning.ai 编程作业系列，本文为《神经网络与深度学习》部分的第三周“浅层神经网络”的课程作业。 本节的主要内容是：利用浅层神经网络实现平面数据分类">
<meta name="keywords">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习实践-1-3-构建浅层神经网络">
<meta property="og:url" content="http://yoursite.com/child/2017/12/05/深度学习实践-1-3-构建浅层神经网络/index.html">
<meta property="og:site_name" content="jiayi797的专栏">
<meta property="og:description" content="1. 序言本文主要参考自吴恩达Coursera深度学习课程 DeepLearning.ai 编程作业（1-3） 吴恩达Coursera课程 DeepLearning.ai 编程作业系列，本文为《神经网络与深度学习》部分的第三周“浅层神经网络”的课程作业。 本节的主要内容是：利用浅层神经网络实现平面数据分类">
<meta property="og:image" content="http://om1bxijvl.bkt.clouddn.com/2017-12-05-21-55-52.png">
<meta property="og:image" content="http://om1bxijvl.bkt.clouddn.com/2017-12-05-21-56-33.png">
<meta property="og:image" content="http://om1bxijvl.bkt.clouddn.com/2017-12-05-20-50-56.png">
<meta property="og:image" content="http://om1bxijvl.bkt.clouddn.com/2017-12-05-21-57-06.png">
<meta property="og:image" content="http://om1bxijvl.bkt.clouddn.com/2017-12-05-21-57-24.png">
<meta property="og:updated_time" content="2017-12-16T06:17:59.581Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="深度学习实践-1-3-构建浅层神经网络">
<meta name="twitter:description" content="1. 序言本文主要参考自吴恩达Coursera深度学习课程 DeepLearning.ai 编程作业（1-3） 吴恩达Coursera课程 DeepLearning.ai 编程作业系列，本文为《神经网络与深度学习》部分的第三周“浅层神经网络”的课程作业。 本节的主要内容是：利用浅层神经网络实现平面数据分类">
<meta name="twitter:image" content="http://om1bxijvl.bkt.clouddn.com/2017-12-05-21-55-52.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: false,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/child/2017/12/05/深度学习实践-1-3-构建浅层神经网络/"/>





  <title>深度学习实践-1-3-构建浅层神经网络 | jiayi797的专栏</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  




<!-- hexo-inject:begin --><!-- hexo-inject:end --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-110169171-1', 'auto');
  ga('send', 'pageview');
</script>


  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?9856596edaab494b299151eb0e9bb214";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>











  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">jiayi797的专栏</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            时光机
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            琐碎
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/child/2017/12/05/深度学习实践-1-3-构建浅层神经网络/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="jiayi797">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="jiayi797的专栏">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">深度学习实践-1-3-构建浅层神经网络</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-12-05T21:58:36+08:00">
                2017-12-05
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2017-12-16T14:17:59+08:00">
                2017-12-16
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习算法/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习算法</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习算法/神经网络/" itemprop="url" rel="index">
                    <span itemprop="name">神经网络</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
              <span class="post-meta-divider">|</span>
              <span class="post-meta-item-icon">
                <i class="fa fa-comment-o"></i>
              </span>
              
                <a href="/2017/12/05/深度学习实践-1-3-构建浅层神经网络/#SOHUCS" itemprop="discussionUrl">
                  <span id="changyan_count_unit" class="post-comments-count hc-comment-count" data-xid="2017/12/05/深度学习实践-1-3-构建浅层神经网络/" itemprop="commentsCount"></span>
                </a>
              
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 浏览
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>次
            </span>
          

          
            <div class="post-wordcount">
              
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计</span>
                
                <span title="字数统计">
                  3,590
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="序言">1. 序言</h1><p>本文主要参考自<a href="http://blog.csdn.net/koala_tree/article/details/78067464" target="_blank" rel="external">吴恩达Coursera深度学习课程 DeepLearning.ai 编程作业（1-3）</a></p>
<p>吴恩达Coursera课程 DeepLearning.ai 编程作业系列，本文为《神经网络与深度学习》部分的第三周“浅层神经网络”的课程作业。</p>
<p>本节的主要内容是：利用浅层神经网络实现平面数据分类</p>
<a id="more"></a>
<h1 id="1-import的包">2. 1 - import的包</h1><ul>
<li>numpy</li>
<li>sklearn</li>
<li>matplotlib</li>
<li>testCase - 提供了测试样例</li>
<li>pannar_utils - 一些有用的工具</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> warnings</div><div class="line">warnings.filterwarnings(<span class="string">"ignore"</span>) </div><div class="line"></div><div class="line"><span class="comment"># Package imports</span></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">from</span> testCases <span class="keyword">import</span> *</div><div class="line"><span class="keyword">import</span> sklearn</div><div class="line"><span class="keyword">import</span> sklearn.datasets</div><div class="line"><span class="keyword">import</span> sklearn.linear_model</div><div class="line"><span class="keyword">from</span> planar_utils <span class="keyword">import</span> plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasets</div><div class="line"></div><div class="line">%matplotlib inline</div><div class="line"></div><div class="line">np.random.seed(<span class="number">1</span>) <span class="comment"># 给np.random设定一个种子，这样随机数就固定了</span></div></pre></td></tr></table></figure>
<h1 id="2-数据集">3. 2 - 数据集</h1><p>下面的代码生成了“花”的二类数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 这个函数原本在panar_utils.py里</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_planar_dataset</span><span class="params">()</span>:</span></div><div class="line">    np.random.seed(<span class="number">1</span>)</div><div class="line">    m = <span class="number">400</span> <span class="comment"># 样本数量</span></div><div class="line">    N = int(m/<span class="number">2</span>) <span class="comment"># 每个类别的数量</span></div><div class="line">    D = <span class="number">2</span> <span class="comment"># 维度</span></div><div class="line">    <span class="comment"># 初始化X,Y</span></div><div class="line">    X = np.zeros((m,D))</div><div class="line">    Y = np.zeros((m,<span class="number">1</span>),dtype=<span class="string">'uint8'</span>)</div><div class="line">    a = <span class="number">4</span> <span class="comment"># 花儿最大长度</span></div><div class="line">    </div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">2</span>):</div><div class="line">        ix = range(N*j,N*(j+<span class="number">1</span>))</div><div class="line">        t = np.linspace(j*<span class="number">3.12</span>,(j+<span class="number">1</span>)*<span class="number">3.12</span>,N) + np.random.randn(N)*<span class="number">0.2</span> <span class="comment"># theta</span></div><div class="line">        r = a*np.sin(<span class="number">4</span>*t) + np.random.randn(N)*<span class="number">0.2</span> <span class="comment"># radius</span></div><div class="line">        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]</div><div class="line">        Y[ix] = j</div><div class="line">        </div><div class="line">    X = X.T</div><div class="line">    Y = Y.T</div><div class="line"></div><div class="line">    <span class="keyword">return</span> X, Y</div><div class="line"></div><div class="line">X,Y = load_planar_dataset()</div><div class="line"><span class="keyword">print</span> X.shape,Y.shape</div></pre></td></tr></table></figure>
<pre><code>(2L, 400L) (1L, 400L)
</code></pre><p>​    </p>
<p>此时你得到了：</p>
<ul>
<li>一个numpy-array(matrix) X,包括特征（X1，X2）</li>
<li>一个numpy-arrya(vector) Y,包含一列标签（0或1）</li>
</ul>
<p>接下来用matplotlib将这个“花儿”数据集可视化，其中：</p>
<ul>
<li>y = 0 -&gt; 红色</li>
<li>y = 1 -&gt; 蓝色</li>
</ul>
<p>我们的目标是建立一个模型，能将红色和蓝色分开</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 数据可视化</span></div><div class="line">plt.scatter(X[<span class="number">0</span>, :], X[<span class="number">1</span>, :], c=Y, s=<span class="number">40</span>, cmap=plt.cm.Spectral)</div></pre></td></tr></table></figure>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-12-05-21-55-52.png" alt=""> </p>
<h1 id="简单的逻辑回归">4. 简单的逻辑回归</h1><p>首先我们看看LR在这个问题上表现如何：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Train the logistic regression classifier</span></div><div class="line">clf = sklearn.linear_model.LogisticRegressionCV();</div><div class="line">clf.fit(X.T, Y.T);</div><div class="line"></div><div class="line"><span class="comment"># 画出LR的决策边界</span></div><div class="line">plot_decision_boundary(<span class="keyword">lambda</span> x: clf.predict(x), X, Y)</div><div class="line">plt.title(<span class="string">"Logistic Regression"</span>)</div><div class="line"></div><div class="line"><span class="comment"># 打印准确率</span></div><div class="line">LR_predictions = clf.predict(X.T)</div><div class="line"><span class="keyword">print</span> (<span class="string">'LR的准确率是: %d '</span> % float((np.dot(Y,LR_predictions) + np.dot(<span class="number">1</span>-Y,<span class="number">1</span>-LR_predictions))/float(Y.size)*<span class="number">100</span>) +</div><div class="line">       <span class="string">'% '</span>)</div></pre></td></tr></table></figure>
<pre><code>LR的准确率是: 47 % 
</code></pre><p>​    </p>
<p><img src="http://om1bxijvl.bkt.clouddn.com/2017-12-05-21-56-33.png" alt=""> </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 以上的plot_decision_boundary()函数定义如下：</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_decision_boundary</span><span class="params">(model, X, y)</span>:</span></div><div class="line">    <span class="comment"># Set min and max values and give it some padding</span></div><div class="line">    x_min, x_max = X[<span class="number">0</span>, :].min() - <span class="number">1</span>, X[<span class="number">0</span>, :].max() + <span class="number">1</span></div><div class="line">    y_min, y_max = X[<span class="number">1</span>, :].min() - <span class="number">1</span>, X[<span class="number">1</span>, :].max() + <span class="number">1</span></div><div class="line">    h = <span class="number">0.01</span></div><div class="line">    <span class="comment"># Generate a grid of points with distance h between them</span></div><div class="line">    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))</div><div class="line">    <span class="comment"># Predict the function value for the whole grid</span></div><div class="line">    Z = model(np.c_[xx.ravel(), yy.ravel()])</div><div class="line">    Z = Z.reshape(xx.shape)</div><div class="line">    <span class="comment"># Plot the contour and training examples</span></div><div class="line">    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)</div><div class="line">    plt.ylabel(<span class="string">'x2'</span>)</div><div class="line">    plt.xlabel(<span class="string">'x1'</span>)</div><div class="line">    plt.scatter(X[<span class="number">0</span>, :], X[<span class="number">1</span>, :], c=y, cmap=plt.cm.Spectral)</div></pre></td></tr></table></figure>
<h1 id="神经网络模型">5. 神经网络模型</h1><p>我们本次<strong>模型</strong>为：<br><img src="http://om1bxijvl.bkt.clouddn.com/2017-12-05-20-50-56.png" alt=""> </p>
<p><strong>数学模型</strong><br>对于一条样本$x^{i}$</p>
<p>$$z^{[1] (i)} =  W^{[1]} x^{(i)} + b^{[1] (i)}\tag{1}$$<br>$$a^{[1] (i)} = \tanh(z^{[1] (i)})\tag{2}$$<br>$$z^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2] (i)}\tag{3}$$<br>$$\hat{y}^{(i)} = a^{[2] (i)} = \sigma(z^{ [2] (i)})\tag{4}$$<br>$$y^{(i)}_{prediction} = \begin{cases} 1 &amp; \mbox{if } a^{<a href="i">2</a>} &gt; 0.5 \ 0 &amp; \mbox{otherwise } \end{cases}\tag{5}$$</p>
<p>通过上式计算出所有样本的预测误差，我们可以通过下式计算出误差函数：<br>$$J = - \frac{1}{m} \sum\limits_{i = 0}^{m} \large\left(\small y^{(i)}\log\left(a^{[2] (i)}\right) + (1-y^{(i)})\log\left(1- a^{[2] (i)}\right)  \large  \right) \small \tag{6}$$</p>
<p>回忆一下，计算神经网络的步骤为：</p>
<ol>
<li>定义网络结构</li>
<li>初始化模型参数</li>
<li>迭代<ul>
<li>前向传播计算预测值</li>
<li>计算误差</li>
<li>后向传播计算梯度</li>
<li>根据梯度更新参数</li>
</ul>
</li>
</ol>
<h1 id="定义网络结构">6. 定义网络结构</h1><p>约定：</p>
<ul>
<li>n_x : 输入层的数据个数</li>
<li>n_h : 隐藏层数 （此处设置为4）</li>
<li>n_y : 输出层的数据个数（类别个数）</li>
</ul>
<p>可定义如下函数来获取以上三个数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># GRADED FUNCTION: layer_sizes</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">layer_sizes</span><span class="params">(X, Y)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Arguments:</div><div class="line">    X -- input dataset of shape (input size, number of examples)</div><div class="line">    Y -- labels of shape (output size, number of examples)</div><div class="line"></div><div class="line">    Returns:</div><div class="line">    n_x -- the size of the input layer</div><div class="line">    n_h -- the size of the hidden layer</div><div class="line">    n_y -- the size of the output layer</div><div class="line">    """</div><div class="line">    <span class="comment">### START CODE HERE ### (≈ 3 lines of code)</span></div><div class="line">    n_x = X.shape[<span class="number">0</span>] <span class="comment"># size of input layer</span></div><div class="line">    n_h = <span class="number">4</span></div><div class="line">    n_y = Y.shape[<span class="number">0</span>]<span class="comment"># size of output layer</span></div><div class="line">    <span class="comment">### END CODE HERE ###</span></div><div class="line">    <span class="keyword">return</span> (n_x, n_h, n_y)</div><div class="line">n_x, n_h, n_y = layer_sizes(X,Y)</div><div class="line"></div><div class="line"><span class="keyword">print</span> <span class="string">"n_x = "</span>,n_x</div><div class="line"><span class="keyword">print</span> <span class="string">"n_h = "</span>,n_h</div><div class="line"><span class="keyword">print</span> <span class="string">"n_y = "</span>,n_y</div></pre></td></tr></table></figure>
<pre><code>n_x =  2
n_h =  4
n_y =  1
</code></pre><h2 id="初始化参数">6.1. 初始化参数</h2><p>需要初始化的参数主要是W和b</p>
<p>Exercise: Implement the function initialize_parameters().</p>
<p>Instructions: </p>
<ul>
<li>Make sure your parameters’ sizes are right. Refer to the neural network figure above if needed. </li>
<li>You will initialize the weights matrices with random values. </li>
<li>Use: np.random.randn(a,b) * 0.01 to randomly initialize a matrix of shape (a,b). </li>
<li>You will initialize the bias vectors as zeros. </li>
<li>Use: np.zeros((a,b)) to initialize a matrix of shape (a,b) with zeros.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># GRADED FUNCTION: initialize_parameters</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters</span><span class="params">(n_x, n_h, n_y)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Argument:</div><div class="line">    n_x -- size of the input layer</div><div class="line">    n_h -- size of the hidden layer</div><div class="line">    n_y -- size of the output layer</div><div class="line"></div><div class="line">    Returns:</div><div class="line">    params -- python dictionary containing your parameters:</div><div class="line">                    W1 -- weight matrix of shape (n_h, n_x)</div><div class="line">                    b1 -- bias vector of shape (n_h, 1)</div><div class="line">                    W2 -- weight matrix of shape (n_y, n_h)</div><div class="line">                    b2 -- bias vector of shape (n_y, 1)</div><div class="line">    """</div><div class="line"></div><div class="line">    np.random.seed(<span class="number">2</span>) <span class="comment"># we set up a seed so that your output matches ours although the initialization is random.</span></div><div class="line"></div><div class="line">    <span class="comment">### START CODE HERE ### (≈ 4 lines of code)</span></div><div class="line">    W1 = np.random.randn(n_h, n_x)</div><div class="line">    b1 = np.zeros((n_h, <span class="number">1</span>))</div><div class="line">    W2 = np.random.randn(n_y, n_h)</div><div class="line">    b2 = np.zeros((n_y, <span class="number">1</span>))</div><div class="line">    <span class="comment">### END CODE HERE ###</span></div><div class="line"></div><div class="line">    <span class="keyword">assert</span> (W1.shape == (n_h, n_x))</div><div class="line">    <span class="keyword">assert</span> (b1.shape == (n_h, <span class="number">1</span>))</div><div class="line">    <span class="keyword">assert</span> (W2.shape == (n_y, n_h))</div><div class="line">    <span class="keyword">assert</span> (b2.shape == (n_y, <span class="number">1</span>))</div><div class="line"></div><div class="line">    parameters = &#123;<span class="string">"W1"</span>: W1,</div><div class="line">                  <span class="string">"b1"</span>: b1,</div><div class="line">                  <span class="string">"W2"</span>: W2,</div><div class="line">                  <span class="string">"b2"</span>: b2&#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> parameters</div><div class="line"></div><div class="line">parameters = initialize_parameters(n_x, n_h, n_y)</div><div class="line">print(<span class="string">"W1 = "</span> + str(parameters[<span class="string">"W1"</span>]))</div><div class="line">print(<span class="string">"b1 = "</span> + str(parameters[<span class="string">"b1"</span>]))</div><div class="line">print(<span class="string">"W2 = "</span> + str(parameters[<span class="string">"W2"</span>]))</div><div class="line">print(<span class="string">"b2 = "</span> + str(parameters[<span class="string">"b2"</span>]))</div></pre></td></tr></table></figure>
<pre><code>W1 = [[-0.41675785 -0.05626683]
 [-2.1361961   1.64027081]
 [-1.79343559 -0.84174737]
 [ 0.50288142 -1.24528809]]
b1 = [[ 0.]
 [ 0.]
 [ 0.]
 [ 0.]]
W2 = [[-1.05795222 -0.90900761  0.55145404  2.29220801]]
b2 = [[ 0.]]
</code></pre><h2 id="迭代">6.2. 迭代</h2><h3 id="前向传播">6.2.1. 前向传播</h3><p><strong>问题</strong>: 实现 <code>forward_propagation()</code>.</p>
<p><strong>Instructions</strong>:</p>
<ul>
<li>Look above at the mathematical representation of your classifier.</li>
<li>You can use the function <code>sigmoid()</code>. It is built-in (imported) in the notebook.</li>
<li>You can use the function <code>np.tanh()</code>. It is part of the numpy library.</li>
<li>The steps you have to implement are:<ol>
<li>Retrieve each parameter from the dictionary “parameters” (which is the output of <code>initialize_parameters()</code>) by using <code>parameters[&quot;..&quot;]</code>.</li>
<li>Implement Forward Propagation. Compute $Z^{[1]}, A^{[1]}, Z^{[2]}$ and $A^{[2]}$ (the vector of all your predictions on all the examples in the training set).</li>
</ol>
</li>
<li>Values needed in the backpropagation are stored in “<code>cache</code>“. The <code>cache</code> will be given as an input to the backpropagation function.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 前向传播</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation</span><span class="params">(X, parameters)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Argument:</div><div class="line">    X -- input data of size (n_x, m)</div><div class="line">    parameters -- python dictionary containing your parameters (output of initialization function)</div><div class="line"></div><div class="line">    Returns:</div><div class="line">    A2 -- The sigmoid output of the second activation</div><div class="line">    cache -- a dictionary containing "Z1", "A1", "Z2" and "A2"</div><div class="line">    """</div><div class="line">    <span class="comment"># Retrieve each parameter from the dictionary "parameters"</span></div><div class="line">    <span class="comment">### START CODE HERE ### (≈ 4 lines of code)</span></div><div class="line">    <span class="comment"># 参数获取</span></div><div class="line">    W1 = parameters[<span class="string">"W1"</span>]</div><div class="line">    b1 = parameters[<span class="string">"b1"</span>]</div><div class="line">    W2 = parameters[<span class="string">"W2"</span>]</div><div class="line">    b2 = parameters[<span class="string">"b2"</span>]</div><div class="line">    <span class="comment">### END CODE HERE ###</span></div><div class="line"></div><div class="line">    <span class="comment"># Implement Forward Propagation to calculate A2 (probabilities)</span></div><div class="line">    <span class="comment">### START CODE HERE ### (≈ 4 lines of code)</span></div><div class="line">    <span class="comment"># 计算预测值</span></div><div class="line">    Z1 = np.dot(W1, X) + b1</div><div class="line">    A1 = np.tanh(Z1)</div><div class="line">    Z2 = np.dot(W2, A1) + b2 </div><div class="line">    A2 = sigmoid(Z2)</div><div class="line">    <span class="comment">### END CODE HERE ###</span></div><div class="line"></div><div class="line">    <span class="keyword">assert</span>(A2.shape == (<span class="number">1</span>, X.shape[<span class="number">1</span>]))</div><div class="line"></div><div class="line">    cache = &#123;<span class="string">"Z1"</span>: Z1,</div><div class="line">             <span class="string">"A1"</span>: A1,</div><div class="line">             <span class="string">"Z2"</span>: Z2,</div><div class="line">             <span class="string">"A2"</span>: A2&#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> A2, cache</div><div class="line"></div><div class="line">X_assess, parameters = forward_propagation_test_case()</div><div class="line">A2, cache = forward_propagation(X_assess, parameters)</div><div class="line"></div><div class="line"><span class="comment"># Note: we use the mean here just to make sure that your output matches ours. </span></div><div class="line">print(np.mean(cache[<span class="string">'Z1'</span>]) ,np.mean(cache[<span class="string">'A1'</span>]),np.mean(cache[<span class="string">'Z2'</span>]),np.mean(cache[<span class="string">'A2'</span>]))</div></pre></td></tr></table></figure>
<pre><code>(-0.00049975577774199022, -0.00049696335323177901, 0.00043818745095914658, 0.50010954685243103)
</code></pre><p>​    </p>
<h3 id="计算误差">6.2.2. 计算误差</h3><p>现在我们已经计算除了预测值A2，接下来我们需要计算本轮误差：</p>
<p>$$J = - \frac{1}{m} \sum\limits_{i = 0}^{m} \large{(} \small y^{(i)}\log\left(a^{[2] (i)}\right) + (1-y^{(i)})\log\left(1- a^{[2] (i)}\right) \large{)} \small\tag{13}$$</p>
<p><strong>Exercise</strong>: Implement <code>compute_cost()</code> to compute the value of the cost $J$.</p>
<p><strong>Instructions</strong>:</p>
<ul>
<li>There are many ways to implement the cross-entropy loss. To help you, we give you how we would have implemented<br>$- \sum\limits_{i=0}^{m}  y^{(i)}\log(a^{<a href="i">2</a>})$:<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">logprobs = np.multiply(np.log(A2),Y)</div><div class="line">cost = - np.sum(logprobs)                <span class="comment"># no need to use a for loop!</span></div></pre></td></tr></table></figure>
</li>
</ul>
<p>(you can use either <code>np.multiply()</code> and then <code>np.sum()</code> or directly <code>np.dot()</code>).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># GRADED FUNCTION: compute_cost</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost</span><span class="params">(A2, Y, parameters)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Computes the cross-entropy cost given in equation (13)</div><div class="line"></div><div class="line">    Arguments:</div><div class="line">    A2 -- The sigmoid output of the second activation, of shape (1, number of examples)</div><div class="line">    Y -- "true" labels vector of shape (1, number of examples)</div><div class="line">    parameters -- python dictionary containing your parameters W1, b1, W2 and b2</div><div class="line"></div><div class="line">    Returns:</div><div class="line">    cost -- cross-entropy cost given equation (13)</div><div class="line">    """</div><div class="line"></div><div class="line">    m = Y.shape[<span class="number">1</span>] <span class="comment"># number of example</span></div><div class="line"></div><div class="line">    <span class="comment"># Compute the cross-entropy cost</span></div><div class="line">    <span class="comment">### START CODE HERE ### (≈ 2 lines of code)</span></div><div class="line">    <span class="comment"># 误差计算</span></div><div class="line">    logprobs = np.multiply(np.log(A2), Y) + np.multiply(np.log(<span class="number">1</span>-A2), (<span class="number">1</span>-Y))</div><div class="line">    cost = -(<span class="number">1.0</span>/m)*np.sum(logprobs)</div><div class="line">    <span class="comment">### END CODE HERE ###</span></div><div class="line"></div><div class="line">    cost = np.squeeze(cost)     <span class="comment"># makes sure cost is the dimension we expect. </span></div><div class="line">                                <span class="comment"># E.g., turns [[17]] into 17 </span></div><div class="line">    <span class="keyword">assert</span>(isinstance(cost, float))</div><div class="line"></div><div class="line">    <span class="keyword">return</span> cost</div><div class="line">A2, Y_assess, parameters = compute_cost_test_case()</div><div class="line"></div><div class="line">print(<span class="string">"cost = "</span> + str(compute_cost(A2, Y_assess, parameters)))</div></pre></td></tr></table></figure>
<pre><code>cost = 0.692919893776
</code></pre><p>​    </p>
<h3 id="后向传播计算梯度">6.2.3. 后向传播计算梯度</h3><p>Using the cache computed during forward propagation, you can now implement backward propagation.</p>
<p><strong>Question</strong>: Implement the function <code>backward_propagation()</code>.</p>
<p><strong>Instructions</strong>:<br>Backpropagation is usually the hardest (most mathematical) part in deep learning. To help you, here again is the slide from the lecture on backpropagation. You’ll want to use the six equations on the right of this slide, since you are building a vectorized implementation.  </p>
<p>$\frac{\partial \mathcal{J} }{ \partial z_{2}^{(i)} } = \frac{1}{m} (a^{<a href="i">2</a>} - y^{(i)})$</p>
<p>$\frac{\partial \mathcal{J} }{ \partial W_2 } = \frac{\partial \mathcal{J} }{ \partial z_{2}^{(i)} } a^{[1] (i) T} $</p>
<p>$\frac{\partial \mathcal{J} }{ \partial b_2 } = \sum_i{\frac{\partial \mathcal{J} }{ \partial z_{2}^{(i)}}}$</p>
<p>$\frac{\partial \mathcal{J} }{ \partial z_{1}^{(i)} } =  W_2^T \frac{\partial \mathcal{J} }{ \partial z_{2}^{(i)} } * ( 1 - a^{[1] (i) 2}) $</p>
<p>$\frac{\partial \mathcal{J} }{ \partial W_1 } = \frac{\partial \mathcal{J} }{ \partial z_{1}^{(i)} }  X^T $</p>
<p>$\frac{\partial \mathcal{J} _i }{ \partial b_1 } = \sum_i{\frac{\partial \mathcal{J} }{ \partial z_{1}^{(i)}}}$</p>
<ul>
<li>Note that $*$ denotes elementwise multiplication.</li>
<li>The notation you will use is common in deep learning coding:<ul>
<li>dW1 = $\frac{\partial \mathcal{J} }{ \partial W_1 }$</li>
<li>db1 = $\frac{\partial \mathcal{J} }{ \partial b_1 }$</li>
<li>dW2 = $\frac{\partial \mathcal{J} }{ \partial W_2 }$</li>
<li>db2 = $\frac{\partial \mathcal{J} }{ \partial b_2 }$</li>
</ul>
</li>
</ul>
<ul>
<li>Tips:<ul>
<li>To compute dZ1 you’ll need to compute $g^{[1]’}(Z^{[1]})$. Since $g^{[1]}(.)$ is the tanh activation function, if $a = g^{[1]}(z)$ then $g^{[1]’}(z) = 1-a^2$. So you can compute<br>$g^{[1]’}(Z^{[1]})$ using <code>(1 - np.power(A1, 2))</code>.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># GRADED FUNCTION: backward_propagation</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward_propagation</span><span class="params">(parameters, cache, X, Y)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Implement the backward propagation using the instructions above.</div><div class="line"></div><div class="line">    Arguments:</div><div class="line">    parameters -- python dictionary containing our parameters </div><div class="line">    cache -- a dictionary containing "Z1", "A1", "Z2" and "A2".</div><div class="line">    X -- input data of shape (2, number of examples)</div><div class="line">    Y -- "true" labels vector of shape (1, number of examples)</div><div class="line"></div><div class="line">    Returns:</div><div class="line">    grads -- python dictionary containing your gradients with respect to different parameters</div><div class="line">    """</div><div class="line">    m = X.shape[<span class="number">1</span>]</div><div class="line"></div><div class="line">    <span class="comment"># First, retrieve W1 and W2 from the dictionary "parameters".</span></div><div class="line">    <span class="comment"># 获取参数</span></div><div class="line">    W1 = parameters[<span class="string">"W1"</span>]</div><div class="line">    W2 = parameters[<span class="string">"W2"</span>]</div><div class="line"></div><div class="line">    A1 = cache[<span class="string">"A1"</span>]</div><div class="line">    A2 = cache[<span class="string">"A2"</span>]</div><div class="line"></div><div class="line"></div><div class="line">    <span class="comment"># Backward propagation: calculate dW1, db1, dW2, db2. </span></div><div class="line">    <span class="comment"># 后向传播</span></div><div class="line">    dZ2 = A2 - Y</div><div class="line">    dW2 = <span class="number">1.0</span>/m*np.dot(dZ2, A1.T)</div><div class="line">    db2 = <span class="number">1.0</span>/m*np.sum(dZ2, axis=<span class="number">1</span>, keepdims=<span class="keyword">True</span>)</div><div class="line">    dZ1 = np.dot(W2.T, dZ2)*(<span class="number">1</span>-np.power(A1, <span class="number">2</span>))</div><div class="line">    dW1 = <span class="number">1.0</span>/m*np.dot(dZ1, X.T)</div><div class="line">    db1 = <span class="number">1.0</span>/m*np.sum(dZ1, axis=<span class="number">1</span>, keepdims=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"></div><div class="line">    grads = &#123;<span class="string">"dW1"</span>: dW1,</div><div class="line">             <span class="string">"db1"</span>: db1,</div><div class="line">             <span class="string">"dW2"</span>: dW2,</div><div class="line">             <span class="string">"db2"</span>: db2&#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> grads</div><div class="line"></div><div class="line">parameters, cache, X_assess, Y_assess = backward_propagation_test_case()</div><div class="line"></div><div class="line">grads = backward_propagation(parameters, cache, X_assess, Y_assess)</div><div class="line"><span class="keyword">print</span> (<span class="string">"dW1 = "</span>+ str(grads[<span class="string">"dW1"</span>]))</div><div class="line"><span class="keyword">print</span> (<span class="string">"db1 = "</span>+ str(grads[<span class="string">"db1"</span>]))</div><div class="line"><span class="keyword">print</span> (<span class="string">"dW2 = "</span>+ str(grads[<span class="string">"dW2"</span>]))</div><div class="line"><span class="keyword">print</span> (<span class="string">"db2 = "</span>+ str(grads[<span class="string">"db2"</span>]))</div></pre></td></tr></table></figure>
<pre><code>dW1 = [[ 0.01018708 -0.00708701]
 [ 0.00873447 -0.0060768 ]
 [-0.00530847  0.00369379]
 [-0.02206365  0.01535126]]
db1 = [[-0.00069728]
 [-0.00060606]
 [ 0.000364  ]
 [ 0.00151207]]
dW2 = [[ 0.00363613  0.03153604  0.01162914 -0.01318316]]
db2 = [[ 0.06589489]]
</code></pre><h3 id="更新参数">6.2.4. 更新参数</h3><p><strong>Question</strong>: Implement the update rule. Use gradient descent. You have to use (dW1, db1, dW2, db2) in order to update (W1, b1, W2, b2).</p>
<p><strong>General gradient descent rule</strong>: $ \theta = \theta - \alpha \frac{\partial J }{ \partial \theta }$ where $\alpha$ is the learning rate and $\theta$ represents a parameter.</p>
<p><strong>Illustration</strong>: The gradient descent algorithm with a good learning rate (converging) and a bad learning rate (diverging). Images courtesy of Adam Harley.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># GRADED FUNCTION: update_parameters</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters</span><span class="params">(parameters, grads, learning_rate = <span class="number">1.2</span>)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Updates parameters using the gradient descent update rule given above</div><div class="line">    </div><div class="line">    Arguments:</div><div class="line">    parameters -- python dictionary containing your parameters </div><div class="line">    grads -- python dictionary containing your gradients </div><div class="line">    </div><div class="line">    Returns:</div><div class="line">    parameters -- python dictionary containing your updated parameters </div><div class="line">    """</div><div class="line">    <span class="comment"># Retrieve each parameter from the dictionary "parameters"</span></div><div class="line">    <span class="comment"># 获取参数</span></div><div class="line">    W1 = parameters[<span class="string">"W1"</span>]</div><div class="line">    b1 = parameters[<span class="string">"b1"</span>]</div><div class="line">    W2 = parameters[<span class="string">"W2"</span>]</div><div class="line">    b2 = parameters[<span class="string">"b2"</span>]</div><div class="line"></div><div class="line">    </div><div class="line">    <span class="comment"># Retrieve each gradient from the dictionary "grads"</span></div><div class="line">    <span class="comment"># 获取梯度</span></div><div class="line">    dW1 = grads[<span class="string">"dW1"</span>]</div><div class="line">    db1 = grads[<span class="string">"db1"</span>]</div><div class="line">    dW2 = grads[<span class="string">"dW2"</span>]</div><div class="line">    db2 = grads[<span class="string">"db2"</span>]</div><div class="line"></div><div class="line">    </div><div class="line">    <span class="comment"># Update rule for each parameter</span></div><div class="line">    <span class="comment"># 根据梯度更新参数</span></div><div class="line">    W1 = W1 - learning_rate * dW1</div><div class="line">    b1 = b1 - learning_rate * db1</div><div class="line">    W2 = W2 - learning_rate * dW2</div><div class="line">    b2 = b2 - learning_rate * db2</div><div class="line">    </div><div class="line">    parameters = &#123;<span class="string">"W1"</span>: W1,</div><div class="line">                  <span class="string">"b1"</span>: b1,</div><div class="line">                  <span class="string">"W2"</span>: W2,</div><div class="line">                  <span class="string">"b2"</span>: b2&#125;</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> parameters</div><div class="line"></div><div class="line">parameters, grads = update_parameters_test_case()</div><div class="line">parameters = update_parameters(parameters, grads)</div><div class="line"></div><div class="line">print(<span class="string">"W1 = "</span> + str(parameters[<span class="string">"W1"</span>]))</div><div class="line">print(<span class="string">"b1 = "</span> + str(parameters[<span class="string">"b1"</span>]))</div><div class="line">print(<span class="string">"W2 = "</span> + str(parameters[<span class="string">"W2"</span>]))</div><div class="line">print(<span class="string">"b2 = "</span> + str(parameters[<span class="string">"b2"</span>]))</div></pre></td></tr></table></figure>
<pre><code>W1 = [[-0.00643025  0.01936718]
 [-0.02410458  0.03978052]
 [-0.01653973 -0.02096177]
 [ 0.01046864 -0.05990141]]
b1 = [[ -1.02420756e-06]
 [  1.27373948e-05]
 [  8.32996807e-07]
 [ -3.20136836e-06]]
W2 = [[-0.01041081 -0.04463285  0.01758031  0.04747113]]
b2 = [[ 0.00010457]]
</code></pre><h3 id="将前面三步合在一起">6.2.5. 将前面三步合在一起</h3><p><strong>Question</strong>: Build your neural network model in <code>nn_model()</code>.</p>
<p><strong>Instructions</strong>: The neural network model has to use the previous functions in the right order.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># GRADED FUNCTION: nn_model</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">nn_model</span><span class="params">(X, Y, n_h, num_iterations = <span class="number">10000</span>, print_cost=False)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Arguments:</div><div class="line">    X -- dataset of shape (2, number of examples)</div><div class="line">    Y -- labels of shape (1, number of examples)</div><div class="line">    n_h -- size of the hidden layer</div><div class="line">    num_iterations -- Number of iterations in gradient descent loop</div><div class="line">    print_cost -- if True, print the cost every 1000 iterations</div><div class="line"></div><div class="line">    Returns:</div><div class="line">    parameters -- parameters learnt by the model. They can then be used to predict.</div><div class="line">    """</div><div class="line"></div><div class="line">    np.random.seed(<span class="number">3</span>)</div><div class="line">    n_x = layer_sizes(X, Y)[<span class="number">0</span>]</div><div class="line">    n_y = layer_sizes(X, Y)[<span class="number">2</span>]</div><div class="line"></div><div class="line">    <span class="comment"># Initialize parameters, then retrieve W1, b1, W2, b2. Inputs: "n_x, n_h, n_y". Outputs = "W1, b1, W2, b2, parameters".</span></div><div class="line">    <span class="comment"># 获取初始化参数</span></div><div class="line">    parameters = initialize_parameters(n_x, n_h, n_y)</div><div class="line">    W1 = parameters[<span class="string">"W1"</span>]</div><div class="line">    b1 = parameters[<span class="string">"b1"</span>]</div><div class="line">    W2 = parameters[<span class="string">"W2"</span>]</div><div class="line">    b2 = parameters[<span class="string">"b2"</span>]</div><div class="line"></div><div class="line">    <span class="comment"># Loop (gradient descent)</span></div><div class="line"></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, num_iterations):</div><div class="line"></div><div class="line">        <span class="comment"># Forward propagation. Inputs: "X, parameters". Outputs: "A2, cache".</span></div><div class="line">        <span class="comment"># 前向传播计算预测值</span></div><div class="line">        A2, cache = forward_propagation(X, parameters)</div><div class="line"></div><div class="line">        <span class="comment"># Cost function. Inputs: "A2, Y, parameters". Outputs: "cost".</span></div><div class="line">        <span class="comment"># 计算误差</span></div><div class="line">        cost = compute_cost(A2, Y, parameters)</div><div class="line"></div><div class="line">        <span class="comment"># Backpropagation. Inputs: "parameters, cache, X, Y". Outputs: "grads".</span></div><div class="line">        <span class="comment"># 后向传播计算梯度</span></div><div class="line">        grads = backward_propagation(parameters, cache, X, Y)</div><div class="line"></div><div class="line">        <span class="comment"># Gradient descent parameter update. Inputs: "parameters, grads". Outputs: "parameters".</span></div><div class="line">        <span class="comment"># 根据梯度更新参数</span></div><div class="line">        parameters = update_parameters(parameters, grads)</div><div class="line"></div><div class="line">        <span class="comment"># Print the cost every 1000 iterations</span></div><div class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">1000</span> == <span class="number">0</span>:</div><div class="line">            <span class="keyword">print</span> (<span class="string">"Cost after iteration %i: %f"</span> %(i, cost))</div><div class="line"></div><div class="line">    <span class="keyword">return</span> parameters</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">nn_model_test_case</span><span class="params">()</span>:</span></div><div class="line">    np.random.seed(<span class="number">1</span>)</div><div class="line">    X_assess = np.random.randn(<span class="number">2</span>, <span class="number">3</span>)</div><div class="line">    Y_assess = np.random.randn(<span class="number">1</span>, <span class="number">3</span>)</div><div class="line">    <span class="keyword">return</span> X_assess, Y_assess</div><div class="line"></div><div class="line">X_assess, Y_assess = nn_model_test_case()</div><div class="line"><span class="keyword">print</span> X_assess</div><div class="line"><span class="keyword">print</span> Y_assess</div><div class="line">parameters = nn_model(X_assess, Y_assess, <span class="number">4</span>, num_iterations=<span class="number">10000</span>, print_cost=<span class="keyword">True</span>)</div><div class="line">print(<span class="string">"W1 = "</span> + str(parameters[<span class="string">"W1"</span>]))</div><div class="line">print(<span class="string">"b1 = "</span> + str(parameters[<span class="string">"b1"</span>]))</div><div class="line">print(<span class="string">"W2 = "</span> + str(parameters[<span class="string">"W2"</span>]))</div><div class="line">print(<span class="string">"b2 = "</span> + str(parameters[<span class="string">"b2"</span>]))</div></pre></td></tr></table></figure>
<pre><code>[[ 1.62434536 -0.61175641 -0.52817175]
 [-1.07296862  0.86540763 -2.3015387 ]]
[[ 1.74481176 -0.7612069   0.3190391 ]]
Cost after iteration 0: -0.734104
Cost after iteration 1000: -inf
Cost after iteration 2000: -inf
Cost after iteration 3000: -inf
Cost after iteration 4000: -inf
Cost after iteration 5000: -inf
Cost after iteration 6000: -inf
Cost after iteration 7000: -inf
Cost after iteration 8000: -inf
Cost after iteration 9000: -inf
W1 = [[-7.53845806  1.20775367]
 [-4.25271792  5.29708473]
 [-7.53823957  1.20769882]
 [ 4.1479613  -5.35960029]]
b1 = [[ 3.81060333]
 [ 2.31388695]
 [ 3.81043858]
 [-2.32850837]]
W2 = [[-6012.41560745 -6036.77027646 -6010.58554698  6038.039225  ]]
b2 = [[-53.79862878]]
</code></pre><h3 id="预测">6.2.6. 预测</h3><p><strong>Question</strong>: Use your model to predict by building predict().<br>Use forward propagation to predict results.</p>
<p><strong>Reminder</strong>: predictions = $y_{prediction} = \mathbb 1 (\text{ if activation &gt; 0.5}) $  </p>
<p>As an example, if you would like to set the entries of a matrix X to 0 and 1 based on a threshold you would do: <figure class="highlight plain"><figcaption><span>= (X > threshold)```</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"></div><div class="line">```python</div><div class="line"># GRADED FUNCTION: predict</div><div class="line"></div><div class="line">def predict(parameters, X):</div><div class="line">    &quot;&quot;&quot;</div><div class="line">    Using the learned parameters, predicts a class for each example in X</div><div class="line"></div><div class="line">    Arguments:</div><div class="line">    parameters -- python dictionary containing your parameters </div><div class="line">    X -- input data of size (n_x, m)</div><div class="line"></div><div class="line">    Returns</div><div class="line">    predictions -- vector of predictions of our model (red: 0 / blue: 1)</div><div class="line">    &quot;&quot;&quot;</div><div class="line"></div><div class="line">    # Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.</div><div class="line">    ### START CODE HERE ### (≈ 2 lines of code)</div><div class="line">    A2, cache = forward_propagation(X, parameters)</div><div class="line">    predictions = (A2 &gt; 0.5)</div><div class="line">    ### END CODE HERE ###</div><div class="line"></div><div class="line">    return predictions</div><div class="line"></div><div class="line"></div><div class="line">parameters, X_assess = predict_test_case()</div><div class="line"></div><div class="line">predictions = predict(parameters, X_assess)</div><div class="line">print(&quot;predictions mean = &quot; + str(np.mean(predictions)))</div></pre></td></tr></table></figure></p>
<pre><code>predictions mean = 0.666666666667
</code></pre><p>​    </p>
<h1 id="应用模型">7. 应用模型</h1><p>将上面这个模型用在数据集上：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Build a model with a n_h-dimensional hidden layer</span></div><div class="line">parameters = nn_model(X, Y, n_h = <span class="number">4</span>, num_iterations = <span class="number">10000</span>, print_cost=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"><span class="comment"># Plot the decision boundary</span></div><div class="line">plot_decision_boundary(<span class="keyword">lambda</span> x: predict(parameters, x.T), X, Y)</div><div class="line">plt.title(<span class="string">"Decision Boundary for hidden layer size "</span> + str(<span class="number">4</span>))</div><div class="line"></div><div class="line"><span class="comment"># Print accuracy</span></div><div class="line">predictions = predict(parameters, X)</div><div class="line"><span class="keyword">print</span> (<span class="string">'Accuracy: %d'</span> % float((np.dot(Y,predictions.T) + np.dot(<span class="number">1</span>-Y,<span class="number">1</span>-predictions.T))/float(Y.size)*<span class="number">100</span>) + <span class="string">'%'</span>)</div></pre></td></tr></table></figure>
<pre><code>Cost after iteration 0: 1.127380
Cost after iteration 1000: 0.288553
Cost after iteration 2000: 0.276386
Cost after iteration 3000: 0.268077
Cost after iteration 4000: 0.263069
Cost after iteration 5000: 0.259617
Cost after iteration 6000: 0.257070
Cost after iteration 7000: 0.255105
Cost after iteration 8000: 0.253534
Cost after iteration 9000: 0.252245
Accuracy: 91%
</code></pre><p><img src="http://om1bxijvl.bkt.clouddn.com/2017-12-05-21-57-06.png" alt=""> </p>
<h1 id="观测不同的隐藏层数对于模型的影响">8. 观测不同的隐藏层数对于模型的影响</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># This may take about 2 minutes to run</span></div><div class="line"></div><div class="line">plt.figure(figsize=(<span class="number">16</span>, <span class="number">32</span>))</div><div class="line">hidden_layer_sizes = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">20</span>, <span class="number">50</span>]</div><div class="line"><span class="keyword">for</span> i, n_h <span class="keyword">in</span> enumerate(hidden_layer_sizes):</div><div class="line">    plt.subplot(<span class="number">5</span>, <span class="number">2</span>, i+<span class="number">1</span>)</div><div class="line">    plt.title(<span class="string">'Hidden Layer of size %d'</span> % n_h)</div><div class="line">    parameters = nn_model(X, Y, n_h, num_iterations = <span class="number">5000</span>)</div><div class="line">    plot_decision_boundary(<span class="keyword">lambda</span> x: predict(parameters, x.T), X, Y)</div><div class="line">    predictions = predict(parameters, X)</div><div class="line">    accuracy = float((np.dot(Y,predictions.T) + np.dot(<span class="number">1</span>-Y,<span class="number">1</span>-predictions.T))/float(Y.size)*<span class="number">100</span>)</div><div class="line">    <span class="keyword">print</span> (<span class="string">"Accuracy for &#123;&#125; hidden units: &#123;&#125; %"</span>.format(n_h, accuracy))</div></pre></td></tr></table></figure>
<pre><code>Accuracy for 1 hidden units: 61.5 %
Accuracy for 2 hidden units: 70.5 %
Accuracy for 3 hidden units: 66.25 %
Accuracy for 4 hidden units: 90.75 %
Accuracy for 5 hidden units: 90.5 %
Accuracy for 20 hidden units: 92.0 %
Accuracy for 50 hidden units: 90.75 %
</code></pre><p><img src="http://om1bxijvl.bkt.clouddn.com/2017-12-05-21-57-24.png" alt=""> </p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/12/08/深度学习算法-深度卷积模型/" rel="next" title="深度学习算法-深度卷积模型">
                <i class="fa fa-chevron-left"></i> 深度学习算法-深度卷积模型
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/12/04/算法-链表/" rel="prev" title="算法-链表">
                算法-链表 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="SOHUCS"></div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="jiayi797" />
          <p class="site-author-name" itemprop="name">jiayi797</p>
           
              <p class="site-description motion-element" itemprop="description">甲乙小朋友写字的地方</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">95</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">20</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">30</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#序言"><span class="nav-text">1. 序言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-import的包"><span class="nav-text">2. 1 - import的包</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-数据集"><span class="nav-text">3. 2 - 数据集</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#简单的逻辑回归"><span class="nav-text">4. 简单的逻辑回归</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#神经网络模型"><span class="nav-text">5. 神经网络模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#定义网络结构"><span class="nav-text">6. 定义网络结构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#初始化参数"><span class="nav-text">6.1. 初始化参数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#迭代"><span class="nav-text">6.2. 迭代</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#前向传播"><span class="nav-text">6.2.1. 前向传播</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#计算误差"><span class="nav-text">6.2.2. 计算误差</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#后向传播计算梯度"><span class="nav-text">6.2.3. 后向传播计算梯度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#更新参数"><span class="nav-text">6.2.4. 更新参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#将前面三步合在一起"><span class="nav-text">6.2.5. 将前面三步合在一起</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#预测"><span class="nav-text">6.2.6. 预测</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#应用模型"><span class="nav-text">7. 应用模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#观测不同的隐藏层数对于模型的影响"><span class="nav-text">8. 观测不同的隐藏层数对于模型的影响</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">jiayi797</span>
</div>



<div class="theme-info">
  <div class="powered-by">感谢hexo.Next</div>
  <span class="post-count">博客全站共178.9k字</span>
</div>


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人次
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.1"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  




  
    <script type="text/javascript">
    (function(){
      var appid = 'cytmgt7V8';
      var conf = 'f20a47bca89136fdb1ce79762c886a35';
      var width = window.innerWidth || document.documentElement.clientWidth;
      if (width < 960) {
      window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/mobile/wap-js/changyan_mobile.js?client_id=' + appid + '&conf=' + conf + '"><\/script>'); } else { var loadJs=function(d,a){var c=document.getElementsByTagName("head")[0]||document.head||document.documentElement;var b=document.createElement("script");b.setAttribute("type","text/javascript");b.setAttribute("charset","UTF-8");b.setAttribute("src",d);if(typeof a==="function"){if(window.attachEvent){b.onreadystatechange=function(){var e=b.readyState;if(e==="loaded"||e==="complete"){b.onreadystatechange=null;a()}}}else{b.onload=a}}c.appendChild(b)};loadJs("https://changyan.sohu.com/upload/changyan.js",function(){
        window.changyan.api.config({appid:appid,conf:conf})});
      }
    })();
    </script>
    <script type="text/javascript" src="https://assets.changyan.sohu.com/upload/plugins/plugins.count.js"></script>
  



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (search_path.endsWith("json")) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"]]}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


  

  

  

</body>
</html>
